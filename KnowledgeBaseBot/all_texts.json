[
  "CAPE Sandbox Book\n\nCAPE Sandbox is an Open Source software for automating analysis of suspicious files. To do so it makes use of custom components that monitor the behavior of the malicious processes while running in an isolated environment.\n\nThis guide will explain how to set up CAPE, use it and customize it.\n\nHaving troubles?\n\nIf you're having troubles you might want to check out the FAQ <faq/index> as it may already have the answers to your questions.\n\nfaq/index\n\nOtherwise you can ask the developers and/or other CAPE users, see Join the discussion <finalremarks/index>.\n\nContents\n\nintroduction/index installation/index usage/index customization/index integrations/index development/index finalremarks/index",
  "Customization\n\nThis chapter explains how to customize CAPE. CAPE is written in a modular architecture built to be as customizable as it can, to fit the needs of all users.\n\nauxiliary machinery packages processing signatures reporting",
  "Reporting Modules\n\nAfter the raw analysis results have been processed and abstracted by the processing modules and the global container is generated (ref. processing), it is passed over by CAPE to all the reporting modules available, which will make use of it and will make it accessible and consumable in different formats.\n\nGetting Started\n\nAll reporting modules must be placed inside the directory modules/reporting/.\n\nEvery module must also have a dedicated section in the file conf/reporting.conf: for example, if you create a module module/reporting/foobar.py you will have to append the following section to conf/reporting.conf:\n\n[foobar]\nenabled = on\n\nEvery additional option you add to your section will be available to your reporting module in the self.options dictionary.\n\nFollowing is an example of a working JSON reporting module:\n\nimport os\nimport json\nimport codecs\n\nfrom lib.cuckoo.common.abstracts import Report\nfrom lib.cuckoo.common.exceptions import CuckooReportError",
  "class JsonDump(Report):\n    \"\"\"Saves analysis results in JSON format.\"\"\"\n\n    def run(self, results):\n        \"\"\"Writes report.\n        @param results: Cuckoo results dict.\n        @raise CuckooReportError: if fails to write report.\n        \"\"\"\n        try:\n            report = codecs.open(os.path.join(self.reports_path, \"report.json\"), \"w\", \"utf-8\")\n            json.dump(results, report, sort_keys=False, indent=4)\n            report.close()\n        except (UnicodeError, TypeError, IOError) as e:\n            raise CuckooReportError(\"Failed to generate JSON report: %s\" % e)\n\nThis code is very simple, it just receives the global container produced by the processing modules, converts it into JSON, and writes it to a file.\n\nThere are a few requirements for writing a valid reporting module:\n\nDeclare your class inheriting from Report.\n\nHave a run() function performing the main operations.\n\nTry to catch most exceptions and raise CuckooReportError to notify the issue.",
  "Try to catch most exceptions and raise CuckooReportError to notify the issue.\n\nAll reporting modules have access to some attributes:\n\nself.analysis_path: path to the folder containing the raw analysis results (e.g. storage/analyses/1/)\n\nself.reports_path: path to the folder where the reports should be written (e.g. storage/analyses/1/reports/)\n\nself.conf_path: path to the analysis.conf file of the current analysis (e.g. storage/analyses/1/analysis.conf)\n\nself.options: a dictionary containing all the options specified in the report's configuration section in conf/reporting.conf.",
  "Auxiliary Modules\n\nAuxiliary modules define some procedures that need to be executed in parallel to every single analysis process. All auxiliary modules should be placed under the modules/auxiliary/ directory.\n\nThe skeleton of a module would look something like this:\n\nfrom lib.cuckoo.common.abstracts import Auxiliary\n\nclass MyAuxiliary(Auxiliary):\n\n    def start(self):\n        # Do something.\n\n    def stop(self):\n        # Stop the execution.\n\nThe function start() will be executed before starting the analysis machine and effectively executing the submitted malicious file, while the stop() function will be launched at the very end of the analysis process, before launching the processing and reporting procedures.\n\nFor example, an auxiliary module provided by default in CAPE is called sniffer.py and takes care of executing tcpdump in order to dump the generated network traffic.\n\nAuxiliary Module Configuration",
  "Auxiliary Module Configuration\n\nAuxiliary modules can be \"configured\" before being started. This allows data to be added at runtime, whilst also allowing for the configuration to be stored separately from the CAPE python code.\n\nPrivate Auxiliary Module Configuration\n\nPrivate auxiliary module configuration is stored outside the auxiliary class, in a module under the same name as the auxiliary module. This is useful when managing configuration of auxiliary modules separately if desired, for privacy reasons or otherwise.\n\nHere is a configuration module example that installs some software prior to the auxiliary module starting:\n\n# data/auxiliary/example.py\nimport subprocess\nimport logging\nfrom pathlib import Path\n\nlog = logging.getLogger(__name__)\nBIN_PATH = Path.cwd() / \"bin\"",
  "log = logging.getLogger(__name__)\nBIN_PATH = Path.cwd() / \"bin\"\n\n\ndef configure(aux_instance):\n    # here \"example\" refers to modules.auxiliary.example.Example\n    if not aux_instance.enabled:\n        return\n    msi = aux_instance.options.get(\"example_msi\")\n    if not msi:\n        return\n    msi_path = BIN_PATH / msi\n    if not msi_path.exists():\n        log.warning(\"missing MSI %s\", msi_path)\n        return\n    cmd = [\"msiexec\", \"/i\", msi_path, \"/quiet\"]\n    try:\n        log.info(\"Executing msi package...\")\n        subprocess.check_output(cmd)\n        log.info(\"Installation succesful\")\n    except subprocess.CalledProcessError as exc:\n        log.error(\"Installation failed: %s\", exc)\n        return",
  "Analysis Packages\n\nAs explained in ../usage/packages, analysis packages are structured Python classes that describe how CAPE's analyzer component should conduct the analysis procedure for a given file inside the guest environment.\n\nAs you already know, you can create your packages and add them along with the default ones. Designing new packages is very easy and requires just a minimal understanding of programming and the Python language.\n\nGetting started\n\nAs an example we'll take a look at the default package for analyzing generic Windows executables (located at analyzer/windows/packages/exe.py):\n\nfrom lib.common.abstracts import Package\n\nclass Exe(Package):\n    \"\"\"EXE analysis package.\"\"\"\n\n    def start(self, path):\n        args = self.options.get(\"arguments\")\n        return self.execute(path, args)\n\nIt seems easy, thanks to all methods inherited by the Package object. Let's have a look at some of the main methods an analysis package inherits from the Package object:",
  "from lib.api.process import Process\nfrom lib.common.exceptions import CuckooPackageError\n\nclass Package:\n    def start(self):\n        raise NotImplementedError\n\n    def check(self):\n        return True\n\n    def execute(self, path, args):\n        dll = self.options.get(\"dll\")\n        free = self.options.get(\"free\")\n        suspended = True\n        if free:\n            suspended = False\n\n        p = Process()\n        if not p.execute(path=path, args=args, suspended=suspended):\n            raise CuckooPackageError(\"Unable to execute the initial process, \"\n                                     \"analysis aborted.\")\n\n        if not free and suspended:\n            p.inject(dll)\n            p.resume()\n            p.close()\n            return p.pid\n\n    def finish(self):\n        if self.options.get(\"procmemdump\"):\n            for pid in self.pids:\n                p = Process(pid=pid)\n                p.dump_memory()\n        return True\n\nstart()",
  "start()\n\nIn this function you have to place all the initialization operations you want to run. This may include running the malware process, launching additional applications, taking memory snapshots, and more.\n\ncheck()\n\nThis function is executed by CAPE every second while the malware is running. You can use this function to perform any kind of recurrent operation.\n\nFor example, if in your analysis you are looking for just one specific indicator to be created (e.g. a file) you could place your condition in this function and if it returns False, the analysis will terminate straight away.\n\nThink of it as \"should the analysis continue or not?\".\n\nFor example:\n\ndef check(self):\n    if os.path.exists(\"C:\\\\config.bin\"):\n        return False\n    else:\n        return True\n\nThis check() function will cause CAPE to immediately terminate the analysis whenever C:\\config.bin is created.\n\nexecute()\n\nWraps the malware execution and deals with DLL injection.\n\nfinish()",
  "execute()\n\nWraps the malware execution and deals with DLL injection.\n\nfinish()\n\nThis function is simply called by CAPE before terminating the analysis and powering off the machine. By default, this function contains an optional feature to dump the process memory of all the monitored processes.\n\nOptions\n\nEvery package has automatically access to a dictionary containing all user-specified options (see ../usage/submit).\n\nSuch options are made available in the attribute self.options. For example, let's assume that the user specified the following string at submission:\n\nfoo=1,bar=2\n\nThe analysis package selected will have access to these values:\n\nfrom lib.common.abstracts import Package\n\nclass Example(Package):\n\n    def start(self, path):\n        foo = self.options[\"foo\"]\n        bar = self.options[\"bar\"]\n\n    def check():\n        return True\n\n    def finish():\n        return True\n\nThese options can be used for anything you might need to configure inside your package.",
  "These options can be used for anything you might need to configure inside your package.\n\nPackage Configuration\n\nAnalysis packages can be \"configured\" before being started. Package configuration comes in two forms:\n\nPublic configuration\n\nPrivate configuration\n\nPublic configuration is stored within the analysis package class itself. Private configuration is stored externally, as data added to CAPE at runtime, separate from the CAPE Python code.\n\nPublic Package Configuration\n\nPublic package configuration is stored directly in the analysis package itself. This form of configuration is useful when configuring the host execution environment before the analysis is started.\n\nFor example, here is a alternative PDF package with lowered security settings:\n\nfrom lib.common.abstracts import Package\nfrom lib.common.exceptions import CuckooPackageError\nfrom lib.common.registry import *\n\n\nclass PDFLS(Package):\n    \"\"\"PDF analysis package, with lowered security settings.\"\"\"",
  "class PDFLS(Package):\n    \"\"\"PDF analysis package, with lowered security settings.\"\"\"\n\n    PATHS = [\n        (\"ProgramFiles\", \"Adobe\", \"Acrobat DC\", \"Acrobat\", \"Acrobat.exe\"),\n    ]\n\n    def __init__(self, options=None, config=None):\n        \"\"\"@param options: options dict.\"\"\"\n        if options is None:\n            options = {}\n        self.config = config\n        self.options = options\n        self.options[\"pdf\"] = \"1\"\n\n    def configure(self, target):\n        rootkey, subkey = \"HKEY_CURRENT_USER\", r\"SOFTWARE\\Adobe\\Adobe Acrobat\\DC\"\n        set_regkey(rootkey, fr\"{subkey}\\Privileged\", \"bProtectedMmode\", REG_DWORD, 0)\n        set_regkey(rootkey, fr\"{subkey}\\JSPrefs\", \"bEnableJS\", REG_DWORD, 1)\n        set_regkey(rootkey, fr\"{subkey}\\JSPrefs\", \"bEnableGlobalSecurity\", REG_DWORD, 0)\n\n    def start(self, path):\n        reader = self.get_path_glob(\"Acrobat.exe\")\n        return self.execute(reader, f'\"{path}\"', path)\n\nPrivate Package Configuration",
  "Private Package Configuration\n\nPrivate package configuration is stored outside the analysis package class, in a module under the same name as the analysis package. This is useful when managing configuration of package capabilities separately is desired, for privacy reasons or otherwise.\n\nFor example, here is a private package configuration for exe analysis that disables ASLR for the target being analyzed:\n\n# data/packages/exe.py\nimport lief\n\ndef configure(package, target):\n    # here \"package\" refers to modules.packages.exe.Exe\n    if package.options.get(\"disable-aslr\"):\n        pe_binary = lief.parse(target)\n        old_flags = pe_binary.optional.header.dll_characteristics\n        # unset DYNAMIC_BASE\n        new_flags = (old_flags & ~lief.PE.OptionalHeader.DLL_CHARACTERISTICS.DYNAMIC_BASE)\n        pe_binary.optional_header.dll_characteristics = new_flags\n        pe_binary.write(target)\n\nProcess API",
  "Process API\n\nThe Process class provides access to different process-related features and functions. You can import it into your analysis packages with:\n\nfrom lib.api.process import Process\n\nYou then initialize an instance with:\n\np = Process()\n\nIn case you want to open an existing process instead of creating a new one, you can specify multiple arguments:\n\npid: PID of the process you want to operate on.\n\nh_process: handle of a process you want to operate on.\n\nthread_id: thread ID of a process you want to operate on.\n\nh_thread: handle of the thread of a process you want to operate on.\n\nThis class implements several methods that you can use in your scripts.\n\nMethods\n\nProcess.open()\n\nOpens an handle to a running process. Returns True or False in case of success or failure of the operation.\n\nExample Usage:\n\np = Process(pid=1234)\np.open()\nhandle = p.h_process\n\nProcess.exit_code()",
  "Example Usage:\n\np = Process(pid=1234)\np.open()\nhandle = p.h_process\n\nProcess.exit_code()\n\nReturns the exit code of the opened process. If it wasn't already done before, exit_code() will perform a call to open() to acquire an handle to the process.\n\nExample Usage:\n\np = Process(pid=1234)\ncode = p.exit_code()\n\nProcess.is_alive()\n\nCalls exit_code() and verify if the returned code is STILL_ACTIVE, meaning that the given process is still running. Returns True or False.\n\nExample Usage:\n\np = Process(pid=1234)\nif p.is_alive():\n    print(\"Still running!\")\n\nProcess.get_parent_pid()\n\nReturns the PID of the parent process of the opened process. If it wasn't already done before, get_parent_pid() will perform a call to open() to acquire an handle to the process.\n\nExample Usage:\n\np = Process(pid=1234)\nppid = p.get_parent_pid()\n\nProcess.execute(path [, args=None[, suspended=False]])\n\nExecutes the file at the specified path. Returns True or False in case of success or failure of the operation.",
  "Example Usage:\n\np = Process()\np.execute(path=\"C:\\\\WINDOWS\\\\system32\\\\calc.exe\", args=\"Something\", suspended=True)\n\nProcess.resume()\n\nResumes the opened process from a suspended state. Returns True or False in case of success or failure of the operation.\n\nExample Usage:\n\np = Process()\np.execute(path=\"C:\\\\WINDOWS\\\\system32\\\\calc.exe\", args=\"Something\", suspended=True)\np.resume()\n\nProcess.terminate()\n\nTerminates the opened process. Returns True or False in case of success or failure of the operation.\n\nExample Usage:\n\np = Process(pid=1234)\nif p.terminate():\n    print(\"Process terminated!\")\nelse:\n    print(\"Could not terminate the process!\")\n\nProcess.inject([dll[, apc=False]])\n\nInjects a DLL (by default \"dll/capemon.dll\") into the opened process. Returns True or False in case of success or failure of the operation.\n\nExample Usage:\n\np = Process()\np.execute(path=\"C:\\\\WINDOWS\\\\system32\\\\calc.exe\", args=\"Something\", suspended=True)\np.inject()\np.resume()\n\nProcess.dump_memory()",
  "Process.dump_memory()\n\nTakes a snapshot of the given process' memory space. Returns True or False in case of success or failure of the operation.\n\nExample Usage:\n\np = Process(pid=1234)\np.dump_memory()",
  "Machinery Modules\n\nMachinery modules define how CAPE should interact with your virtualization software (or potentially even with physical disk imaging solutions). Since we decided to not enforce any particular vendor, from release 0.4 you can use your preferred solution and, in case it's not supported by default, write a custom Python module that defines how to make CAPE use it.\n\nEvery machinery module should be located inside modules/machinery/.\n\nA basic machinery module would look like this:\n\nfrom lib.cuckoo.common.abstracts import Machinery\nfrom lib.cuckoo.common.exceptions import CuckooMachineError\n\nclass MyMachinery(Machinery):\n    def start(self, label):\n        try:\n            revert(label)\n            start(label)\n        except SomethingBadHappens as e:\n            raise CuckooMachineError(\"OPS!\")\n\n    def stop(self, label):\n        try:\n            stop(label)\n        except SomethingBadHappens as e:\n            raise CuckooMachineError(\"OPS!\")",
  "The only requirements for Cuckoo are that:\n\nThe class inherits from Machinery.\n\nYou have a start() and stop() functions.\n\nYou raise CuckooMachineError when something fails.\n\nAs you understand, the machinery module is a core part of a CAPE setup, therefore make sure to spend enough time debugging your code and make it solid and resistant to any unexpected error.\n\nConfiguration\n\nEvery machinery module should come with a dedicated configuration file located in conf/<machinery module name>.conf. For example, for modules/machinery/kvm.py we have a conf/kvm.conf.\n\nThe configuration file should follow the default structure:\n\n[kvm]\n# Specify a comma-separated list of available machines to be used. For each\n# specified ID you have to define a dedicated section containing the details\n# on the respective machine. (E.g. cape1,cape2,cape3)\nmachines = cape1\n\n[cape1]\n# Specify the label name of the current machine as specified in your\n# libvirt configuration.\nlabel = cape1",
  "# Specify the operating system platform used by current machine\n# [windows/darwin/linux].\nplatform = windows\n\n# Specify the IP address of the current machine. Make sure that the IP address\n# is valid and that the host machine is able to reach it. If not, the analysis\n# will fail.\nip = 192.168.122.105\n\nThe main section is called [<name of the module>] with a machines field containing a comma-separated list of machines IDs.\n\nFor each machine, you should specify a label, a platform, and its ip.\n\nThese fields are required by CAPE to use the already embedded initialize() function that generates the list of available machines.\n\nIf you plan to change the configuration structure you should override the initialize() function (inside your module, no need to modify CAPE's core code). You can find its original code in the Machinery abstract inside lib/cuckoo/common/abstracts.py.\n\nLibVirt",
  "LibVirt\n\nStarting with Cuckoo 0.5 developing new machinery modules based on LibVirt is easy. Inside lib/cuckoo/common/abstracts.py you can find LibVirtMachinery that already provides all the functionality for a LibVirt module. Just inherit this base class and specify your connection string, as in the example below:\n\nfrom lib.cuckoo.common.abstracts import LibVirtMachinery\n\nclass MyMachinery(LibVirtMachinery):\n    # Set connection string.\n    dsn = \"my:///connection\"\n\nThis works for all the virtualization technologies supported by LibVirt. Just remember to check if your LibVirt package (if you are using one, for example from your Linux distribution) is compiled with the support for the technology you need.\n\nYou can check it with the following command:\n\n$ virsh -V\nVirsh command line tool of libvirt 0.9.13\nSee web site at http://libvirt.org/",
  "$ virsh -V\nVirsh command line tool of libvirt 0.9.13\nSee web site at http://libvirt.org/\n\nCompiled with support for:\n Hypervisors: QEmu/KVM LXC UML Xen OpenVZ VMWare Test\n Networking: Remote Daemon Network Bridging Interface Nwfilter VirtualPort\n Storage: Dir Disk Filesystem SCSI Multipath iSCSI LVM\n Miscellaneous: Nodedev AppArmor Secrets Debug Readline Modular\n\nIf you don't find your virtualization technology in the list of Hypervisors, you will need to recompile LibVirt with the specific support for the missing one.",
  "Processing Modules\n\nCAPE's processing modules are Python scripts that let you define custom ways to analyze the raw results generated by the sandbox and append some information to a global container that will be later used by the signatures and the reporting modules.\n\nYou can create as many modules as you want, as long as they follow a predefined structure that we will present in this chapter.\n\nGlobal Container\n\nAfter an analysis is completed, CAPE will invoke all the processing modules available in the modules/processing/ directory. Any additional module you decide to create must be placed inside that directory.\n\nEvery module should also have a dedicated section in the file conf/processing.conf: for example, if you create a module module/processing/foobar.py you will have to append the following section to conf/processing.conf:\n\n[foobar]\nenabled = on",
  "[foobar]\nenabled = on\n\nEvery module will then be initialized and executed and the data returned will be appended in a data structure that we'll call global container.\n\nThis container is simply just a big Python dictionary that includes the abstracted results produced by all the modules classified by their identification key.\n\nCAPE already provides a default set of modules that will generate a standard global container. It's important for the existing reporting modules (HTML report etc.) that these default modules are not modified, otherwise, the resulting global container structure would change and the reporting modules wouldn't be able to recognize it and extract the information used to build the final reports.\n\nGetting started\n\nTo make them available to CAPE, all processing modules must be placed inside the folder at modules/processing/.\n\nA basic processing module could look like this:\n\nfrom lib.cuckoo.common.abstracts import Processing\n\nclass MyModule(Processing):",
  "from lib.cuckoo.common.abstracts import Processing\n\nclass MyModule(Processing):\n\n    def run(self):\n        self.key = \"key\"\n        data = do_something()\n        return data\n\nYou can also specify an order value, which allows you to run the available processing modules in an ordered sequence. By default, all modules are set with an order value of 1 and are executed in alphabetical order.\n\nIf you want to change this value your module would look like this:\n\nfrom lib.cuckoo.common.abstracts import Processing\n\nclass MyModule(Processing):\n    order = 2\n\n    def run(self):\n        self.key = \"key\"\n        data = do_something()\n        return data\n\nYou can also manually disable a processing module by setting the enabled attribute to False:\n\nfrom lib.cuckoo.common.abstracts import Processing\n\nclass MyModule(Processing):\n    enabled = False\n\n    def run(self):\n        self.key = \"key\"\n        data = do_something()\n        return data",
  "def run(self):\n        self.key = \"key\"\n        data = do_something()\n        return data\n\nThe processing modules are provided with some attributes that can be used to access the raw results for the given analysis:\n\nself.analysis_path: path to the folder containing the results (e.g. storage/analysis/1)\n\nself.log_path: path to the analysis.log file.\n\nself.conf_path: path to the analysis.conf file.\n\nself.file_path: path to the analyzed file.\n\nself.dropped_path: path to the folder containing the dropped files.\n\nself.logs_path: path to the folder containing the raw behavioral logs.\n\nself.shots_path: path to the folder containing the screenshots.\n\nself.pcap_path: path to the network pcap dump.\n\nself.memory_path: path to the full memory dump, if created.\n\nself.pmemory_path: path to the process memory dumps, if created.\n\nWith these attributes, you should be able to easily access all the raw results stored by CAPE and perform your analytic operations on them.",
  "As a last note, a good practice is to use the CuckooProcessingError exception whenever the module encounters an issue you want to report to CAPE. This can be done by importing the class like this:\n\nfrom lib.cuckoo.common.exceptions import CuckooProcessingError\nfrom lib.cuckoo.common.abstracts import Processing\n\nclass MyModule(Processing):\n\n    def run(self):\n        self.key = \"key\"\n\n        try:\n            data = do_something()\n        except SomethingFailed:\n            raise CuckooProcessingError(\"Failed\")\n\n        return data",
  "Signatures\n\nBy taking advantage of CAPE's customizability, you can write signatures which will then by run against analysis results. These signatures can be used to identify a predefined pattern that represents a malicious behavior or an indicator that you're interested in.\n\nThese signatures are very useful to give context to the analyses. They simplify the interpretation of the results and assist with automatically identifying malware samples of interest.\n\nYou can find signatures created by the CAPE administrators and other CAPE users on the Community repository.\n\nGetting Started\n\nCreating a signature is a very simple process but requires a decent understanding of Python programming.\n\nFirst things first, all signatures must be located inside the modules/signatures/ directory.\n\nThe following is a basic example signature:\n\nfrom lib.cuckoo.common.abstracts import Signature",
  "The following is a basic example signature:\n\nfrom lib.cuckoo.common.abstracts import Signature\n\nclass CreatesExe(Signature):\n    name = \"creates_exe\"\n    description = \"Creates a Windows executable on the filesystem\"\n    severity = 2\n    categories = [\"generic\"]\n    authors = [\"CAPE Developers\"]\n    minimum = \"0.5\"\n\n    def run(self):\n        return self.check_file(pattern=\".*\\\\.exe$\",\n                               regex=True)\n\nAs you can see the structure of the signature is really simple and consistent with the other CAPE modules. Note that on line 12 a helper function is used. These helper functions assist with signature-writing and we highly recommend becoming familiar with what helper functions are available to you (found in the [Signature class](https://github.com/kevoreilly/CAPEv2/blob/master/lib/cuckoo/common/abstracts.py)) before you start writing signatures. Some documentation for Helpers can be found below.",
  "In the example above, the helper function is used to walk through all of the accessed files in the summary and check if there are any files ending with \"*.exe*\". If there is at least one, then the helper function will return True; otherwise it will return False. When a signature returns True, that means that the signature matched.\n\nIf the signature matches, a new entry in the \"signatures\" section will be added to the global container self.results as follows:\n\n\"signatures\": [\n    {\n        \"severity\": 2,\n        \"description\": \"Creates a Windows executable on the filesystem\",\n        \"alert\": false,\n        \"references\": [],\n        \"data\": [\n            {\n                \"file_name\": \"C:\\\\d.exe\"\n            }\n        ],\n        \"name\": \"creates_exe\"\n    }\n]\n\nWe could rewrite the exact same signature by accessing the global container directly, rather than through the helper function `check_file`:\n\nfrom lib.cuckoo.common.abstracts import Signature",
  "from lib.cuckoo.common.abstracts import Signature\n\nclass CreatesExe(Signature):\n    name = \"creates_exe\"\n    description = \"Creates a Windows executable on the filesystem\"\n    severity = 2\n    categories = [\"generic\"]\n    authors = [\"Cuckoo Developers\"]\n    minimum = \"0.5\"\n\n    def run(self):\n        for file_path in self.results[\"behavior\"][\"summary\"][\"files\"]:\n            if file_path.endswith(\".exe\"):\n                return True\n\n        return False\n\nIf you access the global container directly, you must know its structure, which can be observed in the JSON report of your analyses.\n\nCreating your new signature\n\nTo help you better understand the process of creating a signature, we are going to create a very simple one together and walk through the steps and the available options. For this purpose, we're going to create a signature that checks whether the malware analyzed opens a mutex named \"i_am_a_malware\".",
  "The first thing to do is to import the dependencies, create a skeleton, and define some initial attributes. These are the attributes that you can currently set:\n\nname: an identifier for the signature.\n\ndescription: a brief description of what the signature represents.\n\nseverity: a number identifying the severity of the events matched (generally between 1 and 3).\n\nconfidence: a number between 1 and 100 that represents how confident the signature writer is that this signature will not be raised as a false positive.\n\nweight: a number used for calculating the malscore of a submission. This attribute acts as a multiplier of the product of severity and confidence.\n\ncategories: a list of categories that describe the type of event being matched (for example \"*banker*\", \"*injection*\" or \"*anti-vm*\"). For a list of all categories, see Categories.\n\nfamilies: a list of malware family names, in case the signature specifically matches a known one.",
  "families: a list of malware family names, in case the signature specifically matches a known one.\n\nauthors: a list of people who authored the signature.\n\nreferences: a list of references (URLs) to give context to the signature.\n\nenabled: if set to False the signature will be skipped.\n\nalert: if set to True can be used to specify that the signature should be reported (perhaps by a dedicated reporting module).\n\nminimum: the minimum required version of CAPE to successfully run this signature.\n\nmaximum: the maximum required version of CAPE to successfully run this signature.\n\nttps: a list of MITRE ATT&CK IDs applicable to this signature.\n\nmbcs: a list of MITRE Malware Behavior Catalog IDs applicable to this signature.\n\nIn our example, we will create the following skeleton:\n\nfrom lib.cuckoo.common.abstracts import Signature",
  "from lib.cuckoo.common.abstracts import Signature\n\nclass BadBadMalware(Signature): # We initialize the class by inheriting Signature.\n    name = \"badbadmalware\" # We define the name of the signature\n    description = \"Creates a mutex known to be associated with Win32.BadBadMalware\" # We provide a description\n    severity = 3 # We set the severity to maximum\n    categories = [\"trojan\"] # We add a category\n    families = [\"badbadmalware\"] # We add the name of our fictional malware family\n    authors = [\"Me\"] # We specify the author\n    minimum = \"0.5\" # We specify that in order to run the signature, the user will need at least CAPE 0.5\n\ndef run(self):\n    return\n\nThis is a perfectly valid signature. It doesn't do anything yet, so now we need to define the conditions for the signature to be matched.\n\nSince we want to match a particular mutex name, we use the helper function `check_mutex`:\n\nfrom lib.cuckoo.common.abstracts import Signature",
  "from lib.cuckoo.common.abstracts import Signature\n\nclass BadBadMalware(Signature):\n    name = \"badbadmalware\"\n    description = \"Creates a mutex known to be associated with Win32.BadBadMalware\"\n    severity = 3\n    categories = [\"trojan\"]\n    families = [\"badbadmalware\"]\n    authors = [\"Me\"]\n    minimum = \"0.5\"\n\ndef run(self):\n    return self.check_mutex(\"i_am_a_malware\")\n\nIt's as simple as that! Now our signature will return True if the analyzed malware was observed opening the specified mutex.\n\nIf you want to be more explicit and directly access the global container, you could translate the previous signature in the following way:\n\nfrom lib.cuckoo.common.abstracts import Signature\n\nclass BadBadMalware(Signature):\n    name = \"badbadmalware\"\n    description = \"Creates a mutex known to be associated with Win32.BadBadMalware\"\n    severity = 3\n    categories = [\"trojan\"]\n    families = [\"badbadmalware\"]\n    authors = [\"Me\"]\n    minimum = \"0.5\"",
  "def run(self):\n    for mutex in self.results[\"behavior\"][\"summary\"][\"mutexes\"]:\n        if mutex == \"i_am_a_malware\":\n            return True\n\n    return False\n\nEvented Signatures\n\nSince version 1.0, CAPE provides a way to write more high-performance signatures. In the past, every signature was required to loop through the whole collection of API calls collected during the analysis. This was necessarily causing some performance issues when such a collection would be large.\n\nCAPE now supports both the old model as well as what we call \"evented signatures\". The main difference is that with this new format, all the signatures will be executed in parallel and a callback function called on_call() will be invoked for each signature within one single loop through the collection of API calls.\n\nAn example signature using this technique is the following:\n\nfrom lib.cuckoo.common.abstracts import Signature",
  "from lib.cuckoo.common.abstracts import Signature\n\nclass SystemMetrics(Signature):\n    name = \"generic_metrics\"\n    description = \"Uses GetSystemMetrics\"\n    severity = 2\n    categories = [\"generic\"]\n    authors = [\"CAPE Developers\"]\n    minimum = \"1.0\"\n\n    # Evented signatures need to implement the \"on_call\" method\n    evented = True\n\n    # Evented signatures can specify filters that reduce the amount of\n    # API calls that are streamed in. One can filter Process name, API\n    # name/identifier and category. These should be sets for faster lookup.\n    filter_processnames = set()\n    filter_apinames = set([\"GetSystemMetrics\"])\n    filter_categories = set()\n\n    # This is a signature template. It should be used as a skeleton for\n    # creating custom signatures, therefore is disabled by default.\n    # The on_call function is used in \"evented\" signatures.\n    # These use a more efficient way of processing logged API calls.\n    enabled = False",
  "def stop(self):\n        # In the stop method one can implement any cleanup code and\n        #  decide one last time if this signature matches or not.\n        #  Return True in case it matches.\n        return False\n\n    # This method will be called for every logged API call by the loop\n    # in the RunSignatures plugin. The return value determines the \"state\"\n    # of this signature. True means the signature matched and False means\n    # it can't match anymore. Both of which stop streaming in API calls.\n    # Returning None keeps the signature active and will continue.\n    def on_call(self, call, process):\n        # This check would in reality not be needed as we already make use\n        # of filter_apinames above.\n        if call[\"api\"] == \"GetSystemMetrics\":\n            # Signature matched, return True.\n            return True\n\n        # continue\n        return None",
  "# continue\n        return None\n\nThe inline comments are already self-explanatory. You can find many more examples of both evented and traditional signatures in our community repository.\n\nMatches\n\nStarting from version 1.2, signatures can log exactly what triggered the signature. This allows users to better understand why this signature is present in the log, and to be able to better focus malware analysis.\n\nTwo helpers have been included to specify matching data.\n\nSignature.add_match(process, type, match)\n\nAdds a match to the signature. Can be called several times for the same signature.\n\nExample Usage, with a single element:\n\nself.add_match(None, \"url\", \"http://malicious_url_detected.com\")\n\nExample Usage, with a more complex signature, needing several API calls to be triggered:\n\nself.signs = []\nself.signs.append(first_api_call)\nself.signs.append(second_api_call)\nself.add_match(process, 'api', self.signs)\n\nSignature.has_matches()",
  "Signature.has_matches()\n\nChecks whether the current signature has any matching data registered. Returns True in case it does, otherwise returns False.\n\nThis can be used to easily add several matches for the same signature. If you want to do so, make sure that all the api calls are scanned by making sure that on_call never returns True. Then, use on_complete with has_matches so that the signature is triggered if any match was previously added.\n\nExample Usage, from the network_tor signature:\n\ndef on_call(self, call, process):\n    if self.check_argument_call(call,\n                                pattern=\"Tor Win32 Service\",\n                                api=\"CreateServiceA\",\n                                category=\"services\"):\n        self.add_match(process, \"api\", call)\n\ndef on_complete(self):\n    return self.has_matches()\n\nHelpers",
  "def on_complete(self):\n    return self.has_matches()\n\nHelpers\n\nAs anticipated, from version 0.5 the Signature base class also provides some helper methods that simplify the creation of signatures and avoid the need for you having to access the global container directly (at least most of the times).\n\nFollowing is a list of available methods.\n\nSignature.check_file(pattern[, regex=False])\n\nChecks whether the malware opened or created a file matching the specified pattern. Returns True in case it did, otherwise returns False.\n\nExample Usage:\n\nself.check_file(pattern=\".*\\.exe$\", regex=True)\n\nSignature.check_key(pattern[, regex=False])\n\nChecks whether the malware opened or created a registry key matching the specified pattern. Returns True in case it did, otherwise returns False.\n\nExample Usage:\n\nself.check_key(pattern=\".*CurrentVersion\\\\Run$\", regex=True)\n\nSignature.check_mutex(pattern[, regex=False])",
  "Signature.check_mutex(pattern[, regex=False])\n\nChecks whether the malware opened or created a mutex matching the specified pattern. Returns True in case it did, otherwise returns False.\n\nExample Usage:\n\nself.check_mutex(\"mutex_name\")\n\nSignature.check_api(pattern[, process=None[, regex=False]])\n\nChecks whether Windows function was invoked. Returns True in case it was, otherwise returns False.\n\nExample Usage:\n\nself.check_api(pattern=\"URLDownloadToFileW\", process=\"AcroRd32.exe\")\n\nSignature.check_argument(pattern[, name=Name[, api=None[, category=None[, process=None[, regex=False]]]])\n\nChecks whether the malware invoked a function with a specific argument value. Returns True in case it did, otherwise returns False.\n\nExample Usage:\n\nself.check_argument(pattern=\".*CAPE.*\", category=\"filesystem\", regex=True)\n\nSignature.check_ip(pattern[, regex=False])\n\nChecks whether the malware contacted the specified IP address. Returns True in case it did, otherwise returns False.\n\nExample Usage:",
  "Example Usage:\n\nself.check_ip(\"123.123.123.123\")\n\nSignature.check_domain(pattern[, regex=False])\n\nChecks whether the malware contacted the specified domain. Returns True in case it did, otherwise returns False.\n\nExample Usage:\n\nself.check_domain(pattern=\".*capesandbox.com$\", regex=True)\n\nSignature.check_url(pattern[, regex=False])\n\nChecks whether the malware performed an HTTP request to the specified URL. Returns True in case it did, otherwise returns False.\n\nExample Usage:\n\nself.check_url(pattern=\"^.+\\/load\\.php\\?file=[0-9a-zA-Z]+$\", regex=True)\n\nCategories\n\nYou can put signatures into categories to facilitate grouping or sorting. You can create your own category if you wish, but it is easier for other users if you associate a signature with a category that already exists. Here is a list of all categories available:\n\n`account`: Adds or manipulates an administrative user account.\n\n`anti-analysis`: Constructed to conceal or obfuscate itself to prevent analysis.",
  "`anti-analysis`: Constructed to conceal or obfuscate itself to prevent analysis.\n\n`anti-av`: Attempts to conceal itself from detection by antivirus.\n\n`anti-debug`: Attempts to detect if it is being debugged.\n\n`anti-emulation`: Detects the presence of an emulator.\n\n`anti-sandbox`: Attempts to detect if it is in a sandbox.\n\n`anti-vm`: Attempts to detect if it is being run in virtualized environment.\n\n`antivirus`: Antivirus hit. File is infected.\n\n`banker`: Designed to gain access to confidential information stored or processed through online banking.\n\n`bootkit`: Manipulates machine configurations that would affect the boot of the machine.\n\n`bot`: Appears to be a bot or exhibits bot-like behaviour.\n\n`browser`: Manipulates browser-settings in a suspicious way.\n\n`bypass`: Attempts to bypass operating systems security controls (firewall, amsi, applocker, UAC, etc.)\n\n`c2`: Communicates with a server controlled by a malicious actor.",
  "`c2`: Communicates with a server controlled by a malicious actor.\n\n`clickfraud`: Manipulates browser settings to allow for insecure clicking.\n\n`command`: A suspicious command was observed.\n\n`credential_access`: Uses techniques to access credentials.\n\n`credential_dumping`: Uses techniques to dump credentials.\n\n`cryptomining`: Facilitates mining of cryptocurrency.\n\n`discovery`: Uses techniques for discovery information about the system, the user, or the environment.\n\n`dns`: Uses suspicious DNS queries.\n\n`dotnet`: .NET code is used in a suspicious manner.\n\n`downloader`: Trojan that downloads installs files.\n\n`dropper`: Trojan that drops additional malware on an affected system.\n\n`encryption`: Encryption algorithms are used for obfuscating data.\n\n`evasion`: Techniques are used to avoid detection.\n\n`execution`: Uses techniques to execute harmful code or create executables that could run harmful code.\n\n`exploit`: Exploits an known software vulnerability or security flaw.",
  "`exploit`: Exploits an known software vulnerability or security flaw.\n\n`exploit_kit`: Programs designed to crack or break computer and network security measures.\n\n`generic`: Basic operating system objects are used in suspicious ways.\n\n`infostealer`: Collects and disseminates information such as login details, usernames, passwords, etc.\n\n`injection`: Input is not properly validated and gets processed by an interpreter as part of a command or query.\n\n`keylogger`: Monitoring software detected.\n\n`lateral`: Techniques used to move through environment and maintain access.\n\n`loader`: Download and execute additional payloads on compromised machines.\n\n`locker`: Prevents access to system data and files.\n\n`macro`: A set of commands that automates a software to perform a certain action, found in Office macros.\n\n`malware`: The file uses techniques associated with malicious software.\n\n`martians`: Command shell or script process was created by unexpected parent process.",
  "`martians`: Command shell or script process was created by unexpected parent process.\n\n`masquerading`: The name or location of an object is manipulated to evade defenses and observation.\n\n`network`: Suspicious network traffic was observed.\n\n`office`: Makes API calls not consistent with expected/standard behaviour.\n\n`packer`: Compresses, encrypts, and/or modifies a malicious file's format.\n\n`persistence`: Technique used to maintain presence in system(s) across interruptions that could cut off access.\n\n`phishing`: Techniques were observed that attempted to obtain information from the user.\n\n`ransomware`: Designed to block access to a system until a sum of money is paid.\n\n`rat`: Designed to provide the capability of covert surveillance and/or unauthorized access to a target.\n\n`rootkit`: Designed to provide continued privileged access to a system while actively hiding its presence.\n\n`static`: A suspicious characteristic was discovered during static analysis.",
  "`static`: A suspicious characteristic was discovered during static analysis.\n\n`stealth`: Leverages/modifies internal processes and settings to conceal itself.\n\n`trojan`: Presents itself as legitimate in attempt to infiltrate a system.\n\n`virus`: Malicious software program.\n\nTroubleshooting\n\nNo signatures\n\nWhenever you submit a sample for analysis, when it finishes you should be able to inspect the identified signatures. If you see the No signatures message, you might need to download or update them. Example from the web interface:\n\nimage\n\nIf no signatures are showing when executing a given report, you must use the utils/community.py tool so as to download them:\n\n$ sudo -u cape poetry run python3 utils/community.py -waf\n\nIf the execution of the script does not end successfully, make sure you solve it. For example:",
  "If the execution of the script does not end successfully, make sure you solve it. For example:\n\nInstalling REPORTING\nFile \"/opt/CAPEv2/modules/reporting/__init__.py\" installed\nFile \"/opt/CAPEv2/modules/reporting/elasticsearchdb.py\" installed\nTraceback (most recent call last):\n  File \"/opt/CAPEv2/utils/community.py\", line 257, in <module>\n    main()\n  File \"/opt/CAPEv2/utils/community.py\", line 252, in main\n    install(enabled, args.force, args.rewrite, args.file, args.token)\n  File \"/opt/CAPEv2/utils/community.py\", line 180, in install\n    open(filepath, \"wb\").write(t.extractfile(member).read())\nPermissionError: [Errno 13] Permission denied: '/opt/CAPEv2/modules/reporting/elasticsearchdb.py'\n\nhappened because elasticsearchdb.py did not belong to cape:cape but to root:root.\n\nAfter chowning it to cape:cape, the script finished successfully. You should now see in the report page something similar to this:\n\nimage\n\nErrors/warnings in the logs",
  "image\n\nErrors/warnings in the logs\n\nIf you ever face errors or warnings in the logs related to the signatures module (like Signature spawns_dev_util crashing after update)), chances are high you must update the signatures you are working with. To do so, just run the community` utility like so:\n\n$ sudo -u cape poetry run python3 community.py -waf -cr",
  "Development\n\nThis chapter explains how to write CAPE's code and how to contribute.\n\ndevelopment_notes code_style current_module_improvement",
  "Development examples\n\nCurtain\n\nfrom modules.processing.curtain import deobfuscate\nblob = \"\"\"here\"\"\"\nprint(deobfuscate(blob))\n\nSuricata name detection\n\nimport os, sys\nCUCKOO_ROOT = os.path.join(os.path.abspath(os.path.dirname(__file__)), \"..\")\nsys.path.append(CUCKOO_ROOT)\n\nfrom lib.cuckoo.common.suricata_detection import get_suricata_family\n# Signature example: \"ET MALWARE Sharik/Smoke CnC Beacon 11\"\nprint(get_suricata_family(signature_string))",
  "Development Notes\n\nGit branches\n\nCAPE Sandbox source code is available in our official git repository.\n\nUp until version 1.0, we used to coordinate all ongoing development in a dedicated \"development\" branch and we've been exclusively merging pull requests in such branch. Since version 1.1 we moved development to the traditional \"master\" branch and we make use of GitHub's tags and release system to reference development milestones in time.\n\nRelease Versioning\n\nCAPE releases are named using three numbers separated by dots, such as 1.2.3, where the first number is the release, the second number is the major version, and the third number is the bugfix version. The testing stage from git ends with \"-beta\" and the development stage with \"-dev\".\n\nWarning",
  "Warning\n\nIf you are using a \"beta\" or \"dev\" stage, please consider that it's not meant to be an official release, therefore we don't guarantee its functioning and we don't generally provide support. If you think you encountered a bug there, make sure that the nature of the problem is not related to your misconfiguration and collect all the details to be notified to our developers. Make sure to specify which exact version you are using, eventually with your current git commit id.\n\nTicketing system\n\nTo submit bug reports or feature requests, please use GitHub's Issue tracking system.\n\nContribute\n\nTo submit your patch just create a Pull Request from your GitHub fork. If you don't know how to create a Pull Request take a look at GitHub help.",
  "Coding Style\n\nTo contribute code to the project, you must diligently follow the style rules describe in this chapter. Having a clean and structured code is very important for our development lifecycle, and not compliant code will most likely be rejected.\n\nEssentially CAPE's code style is based on PEP 8 - Style Guide for Python Code and PEP 257 -- Docstring Conventions.\n\nFormatting\n\nCopyright header\n\nAll source code files must start with the following copyright header:\n\n# Copyright (C) 2010-2015  X.\n# This file is part of CAPE Sandbox - https://capesandbox.com\n# See the file 'docs/LICENSE' for copying permission.\n\nIndentation\n\nThe code must have a 4-spaces-tabs indentation. Since Python enforces the indentation, make sure to configure your editor properly or your code might cause malfunctioning.\n\nMaximum Line Length\n\nLimit all lines to a maximum of 132 characters.\n\nBlank Lines",
  "Maximum Line Length\n\nLimit all lines to a maximum of 132 characters.\n\nBlank Lines\n\nSeparate the class definition and the top-level function with one blank line. Methods definitions inside a class are separated by a single blank line:\n\nclass MyClass:\n    \"\"\"Doing something.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize\"\"\"\n        pass\n\n    def do_it(self, what):\n        \"\"\"Do it.\n        @param what: do what.\n        \"\"\"\n        pass\n\nUse blank lines in functions, sparingly, to isolate logic sections. Import blocks are separated by a single blank line, import blocks are separated from classes by one blank line.\n\nImports\n\nImports must be on separate lines. If you're importing multiple objects from a package, use a single line:\n\nfrom lib import a, b, c\n\nNOT:\n\nfrom lib import a\nfrom lib import b\nfrom lib import c\n\nAlways specify explicitly the objects to import:\n\nfrom lib import a, b, c\n\nNOT:\n\nfrom lib import *\n\nStrings\n\nStrings must be delimited by double quotes (\").",
  "NOT:\n\nfrom lib import *\n\nStrings\n\nStrings must be delimited by double quotes (\").\n\nPrinting and Logging\n\nWe discourage the use of print(): if you need to log an event please use Python's logging which is already initialized by CAPE.\n\nIn your module add:\n\nimport logging\nlog = logging.getLogger(__name__)\n\nAnd use the log handle, for more details refer to the Python documentation.\n\nIn case you need to print a string to standard output, use the print() function:\n\nprint(\"foo\")\n\nNOT the statement:\n\nprint \"foo\"\n\nChecking for keys in data structures\n\nWhen checking for a key in a data structure, use the clause \"in\" for example:\n\nif \"bar\" in foo:\n    do_something(foo[\"bar\"])\n\nExceptions\n\nCustom exceptions must be defined in the lib/cuckoo/common/exceptions.py file or the local module if the exception should not be global.\n\nThe following is the current CAPE exceptions chain:",
  "The following is the current CAPE exceptions chain:\n\n.-- CuckooCriticalError\n|   |-- CuckooStartupError\n|   |-- CuckooDatabaseError\n|   |-- CuckooMachineError\n|   `-- CuckooDependencyError\n|-- CuckooOperationalError\n|   |-- CuckooAnalysisError\n|   |-- CuckooProcessingError\n|   `-- CuckooReportError\n`-- CuckooGuestError\n\nBeware that the use of CuckooCriticalError and its child exceptions will cause CAPE to terminate.\n\nNaming\n\nCustom exception names must start with \"Cuckoo\" and end with \"Error\" if it represents an unexpected malfunction.\n\nException handling\n\nWhen catching an exception and accessing its handle, use as e:\n\ntry:\n    foo()\nexcept Exception as e:\n    bar()\n\nNOT:\n\ntry:\n    foo()\nexcept Exception, something:\n    bar()\n\nIt's a good practice to use \"e\" instead of \"e.message\".\n\nDocumentation\n\nAll code must be documented in docstring format, see PEP 257 -- Docstring Conventions. Additional comments may be added in logical blocks to make the code easier to understand.",
  "Automated testing\n\nWe believe in automated testing to provide high-quality code and avoid dumb bugs. When possible, all code must be committed with proper unit tests. Particular attention must be placed when fixing bugs: it's good practice to write unit tests to reproduce the bug. All unit tests and fixtures are placed in the tests folder in the CAPE root. We adopted pytest as the unit testing framework.\n\nGithub actions\n\nAutomated tests run as github actions ; see the .github directory.\n\nYou may wish to run github actions locally. A tool that may help is Nektos act. One of the installation options for act is as a plugin for the github CLI, and the actions are then triggered by gh act.\n\nAs input for act it's often helpful to create a simulated github event, and save it as an input file.\n\nExample:\n\n{\n  \"act\": true,\n  \"repository\" : {\n    \"default_branch\": \"master\"\n  }\n}\n\nSo to run the actions that normally are triggered by a push event:",
  "So to run the actions that normally are triggered by a push event:\n\ngh act -s GITHUB_TOKEN=\"$(gh auth token)\" --eventpath /tmp/github-event.json\n\nand to run the actions that are scheduled:\n\ngh act schedule -s GITHUB_TOKEN=\"$(gh auth token)\" --eventpath /tmp/github-event.json\n\nWe created a file .actrc containing --env CAPE_AS_ROOT=1 because act runs the tests as root, and otherwise the tests would exit saying you cannot run CAPE as root.\n\nPoetry and pre-commit hooks\n\nAfter cloning the git repository, the first commands that you should do:\n\npoetry install\npoetry run pre-commit install\n\nThis will install the pre-commit hooks, ensuring that all files have to conform to black and isort.",
  "FAQ\n\nFrequently Asked Questions:\n\nanalyze_urls\n\nesxi_reqs\n\ntroubles_upgrade\n\ntroubles_problem\n\nGeneral Questions\n\nCan I analyze URLs with CAPE?\n\nYes you can. But modern browsers has a lot of problems\n\nWhat I need to use CAPE with VMware ESXi?\n\nTo run with VMware vSphere Hypervisor (or ESXi) CAPE levareges on libvirt. Libivirt is currently using VMware API to take control over virtual machines, although these API are available ony in licensed version. In VMware vSphere free edition, these API are read only, so you are unable to use CAPE with it. For the minimum license needed, please have a look at VMware website.\n\nTroubleshooting\n\nAfter upgrade CAPE stops to work\n\nProbably you upgraded it in a wrong way. It's not a good practice to rewrite the files due to CAPE's complexity and quick evolution.\n\nPlease follow the upgrade steps described in ../installation/upgrade.\n\nCAPE stumbles and produces some error I don't understand",
  "CAPE stumbles and produces some error I don't understand\n\nCAPE is a young and still evolving project, it's possible that you encounter some problems while running it, but before you rush into sending emails to everyone make sure you read what follows.\n\nCAPE is not meant to be a point-and-click tool: it's designed to be a highly customizable and configurable solution for somewhat experienced users and malware analysts.\n\nIt requires you to have a decent understanding of your operating systems, Python, the concepts behind virtualization and sandboxing. We try to make it as easy to use as possible, but you have to keep in mind that it's not a technology meant to be accessible to just anyone.\n\nThat being said, if a problem occurs you have to make sure that you did everything you could before asking for time and effort from our developers and users. We just can't help everyone, we have limited time and it has to be dedicated to the development and fixing of actual bugs.",
  "We have extensive documentation, read it carefully. You can't just skip parts of it.\n\nWe have a mailing list archive, search through it for previous threads where your same problem could have been already addressed and solved.\n\nWe have a Community platform for asking questions, use it.\n\nWe have lot of users producing content on Internet, Google it.\n\nSpend some of your own time trying fixing the issues before asking ours, you might even get to learn and understand CAPE better.\n\nLong story short: use the existing resources, put some efforts into it and don't abuse people.\n\nIf you still can't figure out your problem, you can ask help on our online communities (see ../finalremarks/index). Make sure when you ask for help to:\n\nUse a clear and explicit title for your emails: \"I have a problem\", \"Help me\" or \"CAPE error\" are NOT good titles.\n\nExplain in details what you're experiencing. Try to reproduce several times your issue and write down all steps to achieve that.",
  "Use no-paste services and link your logs, configuration files and details on your setup.\n\nEventually provide a copy of the analysis that generated the problem.\n\nCheck and restore current snapshot with KVM\n\nIf something goes wrong with virtual machine it's best practice to check current snapshot status. You can do that with the following:\n\n$ virsh snapshot-current \"<Name of VM>\"\n\nIf you got a long XML as output your current snapshot is configured and you can skip the rest of this chapter; anyway if you got an error like the following your current snapshot is broken:\n\n$ virsh snapshot-current \"<Name of VM>\"\nerror: domain '<Name of VM>' has no current snapshot\n\nTo fix and create a current snapshot first list all machine's snapshots:\n\n$ virsh snapshot-list \"<Name of VM>\"\n Name                 Creation Time             State\n ------------------------------------------------------------\n 1339506531           2012-06-12 15:08:51 +0200 running\n\nChoose one snapshot name and set it as current:",
  "Choose one snapshot name and set it as current:\n\n$ snapshot-current \"<Name of VM>\" --snapshotname 1339506531\nSnapshot 1339506531 set as current\n\nNow the virtual machine state is fixed.\n\nCheck and restore current snapshot with VirtualBox\n\nIf something goes wrong with virtual it's best practice to check the virtual machine status and the current snapshot. First of all check the virtual machine status with the following:\n\n$ VBoxManage showvminfo \"<Name of VM>\" | grep State\nState:           powered off (since 2012-06-27T22:03:57.000000000)\n\nIf the state is \"powered off\" you can go ahead with the next check, if the state is \"aborted\" or something else you have to restore it to \"powered off\" before:\n\n$ VBoxManage controlvm \"<Name of VM>\" poweroff\n\nWith the following check the current snapshots state:\n\n$ VBoxManage snapshot \"<Name of VM>\" list --details\n   Name: s1 (UUID: 90828a77-72f4-4a5e-b9d3-bb1fdd4cef5f)\n      Name: s2 (UUID: 97838e37-9ca4-4194-a041-5e9a40d6c205) *",
  "If you have a snapshot marked with a star \"*\" your snapshot is ready, anyway you have to restore the current snapshot:\n\n$ VBoxManage snapshot \"<Name of VM>\" restorecurrent\n\nUnable to bind result server error\n\nAt CAPE startup if you get an error message like this one:\n\n2014-01-07 18:42:12,686 [root] CRITICAL: CuckooCriticalError: Unable to bind result server on 192.168.56.1:2042: [Errno 99] Cannot assign requested address\n\nIt means that CAPE is unable to start the result server on the IP address written in cuckoo.conf (or in machinery_conf if you are using the resultserver_ip option inside). This usually happen when you start CAPE without bringing up the virtual interface associated with the result server IP address. You can bring it up manually, it depends from one virtualization software to another, but if you don't know how to do, a good trick is to manually start and stop an analysis virtual machine, this will bring virtual networking up.",
  "Introduction\n\nThis is an introductory chapter to CAPE Sandbox. It explains some basic malware analysis concepts, what CAPE is, and how it can fit into malware analysis.\n\nsandboxing what license",
  "Sandboxing\n\nAs defined by Wikipedia, \"*in computer security, a sandbox is a security mechanism for separating running programs. It is often used to execute untested code, or untrusted programs from unverified third-parties, suppliers, untrusted users and untrusted websites.*\".\n\nThis concept applies to malware analysis' sandboxing too: our goal is to run an unknown and untrusted application or file inside an isolated environment and get information about what the file does.\n\nMalware sandboxing is a practical application of the dynamical analysis approach: instead of statically analyzing the binary file, it gets executed and monitored in real-time.\n\nThis approach obviously has pros and cons, but it's a valuable technique to obtain additional details on the malware, such as its network behavior. Therefore it's a good practice to perform both static and dynamic analysis while inspecting a malware, to gain a deeper understanding of it.",
  "Simple as it is, CAPE is a tool that allows you to perform sandboxed malware analysis.\n\nUsing a Sandbox\n\nBefore starting to install, configure and use CAPE, you should take some time to think about what you want to achieve with it and how.\n\nSome questions you should ask yourself:\n\nWhat kind of files do I want to analyze?\n\nWhat volume of analyses do I want to be able to handle?\n\nWhich platform do I want to use to run my analysis?\n\nWhat kind of information do I want about the file?\n\nThe creation of the isolated environment (the virtual machine) is probably the most critical and important part of a sandbox deployment: it should be done carefully and with proper planning.\n\nBefore getting your hands on the virtualization product of your choice, you should already have a design plan that defines:\n\nWhich operating system, language, and patching level to use.\n\nWhich software to install and which versions (particularly important when analyzing exploits).",
  "Which software to install and which versions (particularly important when analyzing exploits).\n\nConsider that automated malware analysis is not deterministic and its success might depend on a trillion of factors: you are trying to make a malware run in a virtualized system as it would do on a native one, which could be tricky to achieve and may not always succeed. Your goal should be both to create a system able to handle all the requirements you need as well as try to make it as realistic as possible.\n\nFor example, you could consider leaving some intentional traces of normal usage, such as browsing history, cookies, documents, images, etc. If a malware sample is designed to operate, manipulate or steal such files you'll be able to notice it.",
  "Virtualized operating systems usually carry a lot of traces with them which makes them very easily detectable. Even if you shouldn't overestimate this problem, you might want to take care of this and try to hide as many virtualization traces as possible. There is a lot of literature on the Internet regarding virtualization detection techniques and countermeasures.\n\nOnce you finished designing and preparing the prototype of the system you want, you can proceed with creating and deploying it. You will be always in time to change things or slightly fix them, but remember that good planning at the beginning always means fewer troubles in the long run.",
  "License\n\nCuckoo/CAPE Sandbox license is shipped with Cuckoo/CAPE and contained in the \"LICENSE\" file under the base project directory.\n\nDisclaimer\n\nCuckoo/CAPE is distributed as it is, in the hope that it will be useful, but without any warranty nor the implied merchantability or fitness for a particular purpose.\n\nWhatever you do with this tool is uniquely your own responsibility.\n\nCuckoo Foundation\n\nThe Cuckoo Foundation is a non-profit organization incorporated as a Stichting in the Netherlands and it's mainly dedicated to support of the development and growth of Cuckoo Sandbox, an open source malware analysis system, and the surrounding projects and initiatives.\n\nThe Foundation operates to secure financial and infrastructure support for our software projects and coordinates the development and contributions from the community.",
  "What is CAPE?\n\nCAPE is an open-source malware sandbox.\n\nA sandbox is used to execute malicious files in an isolated enviornment whilst instrumenting their dynamic behaviour and collecting forensic artefacts.\n\nCAPE was derived from Cuckoo v1 which features the following core capabilities on the Windows platform:\n\nBehavioral instrumentation based on API hooking\n\nCapture of files created, modified and deleted during execution\n\nNetwork traffic capture in PCAP format\n\nMalware classification based on behavioral and network signatures\n\nScreenshots of the desktop taken during the execution of the malware\n\nFull memory dumps of the target system\n\nCAPE complements Cuckoo's traditional sandbox output with several key additions:\n\nAutomated dynamic malware unpacking\n\nMalware classification based on YARA signatures of unpacked payloads\n\nStatic & dynamic malware configuration extraction\n\nInteractive desktop\n\nSome History",
  "Static & dynamic malware configuration extraction\n\nInteractive desktop\n\nSome History\n\nCuckoo Sandbox started as a Google Summer of Code project in 2010 within The Honeynet Project. It was originally designed and developed by Claudio Guarnieri, the first beta release was published in 2011. In January 2014, Cuckoo v1.0 was released.\n\n2015 was a pivotal year, with a significant fork in Cuckoo's history. Development of the original monitor and API hooking method was halted in the main Cuckoo project. It was replaced by alternative monitor using a restructuredText-based signature format compiled via Linux toolchain, created by Jurriaan Bremer.\n\nAround the same time, a fork called cuckoo-modified was created by Brad 'Spender' Spengler continuing development of the original monitor with significant improvements including 64-bit support and importantly introducting Microsoft's Visual Studio compiler. .. _ `Cuckoo-modified`: https://github.com/spender-sandbox/cuckoo-modified",
  "During that same year development of a dynamic command-line configuration and payload extraction tool called CAPE was begun at Context Information Security by Kevin O'Reilly. The name was coined as an acronym of 'Config And Payload Extraction' and the original research focused on using API hooks provided by Microsoft's Detours library to capture unpacked malware payloads and configuration. However, it became apparent that API hooks alone provide insufficient power and precision to allow for unpacking of payloads or configs from arbitrary malware.\n\nFor this reason research began into a novel debugger concept to allow malware to be precisely controlled and instrumented whilst avoiding use of Microsoft debugging interfaces, in order to be as stealthy as possible. This debugger was integrated into the proof-of-concept Detours-based command-line tool, combining with API hooks and resulting in very powerful capabilities.",
  "When initial work showed that it would be possible to replace Microsoft Detours with cuckoo-modified's API hooking engine, the idea for CAPE Sandbox was born. With the addition of the debugger, automated unpacking, YARA-based classification and integrated config extraction, in September 2016 at 44con, CAPE Sandbox was publicly released for the first time: .. _ `CAPE CTXIS`: https://github.com/ctxis/CAPE\n\nIn the summer of 2018 the project was fortunate to see the beginning of huge contributions from Andriy 'doomedraven' Brukhovetskyy, a long-time Cuckoo contributor. In 2019 he began the mammoth task of porting CAPE to Python 3 and in October of that year CAPEv2 was released: .. _ `CAPEv2 upstream`: https://github.com/kevoreilly/CAPEv2",
  "CAPE has been continuously developed and improved to keep pace with advancements in both malware and operating system capabilities. In 2021, the ability to program CAPE's debugger during detonation via dynamic YARA scans was added, allowing for dynamic bypasses to be created for anti-sandbox techniques. Windows 10 became the default operating system, and other significant additions include interactive desktop, AMSI (Anti-Malware Scan Interface) payload capture, 'syscall hooking' based on Microsoft Nirvana and debugger-based direct/indirect syscall countermeasures.\n\nUse Cases\n\nCAPE is designed to be used both as a standalone application as well as to be integrated into larger frameworks, thanks to its extremely modular design.\n\nIt can be used to analyze:\n\nGeneric Windows executables\n\nDLL files\n\nPDF documents\n\nMicrosoft Office documents\n\nURLs and HTML files\n\nPHP scripts\n\nCPL files\n\nVisual Basic (VB) scripts\n\nZIP files\n\nJava JAR\n\nPython files\n\nAlmost anything else",
  "CPL files\n\nVisual Basic (VB) scripts\n\nZIP files\n\nJava JAR\n\nPython files\n\nAlmost anything else\n\nThanks to its modularity and powerful scripting capabilities, there's no limit to what you can achieve with CAPE!\n\nFor more information on customizing CAPE, see the ../customization/index chapter.\n\nArchitecture\n\nCAPE Sandbox consists of central management software which handles sample execution and analysis.\n\nEach analysis is launched in a fresh and isolated virtual machine. CAPE's infrastructure is composed of a Host machine (the management software) and a number of Guest machines (virtual machines for analysis).\n\nThe Host runs the core component of the sandbox that manages the whole analysis process, while the Guests are the isolated environments where the malware samples get safely executed and analyzed.\n\nThe following picture explains CAPE's main architecture:\n\nimage\n\nThe recommended setup is GNU/Linux (Ubuntu LTS preferably) as the Host and Windows 10 21H2 as a Guest.\n\nObtaining CAPE",
  "Obtaining CAPE\n\nCAPE can be downloaded from the official git repository, where the stable and packaged releases are distributed or can be cloned from our official git repository.\n\nWarning\n\nIt is very likely that documentation is not up-to-date, but for that we try to keep a changelog.",
  "Usage\n\nThis chapter explains how to use CAPE.\n\nstart internals submit web api dist cluster_administration packages results clean rooter utilities performance monitor interactive_desktop patterns_replacement",
  "Analysis Results\n\nOnce an analysis is completed, several files are stored in a dedicated directory. All the analyses are stored under the directory storage/analyses/ inside a subdirectory named after the incremental numerical ID that represents the analysis task in the database.\n\nFollowing is an example of an analysis directory structure:\n\n.\n|-- analysis.conf\n|-- analysis.log\n|-- binary\n|-- dump.pcap\n|-- memory.dmp\n|-- files\n|   |-- 1234567890\n|       `-- dropped.exe\n|-- logs\n|   |-- 1232.raw\n|   |-- 1540.raw\n|   `-- 1118.raw\n|-- reports\n|   |-- report.html\n|   |-- report.json\n|   |-- report.maec-4.0.1.xml\n|   `-- report.metadata.xml\n`-- shots\n    |-- 0001.jpg\n    |-- 0002.jpg\n    |-- 0003.jpg\n    `-- 0004.jpg\n\nanalysis.conf\n\nThis is a configuration file automatically generated by CAPE to give its analyzer some details about the current analysis. It's generally of no interest to the end-user, as it's used internally by the sandbox.\n\nanalysis.log",
  "analysis.log\n\nThis is a log file generated by the analyzer that contains a trace of the analysis execution inside the guest environment. It will report the creation of processes, files, and eventual errors that occurred during the execution.\n\ndump.pcap\n\nThis is the network dump generated by tcpdump or any other corresponding network sniffer.\n\nmemory.dmp\n\nIn case you enabled it, this file contains the full memory dump of the analysis machine.\n\nfiles/\n\nThis directory contains all the files the malware operated on and that CAPE was able to dump.\n\nlogs/\n\nThis directory contains all the raw logs generated by CAPE's process monitoring.\n\nreports/\n\nThis directory contains all the reports generated by CAPE as explained in the ../installation/host/configuration chapter.\n\nshots/\n\nThis directory contains all the screenshots of the guest's desktop taken during the malware execution.",
  "Distributed CAPE\n\nThis works under the main server web interface, so everything is transparent for the end user, even if they were analyzed on another server(s).\n\nDeploy each server as a normal server and later just register it as a worker on the master server where dist.py is running.\n\nDependencies\n\nThe distributed script uses a few Python libraries which can be installed through the following command (on Debian/Ubuntu):\n\n$ poetry run pip install flask flask-restful flask-sqlalchemy requests\n\nStarting the Distributed REST API\n\nThe Distributed REST API requires a few command line options in order to run:\n\n$ cd /opt/CAPEv2/web && poetry run python manage.py runserver_plus 0.0.0.0:8000 --traceback --keep-meta-shutdown\n\nRESTful resources\n\nFollowing are all RESTful resources. Also, make sure to check out the quick-usage section which documents the most commonly used commands.",
  "Resource Description GET node_root_get Get a list of all enabled CAPE nodes . POST node_root_post Register a new CAPE node. GET node_get Get basic information about a node. PUT node_put Update basic information of a node. DELETE node_delete Disable (not completely remove!) a node.\n\nGET /node\n\nReturns all enabled nodes. For each node its associated name, API url, and machines are returned:\n\n$ curl http://localhost:9003/node\n{\n    \"nodes\": {\n        \"localhost\": {\n            \"machines\": [\n                {\n                    \"name\": \"cuckoo1\",\n                    \"platform\": \"windows\",\n                    \"tags\": [\n                        \"\"\n                    ]\n                }\n            ],\n            \"name\": \"localhost\",\n            \"url\": \"http://0:8000/apiv2/\"\n        }\n    }\n}\n\nPOST /node",
  "POST /node\n\nRegister a new CAPE node by providing the name and the URL. Optionally the apikey if auth is enabled, You might need to enable list_exitnodes and machinelist in custom/conf/api.conf if your Node API is using htaccess authentication:\n\n$ curl http://localhost:9003/node -F name=master -F url=http://localhost:8000/apiv2/ -F apikey=apikey -F enabled=1\n{\n    \"machines\": [\n        {\n            \"name\": \"cape1\",\n            \"platform\": \"windows\",\n            \"tags\": []\n        }\n    ],\n    \"name\": \"localhost\"\n}\n\nGET /node/<name>\n\nGet basic information about a particular CAPE node:\n\n$ curl http://localhost:9003/node/localhost\n{\n    \"name\": \"localhost\",\n    \"url\": \"http://localhost:8000/apiv2/\"\n}\n\nPUT /node/<name>\n\nUpdate basic information of a CAPE node:\n\n$ curl -XPUT http://localhost:9003/node/localhost -F name=newhost \\\n    -F url=http://1.2.3.4:8000/apiv2/\nnull\n\nAdditional Arguments:",
  "Additional Arguments:\n\n* enabled\n    False=0 or True=1 to activate or deactivate worker node\n* exitnodes\n    exitnodes=1 - Update exit nodes list, to show on main web UI\n* apikey\n    apikey for authorization\n\nDELETE /node/<name>\n\nDisable a CAPE node, therefore not having it process any new tasks, but keep its history in the Distributed's database:\n\n$ curl -XDELETE http://localhost:9003/node/localhost\nnull\n\nQuick usage\n\nFor practical usage the following few commands will be most interesting.\n\nRegister a CAPE node - a CAPE REST API running on the same machine in this case:\n\n$ curl http://localhost:9003/node -F name=master -F url=http://localhost:8000/apiv2/\nMaster server must be called master, the rest of names we don't care\n\nDisable a CAPE node:\n\n$ curl -XDELETE http://localhost:9003/node/<name>\n\nor:\n\n$ curl -XPUT http://localhost:9003/node/localhost -F enable=0\nnull\n\nor:\n\n$ ./dist.py --node NAME --disable",
  "or:\n\n$ ./dist.py --node NAME --disable\n\nGet the report of a task should be requested throw master node integrated /api/\n\nProposed setup\n\nThe following description depicts a Distributed CAPE setup with two CAPE machines, a master and a worker. In this setup the first machine, the master, also hosts the Distributed CAPE REST API.\n\nConfiguration settings\n\nOur setup will require a couple of updates about the configuration files.\n\nNote about VMs tags in hypervisor conf as kvm.conf:\n\nIf you have ``x64`` and ``x86`` VMs:\n* ``x64`` VMs should have both ``x64`` and ``x86`` tags. Otherwise only ``x64`` tag\n* ``x86`` VMs should have only ``x86`` tag.\n* You can use any other tags, just to work properly you need those two.\n* Probably will be improved in future for better solution\n\ncustom/conf/cuckoo.conf\n\nOptional: Update tmppath to something that holds enough storage to store a few hundred binaries. On some servers or setups /tmp may have a limited amount of space and thus this wouldn't suffice.",
  "Update connection to use something that is not sqlite3. Preferably PostgreSQL. SQLite3 doesn't support multi-threaded applications that well and this will give errors at random if used. Neither support database schema upgrade.\n\ncustom/conf/processing.conf\n\nYou may want to disable some processing modules, such as virustotal.\n\ncustom/conf/reporting.conf\n\nDepending on which report(s) are required for integration with your system it might make sense to only make those report(s) that you're going to use. Thus disable the other ones.\n\ncustom/conf/distributed.conf\n\nCheck also \"[distributed]\" section, where you can set the database, path for samples, and a few more values. Do not use sqlite3! Use PostgreSQL database for performance and thread safe.\n\nUpdate db to use something that is not sqlite3. Preferably PostgreSQL. SQLite3 doesn't support multi-threaded applications that well and this will give errors at random if used. Neither support database schema upgrade.\n\nRegister CAPE nodes",
  "Register CAPE nodes\n\nAs outlined in quick-usage the CAPE nodes have to be registered with the Distributed CAPE script\n\nwithout htaccess:\n\n$ curl http://localhost:9003/node -F name=master -F url=http://localhost:8000/apiv2/\n\nwith htaccess:\n\n$ curl http://localhost:9003/node -F name=worker -F url=http://1.2.3.4:8000/apiv2/ \\\n  -F username=user -F password=password\n\nHaving registered the CAPE nodes all that's left to do now is to submit tasks and fetch reports once finished. Documentation on these commands can be found in the quick-usage section.\n\nVM Maintenance\n\nOccasionally you might want to perform maintenance on VMs without shutting down your whole node. To do this, you need to remove the VM from being used by CAPE in its execution, preferably without having to restart the ./cuckoo.py daemon.\n\nFirst, get a list of available VMs that are running on the worker:\n\n$ poetry run python dist.py --node NAME\n\nSecondly, you can remove VMs from being used by CAPE with:",
  "Secondly, you can remove VMs from being used by CAPE with:\n\n$ poetry run python dist.py --node NAME --delete-vm VM_NAME\n\nWhen you are done editing your VMs you need to add them back to be used by cuckoo. The easiest way to do that is to disable the node, so no more tasks get submitted to it:\n\n$ poetry run python dist.py --node NAME --disable\n\nWait for all running VMs to finish their tasks, and then restart the workers ./cuckoo.py, this will re-insert the previously deleted VMs into the Database from custom/conf/virtualbox.conf.\n\nUpdate the VM list on the master:\n\n$ poetry run python dist.py --node NAME\n\nAnd enable the worker again:\n\n$ poetry run python dist.py --node NAME --enable\n\nGood practice for production\n\nThe number of retrieved threads can be configured in reporting.conf\n\nInstallation of \"uwsgi\":\n\n# nginx is optional\n# apt install uwsgi uwsgi-plugin-python3 nginx\n\nIt's better if you run \"web\" and \"dist.py\" as uwsgi application. To run your api with config just execute as:",
  "# Web UI is started by systemd as cape-web.service\n$ uwsgi --ini /opt/CAPEv2/uwsgi/capedist.ini\n\nTo add your application to auto start after boot, copy your config file to:\n\ncp /opt/CAPEv2/uwsgi/capedist.ini /etc/uwsgi/apps-available/cape_dist.ini\nln -s /etc/uwsgi/apps-available/cape_dist.ini /etc/uwsgi/apps-enabled\n\nservice uwsgi restart\n\nOptimizations:\n\nIf you have many workers is recommended\n    UWSGI:\n        set processes to be able handle number of requests dist + dist2 + 10\n    DB:\n        set max connection number to be able handle number of requests dist + dist2 + 10\n\nDistributed Mongo setup\n\nSet one mongo as master and the rest just point to it, in this example cuckoo_dist.fe is our master server. Depending on your hardware you may prepend the next command before mongod:\n\n$ numactl --interleave=all\n\nThese commands should be executed only on the master:",
  "$ numactl --interleave=all\n\nThese commands should be executed only on the master:\n\n# create config server instance with the \"cuckoo_config\" replica set\n# Preferably to execute few config servers on different shards\n/usr/bin/mongod --configsvr --replSet cuckoo_config --bind_ip_all\n\n# initialize the \"cuckoo_config\" replica set\nmongosh --port 27019\n\nExecute in mongo console:\n    rs.initiate({\n      _id: \"cuckoo_config\",\n      configsvr: true,\n      members: [\n        { _id: 0, host: \"192.168.1.13:27019\" },\n      ]\n    })\n\nThis should be started on all nodes including master:\n\n# start shard server\n/usr/bin/mongod --shardsvr --bind_ip 0.0.0.0 --port 27017 --replSet rs0\n\nAdd clients, execute on master mongo server:\n\n# start mongodb router instance that connects to the config server\nmongos --configdb cuckoo_config/192.168.1.13:27019 --port 27020 --bind_ip_all",
  "# in another terminal\nmongosh\nrs.initiate( {\n   _id : \"rs0\",\n   members: [\n      { _id: 0, host: \"192.168.1.x:27017\" },\n      { _id: 1, host: \"192.168.1.x:27017\" },\n      { _id: 2, host: \"192.168.1.x:27017\" },\n   ]\n})\n\n# Check which node is primary and change the prior if is incorrect\n# https://docs.mongodb.com/manual/tutorial/force-member-to-be-primary/\ncfg = rs.conf()\ncfg.members[0].priority = 0.5\ncfg.members[1].priority = 0.5\ncfg.members[2].priority = 1\nrs.reconfig(cfg, {\"force\": true})\n\n# Add arbiter only\nrs.addArb(\"192.168.1.51:27017\")\n\n# Add replica set member, secondary\nrs.add({\"host\": \"192.168.1.50:27017\", \"priority\": 0.5})\n\n# add shards\nmongosh --port 27020\n\nExecute in mongo console:\n    sh.addShard( \"rs0/192.168.1.13:27017\")\n    sh.addShard( \"rs0/192.168.1.44:27017\")\n    sh.addShard( \"rs0/192.168.1.55:27017\")\n    sh.addShard( \"rs0/192.168.1.62:27017\")\n\nWhere 192.168.1.(2,3,4,5) is our CAPE workers:",
  "Where 192.168.1.(2,3,4,5) is our CAPE workers:\n\nmongo\nuse cuckoo\n# 5 days, last number is days\ndb.analysis.insert({\"name\":\"tutorials point\"})\ndb.calls.insert({\"name\":\"tutorials point\"})\ndb.analysis.createIndex ( {\"_id\": \"hashed\" })\ndb.calls.createIndex ( {\"_id\": \"hashed\"})\n\ndb.analysis.createIndex ( {\"createdAt\": 1 }, {expireAfterSeconds:60*60*24*5} )\ndb.calls.createIndex ( {\"createdAt\": 1}, {expireAfterSeconds:60*60*24*5} )\n\nmongosh --port 27020\nsh.enableSharding(\"cuckoo\")\nsh.shardCollection(\"cuckoo.analysis\", { \"_id\": \"hashed\" })\nsh.shardCollection(\"cuckoo.calls\", { \"_id\": \"hashed\" })\n\nTo see stats on master:\n\nmongos using\nmongosh --host 127.0.0.1 --port 27020\nsh.status()\n\nModify cape reporting.conf [mongodb] to point all mongos in reporting.conf to host = 127.0.0.1 port = 27020\n\nTo remove shard node:\n\nTo see all shards:\ndb.adminCommand( { listShards: 1 } )\n\nThen:\nuse admin\ndb.runCommand( { removeShard: \"SHARD_NAME_HERE\" } )\n\nIf you need extra help, check this:",
  "If you need extra help, check this:\n\nSee any of these files on your system:\n\n$ /etc/uwsgi/apps-available/README\n$ /etc/uwsgi/apps-enabled/README\n$ /usr/share/doc/uwsgi/README.Debian.gz\n$ /etc/default/uwsgi\n\nAdministration and some useful commands:\n\nhttps://docs.mongodb.com/manual/reference/command/nav-sharding/\n$ mongosh --host 127.0.0.1 --port 27020\n$ use admin\n$ db.adminCommand( { listShards: 1 } )\n\n$ mongosh --host 127.0.0.1 --port 27019\n$ db.adminCommand( { movePrimary: \"cuckoo\", to: \"shard0000\" } )\n$ db.adminCommand( { removeShard : \"shard0002\" } )\n\n$ # required for post movePrimary\n$ db.adminCommand(\"flushRouterConfig\")\n$ mongosh --port 27020 --eval 'db.adminCommand(\"flushRouterConfig\")' admin\n\n$ use cuckoo\n$ db.analysis.find({\"shard\" : \"shard0002\"},{\"shard\":1,\"jumbo\":1}).pretty()\n$ db.calls.getShardDistribution()\n\nTo migrate data ensure:\n$ sh.setBalancerState(true)\n\nUser authentication and roles:",
  "To migrate data ensure:\n$ sh.setBalancerState(true)\n\nUser authentication and roles:\n\n# To create ADMIN\nuse admin\ndb.createUser(\n    {\n        user: \"ADMIN_USERNAME\",\n        pwd: passwordPrompt(), // or cleartext password\n        roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" }, \"readWriteAnyDatabase\" ]\n    }\n)\n\n# To create user to read/write on specific database\nuse cuckoo\ndb.createUser(\n    {\n        user: \"WORKER_USERNAME\",\n        pwd:  passwordPrompt(),   // or cleartext password\n        roles: [ { role: \"readWrite\", db: \"cuckoo\" }, { role : \"dbAdmin\", db : \"cuckoo\"  }]\n    }\n)\n\n\n# To enable auth in ``/etc/mongod.conf``, add next lines\nsecurity:\n    authorization: enabled\n\nNFS data fetching:\n\nNice comparison between NFS, SSHFS, SMB\nhttps://blog.ja-ke.tech/2019/08/27/nas-performance-sshfs-nfs-smb.html\n\nTo configure NFS on the main server (NFS calls it client)\n\nTo install new service for fstab utils run as root:",
  "To install new service for fstab utils run as root:\n\nln -s /opt/CAPEv2/systemd/cape-fstab.service /lib/systemd/system/cape-fstab.service\nsystemctl daemon-reload\nsystemctl enable cape-fstab.service\nsystemctl start cape-fstab.service\n\nFollowing steps about folder creation, entry in fstab are automated on 30.01.2023. See utils/fstab.py\n\nCAPE worker(s) (NFS calls it servers):\n\nInstall NFS:\n    * sudo apt install nfs-kernel-server\n    * systemctl enable nfs-kernel-server\n\nRun `id cape`:\n    * to get uid and gid to place inside of the file, Example:\n        * `uid=997(cape) gid=1005(cape) groups=1005(cape),1002(libvirt),1003(kvm),1004(pcap)`\n\nAdd entry to `/etc/exports`\n    /opt/CAPEv2 <clinet_ip/hostname>(rw,no_subtree_check,all_squash,anonuid=<uid>,anongid=<gid>)\nExample:\n    /opt/CAPEv2 192.168.1.1(rw,no_subtree_check,all_squash,anonuid=997,anongid=1005)\n\nRun command on worker:\n    exportfs -rav\n\nOnline:",
  "Interactive session\n\nInstallation\n\nWarning\n\nDoesn't support cluster mode.\n\nTo install dependencies please run:\n\n$ sudo ./installer/cape2.sh guacamole\n\nNew services added:\n\n$ systemctl status guacd.service\n$ systemctl status guac-web.service\n\nWeb server configuration\n\nEnable and configure guacamole in conf/web.conf and restart cape-web.service and guacd.service:\n\n$ systemctl restart cape-web guacd.service\n\nThen configure NGINX. See best_practices_for_production for details.\n\nVirtual machine configuration\n\nAt the moment we support only KVM and we don't have plans to support any other hypervisor.\n\nTo enable support for remote session you need to add a VNC display to your VM, otherwise it won't work.\n\nHaving troubles?\n\nTo test if your guacamole working correctly you can use this code\n\nWarning\n\nIf you have opened VM in virt-manager you won't be able to get it via browser. Close virt-manager VM view and refresh tab in browser.",
  "from uuid import uuid3, NAMESPACE_DNS\nfrom base64 import urlsafe_b64encode as ub64enc\nsid = uuid3(NAMESPACE_DNS, \"0000\").hex[:16]\nip = \"<YOUR_VM_IP>\" # Example 192.168.2.2\nvm_name = \"<YOUR_VM_NAME>\" # example win10\nsd = ub64enc(f\"{sid}|{vm_name}|{ip}\".encode(\"utf8\")).decode(\"utf8\")\nprint(sd)\n\n# Open in your browser https://<hostname>/guac/0000/<sd>\n\nStart your VM and once it finish booting, open that url in browser to ensure that remote session working just fine.\n\nIf that doesn't work, check logs:\n\n$ systemctl status guacd or journalctl -u guacd\n$ cat /opt/CAPEv2/web/guac-server.log\n\nKnown problems and solution steps:\n\nEnsure that CAPE loads on port 80 (later you can enable TLS/SSL). Sometime config instead of sites-enabled/cape.conf should be conf.d/default.conf.\n\nOnce verified that it works with http, move to https.\n\nYou can try websocket test client.\n\nTry another browser.",
  "Utilities\n\nCAPE comes with a set of pre-built utilities to automate several common tasks. You can find them under the \"utils\" folder. There more utilities than documented\n\nCleanup utility\n\nUse CAPE-clean instead which also takes care of cleaning sample and task information from MySQL and PostgreSQL databases. This utility will also delete all data from the configured MongoDB or ElasticSearch databases.\n\nSubmission Utility\n\nSubmits samples to analysis. This tool is already described in submit.\n\nWeb Utility\n\nCAPE's web interface. This tool is already described in submit.\n\nProcessing Utility\n\nRun the results processing engine and optionally the reporting engine (run all reports) on an already available analysis folder, in order to not re-run the analysis if you want to re-generate the reports for it. This is used mainly in debugging and developing CAPE. For example if you want run again the report engine for analysis number 1:\n\n$ ./utils/process.py -r 1",
  "$ ./utils/process.py -r 1\n\nIf you want to re-generate the reports:\n\n$ ./utils/process.py --report 1\n\nFollowing are the usage options:\n\n$ ./utils/process.py -h\n\nusage: process.py [-h] [-c] [-d] [-r] [-s] [-p PARALLEL] [-fp] [-mc MAXTASKSPERCHILD] [-md] [-pt PROCESSING_TIMEOUT] id\n\npositional arguments:\n  id                    ID of the analysis to process (auto for continuous processing of unprocessed tasks).",
  "optional arguments:\n  -h, --help            show this help message and exit\n  -c, --caperesubmit    Allow CAPE resubmit processing.\n  -d, --debug           Display debug messages\n  -r, --report          Re-generate report\n  -s, --signatures      Re-execute signatures on the report\n  -p PARALLEL, --parallel PARALLEL\n                        Number of parallel threads to use (auto mode only).\n  -fp, --failed-processing\n                        reprocess failed processing\n  -mc MAXTASKSPERCHILD, --maxtasksperchild MAXTASKSPERCHILD\n                        Max children tasks per worker\n  -md, --memory-debugging\n                        Enable logging garbage collection related info\n  -pt PROCESSING_TIMEOUT, --processing-timeout PROCESSING_TIMEOUT\n                        Max amount of time spent in processing before we fail a task\n\nAs best practice we suggest to adopt the following configuration if you are running CAPE with many virtual machines:",
  "Run a stand alone process.py in auto mode (you choose the number of parallel threads)\n\nThis could increase the performance of your system because the reporting is not yet demanded to CAPE.\n\nCommunity Download Utility\n\nThis utility downloads signatures from CAPE Community Repository and installs specific additional modules in your local setup. Following are the usage options:\n\n$ ./utils/community.py -h\n\nusage: community.py [-h] [-a] [-s] [-p] [-m] [-r] [-f] [-w] [-b BRANCH]",
  "$ ./utils/community.py -h\n\nusage: community.py [-h] [-a] [-s] [-p] [-m] [-r] [-f] [-w] [-b BRANCH]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -a, --all             Download everything\n  -s, --signatures      Download Cuckoo signatures\n  -p, --processing      Download processing modules\n  -m, --machinemanagers\n                        Download machine managers\n  -r, --reporting       Download reporting modules\n  -f, --force           Install files without confirmation\n  -w, --rewrite         Rewrite existing files\n  -b BRANCH, --branch BRANCH\n                        Specify a different branch\n\nExample: install all available signatures:\n\n$ ./utils/community.py --signatures --force\n\nDatabase migration utility",
  "$ ./utils/community.py --signatures --force\n\nDatabase migration utility\n\nThis utility is developed to migrate your data between CAPE's release. It's developed on top of the Alembic framework and it should provide data migration for both SQL database and Mongo database. This tool is already described in ../installation/upgrade.\n\nStats utility\n\nThis is a really simple utility which prints some statistics about processed samples:\n\n$ ./utils/stats.py\n\n1 samples in db\n1 tasks in db\npending 0 tasks\nrunning 0 tasks\ncompleted 0 tasks\nrecovered 0 tasks\nreported 1 tasks\nfailed_analysis 0 tasks\nfailed_processing 0 tasks\nroughly 32 tasks an hour\nroughly 778 tasks a day\n\nMachine utility\n\nThe machine.py utility is designed to help you automatize the configuration of virtual machines in CAPE. It takes a list of machine details as arguments and write them in the specified configuration file of the machinery module enabled in cuckoo.conf. Following are the available options:",
  "$ ./utils/machine.py -h\nusage: machine.py [-h] [--debug] [--add] [--ip IP] [--platform PLATFORM]\n                [--tags TAGS] [--interface INTERFACE] [--snapshot SNAPSHOT]\n                [--resultserver RESULTSERVER]\n                vmname\n\npositional arguments:\n  vmname                Name of the Virtual Machine.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --debug               Debug log in case of errors.\n  --add                 Add a Virtual Machine.\n  --ip IP               Static IP Address.\n  --platform PLATFORM   Guest Operating System.\n  --tags TAGS           Tags for this Virtual Machine.\n  --interface INTERFACE\n                        Sniffer interface for this machine.\n  --snapshot SNAPSHOT   Specific Virtual Machine Snapshot to use.\n  --resultserver RESULTSERVER\n                        IP:Port of the Result Server.",
  "Web interface\n\nCAPE provides a full-fledged web interface in the form of a Django application. This interface will allow you to submit files, browse through the reports as well as search across all the analysis results.\n\ncape2.sh adds systemd daemon called cape-web.service which listen on all interfaces:\n\n$ /lib/systemd/system/cape-web.service\n\nTo modify that you need to edit that file and change from 0.0.0.0 to your IP. You need to restart daemon to reload after change it:\n\n$ systemctl daemon-reload\n\nIf you get migration-related WARNINGS when launching the cape-web service, you should execute:\n\n$ poetry run python3 manage.py migrate\n\nNote\n\nIn order to improve performance, it is recommended to move from SQLite to PostgreSQL.\n\nConfiguration",
  "Configuration\n\nThe web interface pulls data from a Mongo database or ElasticSearch, so having either the MongoDB or ElasticSearchDB reporting modules enabled in reporting.conf is mandatory for this interface. If that's not the case, the application won't start and it will raise an exception. Also, currently, Django only supports having one of the database modules enabled at a time.\n\nEnable web interface auth\n\nTo enable web authentication you need to edit conf/web.conf -> web_auth -> enabled = yes, after that you need to create your django admin user by running following command from web folder:\n\n$ poetry run python manage.py createsuperuser\n\nFor more security tips see Exposed to internet section.\n\nEnable/Disable REST API Endpoints\n\nBy default, there are multiple REST API endpoints that are disabled. To enable them, head to the API configuration file",
  "For example, to enable the machines/list endpoint, you must find the [machinelist] header in the configuration file just mentioned and set the enabled field to yes.\n\nRestart the CAPE web service for the changes to take effect:\n\n$ systemctl restart cape-web\n\nUsage\n\nTo start the web interface, you can simply run the following command from the web/ directory:\n\n$ poetry run python3 manage.py runserver_plus --traceback --keep-meta-shutdown\n\nIf you want to configure the web interface as listening for any IP on a specified port (by default the web interface is deployed at localhost:8000), you can start it with the following command (replace PORT with the desired port number):\n\n$ poetry run python3 manage.py runserver_plus 0.0.0.0:8000 --traceback --keep-meta-shutdown",
  "$ poetry run python3 manage.py runserver_plus 0.0.0.0:8000 --traceback --keep-meta-shutdown\n\nYou can serve CAPE's web interface using WSGI interface with common web servers: Apache, Nginx, Unicorn, and so on. Devs are using Nginx + Uwsgi. Please refer both to the documentation of the web server of your choice as well as Django documentation.\n\nSubscription\n\nSubscription allows you to control which users what can do what.\n\nRight now we support:\n\nRequest - Limits per second/minute/hour using django-ratelimit extensions\n\nReports - Allow or block downloading reports for specific users. Check conf/web.conf to enable this feature.\n\nTo extend the capabilities of control what users can do check Django migrations a primer.\n\nIn few words you need to add new fields to models.py and run poetry run python3 manage.py makemigrations\n\nExposed to internet",
  "Exposed to internet\n\nTo get rid of many bots/scrappers so we suggest deploying this amazing project Nginx Ultimate bad bot blocker, follow the README for installation steps\n\nEnable web auth with captcha in conf/web.conf properly to avoid any brute force.\n\nEnable ReCaptcha. You will need to set RECAPTCHA_PUBLIC_KEY and RECAPTCHA_PRIVATE_KEY keys in web/web/local_settings.py\n\nYou might need to \"Verify\" and set as \"Stuff user\" to your admin in the Django admin panel and add your domain to Sites in Django admin too\n\nBest practices for production\n\nGunicorn + NGINX is the recommended way of serving the CAPE web UI.\n\nGunicorn\n\nFirst, configure the cape-web service to use Gunicorn\n\nModify /lib/systemd/system/cape-web.service so the ExecStart setting is set to:\n\nExecStart=/usr/bin/python3 -m poetry run gunicorn web.wsgi -w 4 -t 200 --capture-output --enable-stdio-inheritance\n\nRun\n\nsudo systemctl daemon-reload\nsudo service cape-web restart\n\nNGINX",
  "Run\n\nsudo systemctl daemon-reload\nsudo service cape-web restart\n\nNGINX\n\nNext, install NGINX and configure it to be a reverse proxy to Gunicorn.\n\nsudo apt install nginx\n\nCreate a configuration file at /etc/nginx/conf.d/cape. You might need to add include /etc/nginx/conf.d/*.conf; to http section inside of /etc/nginx/nginx.conf.\n\nReplace www.capesandbox.com with your actual hostname.\n\nserver {\n    listen 80;\n    server_name www.capesandbox.com;\n    client_max_body_size 101M;\n    proxy_connect_timeout 75;\n    proxy_send_timeout 200;\n    proxy_read_timeout 200;\n\n\n    location ^~ /.well-known/acme-challenge/ {\n        default_type \"text/plain\";\n        root         /var/www/html;\n        break;\n    }\n\n    location = /.well-known/acme-challenge/ {\n        return 404;\n    }",
  "location = /.well-known/acme-challenge/ {\n        return 404;\n    }\n\n    location / {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Remote-User $remote_user;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n\n    location /static/ {\n        alias /opt/CAPEv2/web/static/;\n    }\n\n    location /static/admin/ {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Remote-User $remote_user;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }",
  "location /guac {\n        proxy_pass http://127.0.0.1:8008;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_buffering off;\n        proxy_http_version 1.1;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $http_connection;\n    }\n\n    location /recordings/playback/recfile {\n        alias /opt/CAPEv2/storage/guacrecordings/;\n        autoindex off;\n    }\n}\n\nNow enable the nginx configuration by executing the following:\n\nrm -f /etc/nginx/conf.d/default\nln -s /etc/nginx/conf.d/cape /etc/nginx/conf.d/default\n\nIf you want to block users from changing their own email addresses, add the following location directive inside of the server directive:\n\nlocation /accounts/email/ {\n    return 403;\n}",
  "location /accounts/email/ {\n    return 403;\n}\n\nIf you want to block users from changing their own passwords, add the following location directive inside of the server directive:\n\nlocation /accounts/email/ {\n    return 403;\n}\n\nThe recording files written by guacd are only readable by the cape user and other members of the cape group, so in order for NGINX to read and serve the recordings the www-data user must be added to the cape group.\n\nsudo usermod www-data -G cape\n\nThen restart NGINX\n\nsudo service nginx restart\n\nWarning\n\nThe CAPE Guacamole Django web application is currently separate from the main CAPE Django web application, and does not support any authentication. Anyone who can connect to the web server access can Guacamole consoles and recordings, if they know the CAPE analysis ID and Guacamole session GUID.\n\nNGINX can be configured to require HTTP basic authentication for all CAPE web applications, as an alternative to the Django authentication system.",
  "Install the apache2-utils package, which contains the htpasswd utility.\n\nsudo apt install apache2-utils\n\nUse the htpasswd file to create a new password file and add a first user, such as cape.\n\nsudo htpasswd -c /opt/CAPEv2/web/.htpasswd cape\n\nUse the same command without the -c option to add another user to an existing password file.\n\nSet the proper file permissions.\n\nsudo chown root:www-data /opt/CAPEv2/web/.htpasswd\nsudo chmod u=rw,g=r,o= /opt/CAPEv2/web/.htpasswd\n\nAdd the following lines to the NGINX configuration, just below the client_max_body_size line.\n\nauth_basic           \"Authentication required\";\nauth_basic_user_file /opt/CAPEv2/web/.htpasswd;\n\nThen restart NGINX\n\nsudo service nginx restart\n\nLet's Encrypt certificates",
  "Then restart NGINX\n\nsudo service nginx restart\n\nLet's Encrypt certificates\n\nIf you would like to install a free Let's Encrypt certificate on your NGINX server, follow these steps, replacing capesandbox.com with your actual hostname. Use cape2.sh to install dependencies. But also ensure that instruction are up to date with this https://certbot.eff.org/\n\nInstall certbot.\n\nsudo cape2.sh letsencrypt\n\nRequest the certificate\n\nsudo certbot certonly --webroot -w /var/www/html -d www.capesandbox.com -d capesandbox.com\n\nInstall the certificate. When prompted, select the \"Attempt to reinstall this existing certificate\" option.\n\nsudo certbot --nginx -d www.capesandbox.com -d capesandbox.com\n\nSome extra security TIP(s)\n\nModSecurity tutorial - rejects requests\n\nFail2ban tutorial - ban hosts\n\nFail2ban + CloudFlare - how to ban on CloudFlare aka CDN firewall level\n\nExample of cloudflare action ban:",
  "Example of cloudflare action ban:\n\n# Author: Mike Andreasen from https://guides.wp-bullet.com\n# Adapted Source: https://github.com/fail2ban/fail2ban/blob/master/config/action.d/cloudflare.conf\n# Referenced from: https://www.normyee.net/blog/2012/02/02/adding-cloudflare-support-to-fail2ban by NORM YEE\n#\n# To get your Cloudflare API key: https://www.cloudflare.com/my-account, you should use GLOBAL KEY!\n\n[Definition]\n\n# Option:  actionstart\n# Notes.:  command executed once at the start of Fail2Ban.\n# Values:  CMD\n#\nactionstart =\n\n# Option:  actionstop\n# Notes.:  command executed once at the end of Fail2Ban\n# Values:  CMD\n#\nactionstop =\n\n# Option:  actioncheck\n# Notes.:  command executed once before each actionban command\n# Values:  CMD\n#\nactioncheck =",
  "# Option:  actionban\n# Notes.:  command executed when banning an IP. Take care that the\n#          command is executed with Fail2Ban user rights.\n# Tags:      IP address\n#            number of failures\n#            unix timestamp of the ban time\n# Values:  CMD\n\nactionban = curl -s -X POST \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules\" -H \"X-Auth-Email: <cfuser>\" -H \"X-Auth-Key: <cftoken>\" -H \"Content-Type: application/json\" --data '{\"mode\":\"block\",\"configuration\":{\"target\":\"ip\",\"value\":\"<ip>\"},\"notes\":\"Fail2ban\"}'\n\n# Option:  actionunban\n# Notes.:  command executed when unbanning an IP. Take care that the\n#          command is executed with Fail2Ban user rights.\n# Tags:      IP address\n#            number of failures\n#            unix timestamp of the ban time\n# Values:  CMD\n#",
  "actionunban = curl -s -X DELETE \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules/$( \\\n            curl -s -X GET \"https://api.cloudflare.com/client/v4/user/firewall/access_rules/rules?mode=block&configuration_target=ip&configuration_value=<ip>&page=1&per_page=1&match=all\" \\\n            -H \"X-Auth-Email: <cfuser>\" \\\n            -H \"X-Auth-Key: <cftoken>\" \\\n            -H \"Content-Type: application/json\" | awk -F\"[,:}]\" '{for(i=1;i<=NF;i++){if($i~/'id'\\042/){print $(i+1)}}}' | tr -d '\"' | head -n 1)\" \\\n            -H \"X-Auth-Email: <cfuser>\" \\\n            -H \"X-Auth-Key: <cftoken>\" \\\n            -H \"Content-Type: application/json\"\n\n[Init]\n\n# Option: cfuser\n# Notes.: Replaces <cfuser> in actionban and actionunban with cfuser value below\n# Values: Your CloudFlare user account\n\ncfuser = put-your-cloudflare-email-here",
  "cfuser = put-your-cloudflare-email-here\n\n# Option: cftoken\n# Notes.: Replaces <cftoken> in actionban and actionunban with cftoken value below\n# Values: Your CloudFlare API key\ncftoken = put-your-API-key-here\n\nExample of fail2ban rule to ban by path:\n\n# This will ban any host that trying to access /api/ for 3 times in 1 minute\n# Goes to /etc/fail2ban/filters.d/nginx-cape-api.conf\n[Definition]\nfailregex = ^<HOST> -.*\"(GET|POST|HEAD) /api/.*HTTP.*\"\nignoreregex =\n\n# goes to /etc/fail2ban/jail.local\n[cape-api]\nenabled = true\nport    = http,https\nfilter  = nginx-cape-api\nlogpath = /var/log/nginx/access.log\nmaxretry = 3\nfindtime = 60\nbantime = -1\n# Remove cloudflare line if you don't use it\naction = iptables-multiport\n         cloudflare",
  "# This will ban any host that trying to brute force login or unauthorized requests for 5 times in 1 minute\n# Goes to /etc/fail2ban/filters.d/filter.d/nginx-cape-login.conf\n[Definition]\nfailregex = ^<HOST> -.*\"(GET|POST|HEAD) /accounts/login/\\?next=.*HTTP.*\"\nignoreregex =\n\n# goes to /etc/fail2ban/jail.local\n[cape-login]\nenabled = true\nport    = http,https\nfilter  = nginx-cape-login\nlogpath = /var/log/nginx/access.log\nmaxretry = 5\nfindtime = 60\nbantime = -1\n# Remove cloudflare line if you don't use it\naction = iptables-multiport\n          cloudflare\n\nTo check banned hosts:\n\n$ sudo fail2ban-client status cape-api\n\nTroubleshooting\n\nLogin error: no such column: users_userprofile.reports\n\nimage\n\nThis error usually appears after updating CAPEv2 and one or more changes have been made to the database schema. To solve it, you must use the web/manage utility like so:\n\n$ sudo -u cape poetry run python3 manage.py migrate\n\nThe output should be similar to:",
  "$ sudo -u cape poetry run python3 manage.py migrate\n\nThe output should be similar to:\n\n$ sudo -u cape poetry run python3 manage.py migrate\nCAPE parser: No module named Nighthawk - No module named 'Crypto'\nMissed dependency flare-floss: poetry run pip install -U flare-floss\nOperations to perform:\n  Apply all migrations: account, admin, auth, authtoken, contenttypes, openid, sessions, sites, socialaccount, users\nRunning migrations:\n  Applying users.0002_reports... OK\n\nAfter the OK, the web service should be back to normal (no need to restart cape-web.service).\n\nNo such table: auth_user\n\nWhen executing:\n\n$ poetry run python manage.py createsuperuser\n\nan error like django.db.utils.OperationalError: no such table: auth_user may be raised. In order to solve it just execute the web/manage.py utility with the migrate option:\n\n$ sudo -u cape poetry run python3 web/manage.py migrate\n\nSlow web/API searches when using MongoDB as backend",
  "Slow web/API searches when using MongoDB as backend\n\nCheck server lack of resources as memory ram, cpu or even slow hard drive.\n\nPossible issue is the lack of proper indexes.\n\nList your MongoDB indexes:\n\ndb.analysis.getIndexes()\n\nTest your query with explaination. Replace with your search patterns:\n\ndb.analysis.find({\"target.file.name\": \"<name>\"}).explain(\"executionStats\")\n\nPay attention to stage value:\n\nexecutionStages: {\n    stage: 'COLLSCAN', # <--- Full collection scan instead of index usage\n\nIf you expect it to search in index, expected output should be like this:\n\nexecutionStages: {\n    stage: 'FETCH',\n    <stripped>\n    inputStage: {\n        stage: 'IXSCAN', # <--- Index usage\n\nHow to delete index\n\ndb.collection.dropIndexes(\"<index name>\")",
  "CAPE Rooter\n\nThe CAPE Rooter is a new concept, providing root access for various commands to CAPE (which itself generally speaking runs as non-root). This command is currently only available for Ubuntu and Debian-like systems.\n\nIn particular, the rooter helps CAPE out with running network-related commands to provide per-analysis routing options. For more information on that, please refer to the routing document. CAPE and the rooter communicate through a UNIX socket for which the rooter makes sure that CAPE can reach it.\n\nIts usage is as follows:\n\n$ python3 rooter.py -h\nusage: rooter.py [-h] [-g GROUP] [--systemctl SYSTEMCTL] [--iptables IPTABLES] [--iptables-save IPTABLES_SAVE] [--iptables-restore IPTABLES_RESTORE] [--ip IP] [-v] [socket]\n\npositional arguments:\nsocket                Unix socket path",
  "positional arguments:\nsocket                Unix socket path\n\noptional arguments:\n-h, --help            show this help message and exit\n-g GROUP, --group GROUP\n                        Unix socket group\n--systemctl SYSTEMCTL\n                        Systemctl wrapper script for invoking OpenVPN\n--iptables IPTABLES   Path to iptables\n--iptables-save IPTABLES_SAVE\n                        Path to iptables-save\n--iptables-restore IPTABLES_RESTORE\n                        Path to iptables-restore\n--ip IP               Path to ip\n-v, --verbose         Enable verbose logging\n\nWhen executing the rooter utility, it will default to the cuckoo group.\n\nimage\n\nYou must specify the user of the UNIX socket. As recommended in the installation, it should be the cape user. You can do so by executing the following command:\n\n$ sudo python3 utils/rooter.py -g cape\n\nHowever, if you're running CAPE under a user other than cape, you will have to specify this to the rooter as follows:",
  "$ sudo python3 utils/rooter.py -g <user>\n\nThe other options are fairly straightforward - you can specify the paths to specific Linux commands. By default, one shouldn't have to do this though, as the rooter takes the default paths for the various utilities as per a default setup.\n\nVirtualenv\n\nSince the rooter must be run as root user, there are some slight complications when using a virtualenv to run CAPE. More specifically, when running sudo python3 utils/rooter.py, the $VIRTUAL_ENV environment variable will not be passed along, due to which Python will not be executed from the same virtualenv as it would have been normally.\n\nTo resolve this one simply has to execute the cape binary from the virtualenv session directly. E.g., if your virtualenv is located at ~/venv, then running the rooter command could be done as follows:\n\n$ sudo ~/venv/bin/cape rooter\n\nCAPE Rooter Usage",
  "$ sudo ~/venv/bin/cape rooter\n\nCAPE Rooter Usage\n\nUsing the CAPE Rooter is pretty easy. If you know how to start it, you're good to go. Even though CAPE talks with the CAPE Rooter for each analysis with a routing option other than routing_none, the CAPE Rooter does not keep any state or attach to any CAPE instance in particular.\n\nIt is therefore that once the CAPE Rooter has been started you may leave it be - the CAPE Rooter will take care of itself from that point onwards, no matter how often you restart your CAPE instance.",
  "CAPE advanced administration\n\nWIP YET!\n\nEverything is easy when you have one server. But when you have many servers or even cluster some parts become more complicated. And when you run your private fork due to custom parts of CAPE, is where the challenge start. For that reason I wrote admin/admin.py. With this utility script you can do a lot of different interesting things that @doomedraven faced with his CAPE clusters. Just to mention some:\n\nServers in different networks that requires different SSH pivoting.\n\nDeploy 1 or N modified number of files (to be pushed to repo) or that was merged by another person and you need to deploy it after git pull.\n\nCompare upstream repo to your private fork or to list of files on your servers. This helps spot badly deployed files, where sha256 doesn't match.\n\nExecute commands on all servers.\n\nPull files.\n\nSee -h for the rest of your options\n\nDependencies",
  "Execute commands on all servers.\n\nPull files.\n\nSee -h for the rest of your options\n\nDependencies\n\nYou need to add your ssh key to .ssh/authorized_keys. I personally suggest to add it under root user.\n\nSSH Pivoting explained\n\nSSH pivoting is when you access to one server using another as proxy. In case if you need deeper explanation of this. Google it! admin.py support two types of of pivoting, simple and more complex. You need to configure admin/admin_conf.py\n\nComparing files\n\nThe idea of this is to spot files that doesn't match and fix them. Right now only deletion works, but in future it will support deploying of mismatched files.",
  "In case you use your own fork of CAPE. Is good to compare from time to time that you didn't miss any update and have all files properly updated. Some of us will have made custom mods to some files as for example: file_extra_info.py for example. You can exclude them in config under EXCLUDE_FILENAMES. Also another known problem that most advanced users will have their own YARA rules, config extractors, etc. For that my personal suggestion is to use prefix of your choice in that way you can filter them out in config with EXCLUDE_PREFIX. To generate repositories listing run:\n\npoetry run python admin/admin.py -gfl <path to private fork> --filename <Your fork name>\n\npoetry run python admin/admin.py -gfl <path to upstream repo> --filename upstream\n\nThe rest of the possibilities",
  "Analysis Packages\n\nThe analysis packages are a core component of CAPE Sandbox. They consist of structured Python classes that, when executed in the guest machines, describe how CAPE's analyzer component should conduct the analysis.\n\nCAPE provides some default analysis packages that you can use, but you can create your own or modify the existing ones. You can find them at analyzer/windows/modules/packages/.\n\nAs described in ../usage/submit, you can specify some options to the analysis packages in the form of key1=value1,key2=value2. The existing analysis packages already include some default options that can be enabled.\n\nThe following is a list of the existing packages in alphabetical order:\n\naccess: used to run and analyze Microsoft Office Access files via msaccess.exe.\n\napplet: used to run and analyze Java applets via firefox.exe or iexplore.exe.\n\narchive: used to run and analyze archives such as ISO, VHD and anything else that 7-Zip can extract via 7z.exe.",
  "Explanation how it works can be found in this Technical Session for CyberShock 2022, presented by CCCS.\n\nNB: Passing file= as a task option will ensure that the entire archive is passed to the victim VM and extracted there, prior to executing files of interest within in the extracted folder.\n\nchm: used to run and analyze Microsoft Compiled HTML Help files via hh.exe.\n\nchrome: used to open the given URL via chrome.exe.\n\nchromium: used to open the given URL via the Chromium version of chrome.exe.\n\ncpl: used to run and analyze Control Panel Applets via control.exe.\n\ndll: used to run and analyze Dynamically Linked Libraries via rundll32.exe.\n\ndoc_antivm: used to run and analyze Microsoft Word documents via winword.exe or wordview.exe.\n\nNB: Multiple applications are executed prior to the sample's execution, to prevent certain anti-vm techniques.\n\ndoc: used to run and analyze Microsoft Word documents via winword.exe.",
  "doc: used to run and analyze Microsoft Word documents via winword.exe.\n\ndoc2016: used to run and analyze Microsoft Word documents via Microsoft Office 2016's winword.exe.\n\nedge: used to open the given URL via msedge.exe.\n\neml: used to run and analyze Electronic Mail files via outlook.exe.\n\nexe: default analysis package used to run and analyze generic Windows executables.\n\nfirefox: used to open the given URL via firefox.exe.\n\ngeneric: used to run and analyze generic samples via cmd.exe.\n\nhta: used to run and analyze HTML Applications via mshta.exe.\n\nhwp: used to run and analyze Hangul Word Processor files via hwp.exe or hword.exe.\n\nichitaro: used to run and analyze Ichitaro Word Processor files via taroview.exe.\n\nie: used to open the given URL via iexplore.exe.\n\ninp: used to run and analyze Inpage Word Processor files via inpage.exe.\n\njar: used to run and analyze Java JAR containers via java.exe.\n\njs_antivm: used to run and analyze JavaScript and JScript Encoded files via wscript.exe.",
  "js_antivm: used to run and analyze JavaScript and JScript Encoded files via wscript.exe.\n\nNB: This package opens 20 Calculator windows prior to execution, to prevent certain anti-vm techniques.\n\njs: used to run and analyze JavaScript and JScript Encoded files via wscript.exe.\n\nNB: This package opens 20 Calculator windows prior to .jse execution, to prevent certain anti-vm techniques.\n\nlnk: used to run and analyze Windows Shortcuts via cmd.exe.\n\nmht: used to run and analyze MIME HTML files via iexplore.exe.\n\nmsbuild: used to run and analyze Microsoft Build Engine files via msbuild.exe.\n\nmsg: used to run and analyze Outlook Message Item files via outlook.exe.\n\nmsi: used to run and analyze Windows Installer Package files via msiexec.exe.\n\nnsis: used to run and analyze Nullsoft Scriptable Install System files via cmd.exe.\n\nollydbg: used to run and analyze generic samples via ollydbg.exe.\n\nNB: The ollydbg.exe application must be in the analyzer's bin directory.",
  "NB: The ollydbg.exe application must be in the analyzer's bin directory.\n\none: used to run and analyze Microsoft OneNote documents via onenote.exe.\n\npdf: used to run and analyze PDF documents via acrord32.exe.\n\nppt: used to run and analyze Microsoft PowerPoint documents via powerpnt.exe.\n\nppt2016: used to run and analyze Microsoft PowerPoint documents via Microsoft Office 2016's powerpnt.exe.\n\nps1_x64: used to run and analyze PowerShell scripts via powershell.exe in SysNative.\n\nNB: This package uses the powershell.exe in SysNative.\n\nps1: used to run and analyze PowerShell scripts via powershell.exe in System32.\n\nNB: This package uses the powershell.exe in System32.\n\npub: used to run and analyze Microsoft Publisher documents via mspub.exe.\n\npub2016: used to run and analyze Microsoft Publisher documents via Microsoft Office 2016's mspub.exe.\n\npython: used to run and analyze Python scripts via py.exe or python.exe.",
  "python: used to run and analyze Python scripts via py.exe or python.exe.\n\nrar: extracts WinRAR Compressed Archive files via the rarfile Python package, and runs an executable file (if it exists), with cmd.exe.\n\nNB: The rarfile Python package must be installed on the guest.\n\nreg: used to run and analyze Registry files via reg.exe.\n\nregsvr: used to run and analyze Dynamically Linked Libraries via regsvr32.exe.\n\nsct: used to run and analyze Windows Scriptlet files via regsvr32.exe.\n\nservice_dll: used to run and analyze Service Dynamically Linked Libraries via sc.exe.\n\nservice: used to run and analyze Services via sc.exe.\n\nshellcode_x64: used to run and analyze Shellcode via the 64-bit CAPE loader.\n\nshellcode: used to run and analyze Shellcode via the 32-bit CAPE loader, with unpacking!\n\nswf: used to run and analyze Shockwave Flash via flashplayer.exe.\n\nNB: You need to have flashplayer.exe in the analyzer's bin folder.",
  "NB: You need to have flashplayer.exe in the analyzer's bin folder.\n\nvbejse: used to run and analyze VBScript Encoded and JScript Encoded files via wscript.exe.\n\nvbs: used to run and analyze VBScript and VBScript Encoded files via wscript.exe.\n\nwsf: used to run and analyze Windows Script Files via wscript.exe.\n\nxls: used to run and analyze Microsoft Excel documents via excel.exe.\n\nxls2016: used to run and analyze Microsoft Excel documents via Microsoft Office 2016's excel.exe.\n\nxslt: used to run and analyze eXtensible Stylesheet Language Transformation Files via wmic.exe.\n\nxps: used to run and analyze XML Paper Specification Files via xpsrchvw.exe.\n\nzip_compound: used to run and analyze Zip archives with more specific settings.\n\nNB: Either file option must be set, or a __configuration.json file must be present in the zip file. Sample json file:",
  "{\n    \"path_to_extract\": {\n        \"a.exe\": \"%USERPROFILE%\\\\Desktop\\\\a\\\\b\\\\c\",\n        \"folder_b\": \"%appdata%\"\n    },\n    \"target_file\":\"a.exe\"\n}\n\nzip: extract Zip archives via the zipfile Python package, and runs an executable file (if it exists), with cmd.exe.\n\nYou can find more details on how to start creating analysis packages in the ../customization/packages customization chapter.\n\nAs you already know, you can select which analysis package to use by specifying its name at submission time (see submit) as follows:\n\n$ ./utils/submit.py --package <package name> /path/to/malware\n\nIf no package is specified, CAPE will try to detect the file type and select the correct analysis package accordingly. If the file type is not supported by default, the analysis will be aborted. Therefore we encourage to specify the package name whenever possible.\n\nFor example, to launch a malware sample and specify some options you can do:",
  "For example, to launch a malware sample and specify some options you can do:\n\n$ ./utils/submit.py --package dll --options function=FunctionName,loader=explorer.exe /path/to/malware.dll",
  "Pattern replacement\n\nReplace/discard any host/network pattern.\n\nCleaning Operation system patterns.\n\nPut your patterns inside of data/safelist/replacepatterns.py\n\nCleaning Network patterns as IP(s)/Domains.",
  "Submit an Analysis\n\nsubmitpy\n\napipy\n\ndistpy\n\nwebpy\n\npython\n\nSubmission Utility\n\nThe easiest way to submit an analysis is to use the provided submit.py command-line utility. It currently has the following options available:\n\nusage: submit.py [-h] [--remote REMOTE] [--url] [--package PACKAGE]\n                 [--custom CUSTOM] [--timeout TIMEOUT] [--options OPTIONS]\n                 [--priority PRIORITY] [--machine MACHINE]\n                 [--platform PLATFORM] [--memory] [--enforce-timeout]\n                 [--clock CLOCK] [--tags TAGS] [--max MAX] [--pattern PATTERN]\n                 [--shuffle] [--unique] [--quiet]\n                 target\n\npositional arguments:\n  target               URL, path to the file or folder to analyze",
  "optional arguments:\n  -h, --help           show this help message and exit\n  --remote REMOTE      Specify IP:port to a CAPE API server to submit\n                       remotely\n  --url                Specify whether the target is an URL\n  --package PACKAGE    Specify an analysis package\n  --custom CUSTOM      Specify any custom value\n  --timeout TIMEOUT    Specify an analysis timeout\n  --options OPTIONS    Specify options for the analysis package (e.g.\n                       \"name=value,name2=value2\")\n  --priority PRIORITY  Specify a priority for the analysis represented by an\n                       integer\n  --machine MACHINE    Specify the identifier of a machine you want to use\n  --platform PLATFORM  Specify the operating system platform you want to use\n                       (windows/darwin/linux)\n  --memory             Enable to take a memory dump of the analysis machine\n  --enforce-timeout    Enable to force the analysis to run for the full\n                       timeout period",
  "timeout period\n  --clock CLOCK        Set virtual machine clock\n  --tags TAGS          Specify tags identifier of a machine you want to use\n  --max MAX            Maximum samples to add in a row\n  --pattern PATTERN    Pattern of files to submit\n  --shuffle            Shuffle samples before submitting them\n  --unique             Only submit new samples, ignore duplicates\n  --quiet              Only print text on failure",
  "If you specify a directory as the target path, all of the files contained within that directory will be submitted for analysis.\n\nThe concept of analysis packages will be dealt with later in this documentation (at packages). The following are some examples of how to use the submit.py tool:\n\nWarning\n\nRemember to use the cape user. The following commands are executed as cape.\n\nExample: Submit a local binary:\n\n$ poetry run python utils/submit.py /path/to/binary\n\nExample: Submit an URL:\n\n$ poetry run python utils/submit.py --url http://www.example.com\n\nExample: Submit a local binary and specify a higher priority:\n\n$ poetry run python utils/submit.py --priority 5 /path/to/binary\n\nExample: Submit a local binary and specify a custom analysis timeout of 60 seconds:\n\n$ poetry run python utils/submit.py --timeout 60 /path/to/binary\n\nExample: Submit a local binary and specify a custom analysis package:\n\n$ poetry run python utils/submit.py --package <name of package> /path/to/binary",
  "$ poetry run python utils/submit.py --package <name of package> /path/to/binary\n\nExample: Submit a local binary and specify a custom analysis package and some options (in this case a command line argument for the malware):\n\n$ poetry run python utils/submit.py --package exe --options arguments=--dosomething /path/to/binary.exe\n\nExample: Submit a local binary to be run on the virtual machine cape1:\n\n$ poetry run python utils/submit.py --machine cape1 /path/to/binary\n\nExample: Submit a local binary to be run on a Windows machine:\n\n$ poetry run python utils/submit.py --platform windows /path/to/binary\n\nExample: Submit a local binary and take a full memory dump of the analysis machine once the analysis is complete:\n\n$ poetry run python utils/submit.py --memory /path/to/binary\n\nExample: Submit a local binary and force the analysis to be executed for the full timeout (disregarding the internal mechanism that CAPE uses to decide when to terminate the analysis):",
  "$ poetry run python utils/submit.py --enforce-timeout /path/to/binary\n\nExample: Submit a local binary and set the virtual machine clock. The format is %m-%d-%Y %H:%M:%S. If not specified, the current time is used. For example, if we want to run a sample on January 24th, 2001, at 14:41:20:\n\n$ poetry run python utils/submit.py --clock \"01-24-2001 14:41:20\" /path/to/binary\n\nExample: Submit a sample for Volatility analysis (to reduce side effects of the CAPE hooking, switch it off with options free=True):\n\n$ poetry run python utils/submit.py --memory --options free=True /path/to/binary\n\n--options Options Available\n\nfilename: Rename the sample file\n\nname: This will force family extractor to run, Ex: name=trickbot\n\nexecutiondir: Sets directory to launch the file from. Need not be the same as the directory of sample file. Defaults to %TEMP% if both executiondir and curdir are not specified. Only supports full paths\n\nfree: Run without monitoring (disables many capabilities) Ex: free=1",
  "free: Run without monitoring (disables many capabilities) Ex: free=1\n\nforce-sleepskip: Override default sleep skipping behavior: 0 disables all sleep skipping, 1 skips all sleeps.\n\nfull-logs: By default, logs prior to network activity for URL analyses and prior to access of the file in question for non-executable formats are suppressed. Set to 1 to disable log suppression.\n\nforce-flush: For performance reasons, logs are buffered before being sent back to the result server. We make every attempt to flush the buffer at critical points including when exceptions occur, but in some rare termination scenarios, logs may be lost. Set to 1 to force flushing of the log buffers after any non-duplicate API is called, set to 2 to force flushing of every log.\n\nno-stealth: Set to 1 to disable anti-anti-VM/sandbox code enabled by default.\n\nbuffer-max: When set to an integer of your choice, changes the maximum number of bytes that can be logged for most API buffers.",
  "large-buffer-max: Some hooked APIs permit larger buffers to be logged. To change the limit for this, set this to an integer of your choice.\n\nnorefer: Disables use of a fake referrer when performing URL analyses\n\nfile: When using the zip or rar package, set the name of the file to execute\n\npassword: When using the zip or rar package, set the password to use for extraction. Also used when analyzing password-protected Office documents.\n\nfunction: When using the dll package, set the name of the exported function to execute\n\ndllloader: When using the dll package, set the name of the process loading the DLL (defaults to rundll32.exe).\n\narguments: When using the dll, exe, or python packages, set the arguments to be passed to the executable or exported function.\n\nappdata: When using the exe package, set to 1 to run the executable out of the Application Data path instead of the Temp directory.",
  "startbrowser: Setting this option to 1 will launch a browser 30 seconds into the analysis (useful for some banking trojans).\n\nbrowserdelay: Sets the number of seconds to wait before starting the browser with the startbrowser option. Defaults to 30 seconds.\n\nurl: When used with the startbrowser option, this will determine the URL the started browser will access.\n\ndebug: Set to 1 to enable reporting of critical exceptions occurring during analysis, set to 2 to enable reporting of all exceptions.\n\ndisable_hook_content: Set to 1 to remove functionality of all hooks except those critical for monitoring other processes. Set to 2 to apply to all hooks.\n\nhook-type: Valid for 32-bit analyses only. Specifies the hook type to use: direct, indirect, or safe. Safe attempts a Detours-style hook.\n\nserial: Spoof the serial of the system volume as the provided hex value\n\nsingle-process: When set to 1 this will limit behavior monitoring to the initial process only.",
  "single-process: When set to 1 this will limit behavior monitoring to the initial process only.\n\nexclude-apis: Exclude the colon-separated list of APIs from being hooked\n\nexclude-dlls: Exclude the colon-separated list of DLLs from being hooked\n\ndropped-limit: Override the default dropped file limit of 100 files\n\ncompression: When set to 1 this will enable CAPE's extraction of compressed payloads\n\nextraction: When set to 1 this will enable CAPE's extraction of payloads from within each process\n\ninjection: When set to 1 this will enable CAPE's capture of injected payloads between processes\n\ncombo: This combines compression, injection and extraction with process dumps\n\ndump-on-api: Dump the calling module when a function from the colon-separated list of APIs is used\n\nbp0: Sets breakpoint 0 (processor/hardware) to a VA or RVA value (or module::export). Applies also to bp1-bp3.\n\nfile-offsets: Breakpoints in bp0-bp3 will be interpreted as PE file offsets rather than RVAs",
  "file-offsets: Breakpoints in bp0-bp3 will be interpreted as PE file offsets rather than RVAs\n\nbreak-on-return: Sets breakpoints on the return address(es) from a colon-separated list of APIs\n\nbase-on-api: Sets the base address to which breakpoints will be applied (and sets breakpoints)\n\ndepth: Sets the depth an instruction trace will step into (defaults to 0, requires Trace package)\n\ncount: Sets the number of instructions in a trace (defaults to 128, requires Trace package)\n\nreferrer: Specify the referrer to be used for URL tasks, overriding the default Google referrer\n\nloop_detection: Set this option to 1 to enable loop detection (compress call logs - behavior analysis)\n\nstatic: Check if config can be extracted statically, if not, send to vm\n\nDl&Exec add headers: Example: dnl_user_agent: \"CAPE Sandbox\", dnl_referrer: google\n\nservicedesc - for service package: Service description\n\narguments - for service package: Service arguments",
  "arguments - for service package: Service arguments\n\nstore_memdump: Will force STORE memdump, only when submitting to analyzer node directly, as distributed cluster can modify this\n\npre_script_args: Command line arguments for pre_script. Example: pre_script_args=file1 file2 file3\n\npre_script_timeout: pre_script_timeout will default to 60 seconds. Script will stop after timeout Example: pre_script_timeout=30\n\nduring_script_args: Command line arguments for during_script. Example: during_script_args=file1 file2 file3\n\npwsh: - for ps1 package: prefer PowerShell Core, if available in the vm\n\ncheck_shellcode: - Setting check_shellcode=0 will disable checking for shellcode during package identification and extracting from archive\n\nunhook-apis: - capability to dynamically unhook previously hooked functions (unhook-apis option takes colon-separated list e.g. unhook-apis=NtSetInformationThread:NtDelayExecution)",
  "ttd: - ttd=1. TTD integration (Microsoft Time Travel Debugging). Place TTD binaries in analyzer/windows/bin (with wow64 subdirectory for 32-bit). .trc files output to TTD directory in results folder for manual retrieval\n\nWeb Interface\n\nDetailed usage of the web interface is described in web.\n\nAPI\n\nDetailed usage of the REST API interface is described in api.\n\nDistributed CAPE\n\nDetailed usage of the Distributed CAPE API interface is described in dist.\n\nPython Functions\n\nTo keep track of submissions, samples, and overall execution, CAPE uses a popular Python ORM called SQLAlchemy that allows you to make the sandbox use PostgreSQL, SQLite, MySQL, and several other SQL database systems.\n\nCAPE is designed to be easily integrated into larger solutions and to be fully automated. To automate analysis submission we suggest using the REST API interface described in api, but in case you want to write a Python submission script, you can also use the add_path() and add_url() functions.",
  "add_path(file_path[, timeout=0[, package=None[, options=None[, priority=1[, custom=None[, machine=None[, platform=None[, memory=False[, enforce_timeout=False], clock=None[]]]]]]]]])\n\nAdd a local file to the list of pending analysis tasks. Returns the ID of the newly generated task.\n\nExample usage:\n\n>>> from lib.cuckoo.core.database import Database\n>>> db = Database()\n>>> db.add_path(\"/tmp/malware.exe\")\n1\n>>>\n\nadd_url(url[, timeout=0[, package=None[, options=None[, priority=1[, custom=None[, machine=None[, platform=None[, memory=False[, enforce_timeout=False], clock=None[]]]]]]]]])\n\nAdd a local file to the list of pending analysis tasks. Returns the ID of the newly generated task.\n\nExample Usage:\n\n>>> from lib.cuckoo.core.database import Database\n>>> db = Database()\n>>> db.add_url(\"http://www.cuckoosandbox.org\")\n2\n>>>\n\nTroubleshooting\n\nsubmit.py\n\nIf you try to submit an analysis using submit.py and your output looks like:",
  "submit.py\n\nIf you try to submit an analysis using submit.py and your output looks like:\n\n$ sudo -u cape poetry run python submit.py /path/to/binary/test.exe\nError: adding task to database\n\nIt could be due to errors while trying to communicate with the PostgreSQL instance. PostgreSQL is installed and configured by default when executing cape2.sh. Make sure your PostgreSQL instance is active and running. To check it out execute the following command:\n\n$ sudo systemctl status postgresql\n\nIf the status is other than Active (it can be in exited status, as long as it is Active), there is something that needs to be fixed.\n\nThe logs for PostgreSQL can be found under /var/log/postgresql/*.log.\n\nIf everything is working regarding PostgreSQL, make sure the cape user is able to access (both read and write) the directories involved in the analysis. For example, cape must be able to read and write in /tmp.\n\nAnalysis results\n\nCheck analysis_results.",
  "CAPE's debugger\n\nCAPE's debugger is one of the most powerful features of the sandbox: a programmable debugger configured at submission by either Yara signature or submission options, allowing breakpoints to be set dynamically. This allows instruction traces of malware execution to be captured, as well as configuring actions to perform such as control flow manipulation for anti-sandbox bypasses, or dumping decrypted config regions or unpacked payloads.\n\nWhat make CAPE's debugger unique among Windows debuggers is the fact that it has been built with minimal (almost zero) use of Windows debugging interfaces specifically for the purpose of malware analysis. Its goal is to make maximal use of the processor's debugging hardware but to avoid Windows interfaces which are typically targeted by anti-debug techniques.\n\nThe debugger is not interactive, its actions are pre-determined upon submission and the results can be found in the debugger log which is presented in a dedicated tab in the UI.",
  "Th following is a quick guide on getting started with the debugger.\n\nBreakpoints: bp0, bp1, bp2, bp3\n\nThe most important feature of the debugger is the ability to set and catch hardware breakpoints using the debug registers of the CPU. There are four breakpoints slots in the Intel CPU to make use of, however it's worth noting that there is no help from the hardware for implemening a debugger feature like stepping over calls, so to achieve this one of the four breakpoints is needed. There are instructions (such as syscalls) which cannot be stepped into, so which must be stepped over. So to allow this as well as stepping over calls via the 'depth' option, at least one breakpoint must be kept free. For more background information on the hardware used here see: https://en.wikipedia.org/wiki/X86_debug_register.",
  "Breakpoints are set using the options bp0, bp1, bp2 and bp3, supplying an RVA value. For example bp0=0x1234. The image base for the RVAs can be set dynamically in a number of ways, please see the remainder of the documentation.\n\nIn order to break on entry point, the option can be to set to 'ep': bp0=ep.This will instruct the debugger to break on the entry point of the main executable of each process and begin tracing. (In the case of a DLL, this breakpoint will also be set on the entry point of the DLL).\n\nDepth\n\nIn single-step mode, the behaviour of a trace can be characterised in terms of whether it steps into a call, or over it. From this comes the concept of depth; the debugger will trace at the same depth in a trace by stepping-over calls to deeper functions. Thus if we set a depth of zero (which is also the default) the behaviour will be to step over all the subsequent calls (at least until a ret is encountered):\n\ndepth=0",
  "depth=0\n\nIf we set a depth of, say, three, then the debugger will step into calls into further levels of depth three times:\n\ndepth=3\n\nCount\n\nAnother important characteristic of a trace is its length or count of instructions. This is set with the count option, for example:\n\ncount=10000\n\nThe count may also be specified as hexadecimal:\n\ncount=0xff00\n\nThe default count is 0x4000.\n\nBreak-on-return\n\nSometimes it might be more convenient or quicker to take advantage of the fact that a certain API call is made from an interesting code region, with its return or 'caller' address to the region in question accompanying the API output in the behavior log. We can tell the debugger to use that return address as a breakpoint with the break-on-return option, for example:\n\nbreak-on-return=RtlDecompressBuffer\n\nBase-on-api",
  "break-on-return=RtlDecompressBuffer\n\nBase-on-api\n\nInstead of breaking directly on the return address of an API, we may just wish to base our breakpoints on the same base address as a particular API. For this we use the base-on-api option, for example: * base-on-api=NtSetInformationThread\n\nThis option requires that the breakpoint RVA value be specified by one of the breakpoint options (bp, br).\n\nBase-on-alloc",
  "Base-on-alloc\n\nAn obvious restriction using this method is that the API call from which the image base is determined must be made before the code we wish to put a breakpoint on is executed. For this reason, there exists an alternative option, base-on-alloc, which will attempt to set the breakpoint RVA relative to every newly executable region (whether through allocation or protection). The advantage of this method is that the breakpoint will always be set before the code can execute, but the downside is that breakpoints may repeatedly be set needlessly with allocations that are not of interest. This is simply set by the option: * base-on-alloc=1\n\nActions",
  "Actions\n\nOften we might wish to perform an action when a breakpoint is hit. These actions can be defined by the actions: action0, action1, action2, and action3, each corresponding to a respective breakpoint. The action is specified by a simple string (not case sensitive). The list of actions is constantly growing, so if the need arises for further actions, they can be simply added.\n\nThe list of actions and their implementation can be found in Trace.c of Capemon(CAPE's monitor), specifically in the ActionDispatcher. It would be really easy to add additionnal actions and there is a lot of other gadgets which could be added there depending on the needs of the debugger's user.\n\nType\n\nAlthough the debugger defaults to execution breakpoints, it is also possible to set data breakpoints either for read-only, or both read & write. This is specified with the options: type0, type1, type2, and type3 for the corresponding breakpoint. The type option uses the following values:\n\nr - read only",
  "r - read only\n\nw - write and read\n\nx - execution\n\nbr0, br1, br2, br3\n\nSometimes it may be convenient to set a breakpoint on the return address of a function, for example when it might be easier to write a YARA signature to detect a function but when you wish to break after it has been executed. For this, the br options exist, where br0 will set a breakpoint on the return address of the function at the supplied address. The format for the address is the same as the one for breakpoints mentionned above. Since the return address (for the breakpoint) is fetched from the top of the stack, the addresses supplied must either be the very first instruction of the function or certainly must come before any instruction that modifies the stack pointer such as push or pop.\n\nFake-rdtsc\n\nThis advanced feature is there for interacting with the TSC register. To learn more on it and what it's used for see: https://en.wikipedia.org/wiki/Time_Stamp_Counter.",
  "To 'emulate' (skip and fake) the rdtsc instruction, the option fake-rdtsc=1 may be set. This will only have an affect on rdtsc instructions that are traced over by the debugger. If the debugger is not tracing at the time the CPU executes the instruction, it cannot of course fake the return value.\n\nThe effect of this setting is to allow the first traced rdtsc instruction to execute normally, but thereafter to fake the return value with the original return value plus whatever value is specified in the option. For example:\n\n'rdtsc=0x1000'\n\nThis will result in each subsequent rdtsc instruction after the first being faked with a value that has incremented by 0x1000.\n\nPractical examples\n\nFor more and the most up-to-date versions of examples please see https://github.com/kevoreilly/CAPEv2/tree/master/analyzer/windows/data/yara",
  "rule Guloader\n{\n    meta:\n        author = \"kevoreilly\"\n        description = \"Guloader bypass\"\n        cape_options = \"bp0=$trap0,bp0=$trap1+4,action0=skip,bp1=$trap2+11,bp1=$trap3+19,action1=skip,bp2=$antihook,action2=goto:ntdll::NtAllocateVirtualMemory,count=0,\"\n    strings:\n        $trap0 = {0F 85 [2] FF FF 81 BD ?? 00 00 00 [2] 00 00 0F 8F [2] FF FF 39 D2 83 FF 00}\n        $trap1 = {49 83 F9 00 75 [1-20] 83 FF 00 [2-6] 81 FF}\n        $trap2 = {39 CB 59 01 D7 49 85 C8 83 F9 00 75 B3}\n        $trap3 = {61 0F AE E8 0F 31 0F AE E8 C1 E2 20 09 C2 29 F2 83 FA 00 7E CE C3}\n        $antihook = {FF 34 08 [0-48] 8F 04 0B [0-80] 83 C1 04 83 F9 18 75 [0-128] FF E3}\n    condition:\n        2 of them\n}",
  "rule GuloaderB\n{\n    meta:\n        author = \"kevoreilly\"\n        description = \"Guloader bypass 2021 Edition\"\n        cape_options = \"bp0=$trap0+12,action0=ret,bp1=$trap1,action1=ret2,bp2=$antihook,action2=goto:ntdll::NtAllocateVirtualMemory,count=0,\"\n    strings:\n        $trap0 = {81 C6 00 10 00 00 81 FE 00 F0 FF 7F 0F 84 [2] 00 00}\n        $trap1 = {31 FF [0-24] (B9|C7 85 F8 00 00 00) 60 5F A9 00}\n        $antihook = {FF 34 08 [0-48] 8F 04 0B [0-80] 83 C1 04 83 F9 18 75 [0-128] FF E3}\n    condition:\n        2 of them\n}\n\nrule Pafish\n{\n    meta:\n        author = \"kevoreilly\"\n        description = \"Pafish bypass\"\n        cape_options = \"bp0=$rdtsc_vmexit-2,action0=SetZeroFlag,count=1\"\n    strings:\n        $rdtsc_vmexit = {8B 45 E8 80 F4 00 89 C3 8B 45 EC 80 F4 00 89 C6 89 F0 09 D8 85 C0 75 07}\n    condition:\n        uint16(0) == 0x5A4D and $rdtsc_vmexit\n}",
  "rule Ursnif3\n{\n    meta:\n        author = \"kevoreilly\"\n        description = \"Ursnif Config Extraction\"\n        cape_options = \"br0=$crypto32-73,instr0=cmp,dumpsize=eax,action0=dumpebx,dumptype0=0x24,count=1\"\n    strings:\n        $golden_ratio = {8B 70 EC 33 70 F8 33 70 08 33 30 83 C0 04 33 F1 81 F6 B9 79 37 9E C1 C6 0B 89 70 08 41 81 F9 84 00 00 00}\n        $crypto32_1 = {8B C3 83 EB 01 85 C0 75 0D 0F B6 16 83 C6 01 89 74 24 14 8D 58 07 8B C2 C1 E8 07 83 E0 01 03 D2 85 C0 0F 84 AB 01 00 00 8B C3 83 EB 01 85 C0 89 5C 24 20 75 13 0F B6 16 83 C6 01 BB 07 00 00 00}\n        $crypto32_2 = {8B 45 EC 0F B6 38 FF 45 EC 33 C9 41 8B C7 23 C1 40 40 D1 EF 75 1B 89 4D 08 EB 45}\n    condition:\n        ($golden_ratio) and any of ($crypto32*)\n}",
  "As shown in the example above, the debugger options are passed in the cape_options section of yar files in the analyzer of CAPE but could be passed to the submission itself like other parameters. It is important to note that even through it appear that br0 and br1 would have multiple values in the Guloader rule above, it is not the case and it's not possible to assign multiples values to them. This is because the yara is designed with an assumption in mind: the patterns $trap0 and $trap1 should never appear concurrently in the same sample. This particular sig is designed to deal with two variants of the same malware where bp0 and bp1 will only ever be set to either one of those values.\n\nImporting instruction traces into disassembler\n\nIt is possible to import CAPE's debugger output into a dissassembler. One example procedure is as follow:\n\nHighlight CFG in disassembler:",
  "Highlight CFG in disassembler:\n\n1 Install lighthouse plugin from\n    pip3 install git+https://github.com/kevoreilly/lighthouse\n2 Load payload into IDA\n3 Check image base matches that from debugger log (if not rebase)\n4 Go to File -> Load File -> Code coverage file and load debugger logfile (ignore any warnings - any address outside image base causes these)\n\nimage",
  "Clean all Tasks and Samples\n\nTo clean your setup, run -h to see available options:\n\n$ poetry run python utils/cleaners.py -h\n\nTo sum up, this command does the following:\n\nDelete analysis results.\n\nDelete submitted binaries.\n\nDelete all associated information of the tasks and samples in the configured database.\n\nDelete all data in the configured MongoDB (if configured and enabled in reporting.conf).\n\nDelete all data in ElasticSearch (if configured and enabled in reporting.conf).\n\nWarning\n\nIf you use this command you will delete permanently all data stored by CAPE in all storages: file system, SQL database, and MongoDB/ElasticSearch database. Use it only if you are sure you would clean up all the data.\n\nAfter executing the poetry run python cleaners.py --clean utility, you must restart CAPE service as it destroys the database.:\n\n$ sudo systemctl restart cape\n\nAfter any other option, you don't need to restart the service.",
  "Starting CAPE\n\nMake sure to run it inside CAPE's root directory:\n\n$ cd /opt/CAPEv2\n\nTo start CAPE, use the command:\n\n$ python3 cuckoo.py\n\nYou will get an output similar to this:\n\nCuckoo Sandbox 2.1-CAPE\nwww.cuckoosandbox.org\nCopyright (c) 2010-2015\n\nCAPE: Config and Payload Extraction\ngithub.com/kevoreilly/CAPEv2\n\n2020-07-06 10:24:38,490 [lib.cuckoo.core.scheduler] INFO: Using \"kvm\" machine manager with max_analysis_count=0, max_machines_count=10, and max_vmstartup_count=10\n2020-07-06 10:24:38,552 [lib.cuckoo.core.scheduler] INFO: Loaded 100 machine/s\n2020-07-06 10:24:38,571 [lib.cuckoo.core.scheduler] INFO: Waiting for analysis tasks.\n\nNow CAPE is ready to run and it's waiting for submissions.\n\ncuckoo.py accepts some command line options as shown by the help:\n\nusage: cuckoo.py [-h] [-q] [-d] [-v] [-a] [-t] [-m MAX_ANALYSIS_COUNT]",
  "usage: cuckoo.py [-h] [-q] [-d] [-v] [-a] [-t] [-m MAX_ANALYSIS_COUNT]\n\noptional arguments:\n-h, --help            show this help message and exit\n-q, --quiet           Display only error messages\n-d, --debug           Display debug messages\n-v, --version         show program's version number and exit\n-a, --artwork         Show artwork\n-t, --test            Test startup\n-m MAX_ANALYSIS_COUNT, --max-analysis-count MAX_ANALYSIS_COUNT\n                        Maximum number of analyses\n\nMost importantly --debug and --quiet respectively increase and decrease the logging verbosity.\n\nPoetry users\n\nIf you used poetry to install dependencies, you should launch cape with the following command:\n\n$ sudo -u cape poetry run python3 cuckoo.py\n\nIf you get any dependency-related error, make sure you execute the extra/libvirt_installer.sh script:\n\n$ sudo -u cape poetry run extra/libvirt_installer.sh\n\nTroubleshooting\n\nPermissionError: [Errno 13] Permission denied: '/opt/CAPEv2/log/cuckoo.log'",
  "Troubleshooting\n\nPermissionError: [Errno 13] Permission denied: '/opt/CAPEv2/log/cuckoo.log'\n\nYou are not executing the CAPE (cuckoo.py) file with the appropriate user.\n\nRemember that the user meant to execute CAPE is the cape user. In fact, after installing CAPE with cape2.sh, the directory should look similar to the following structure:\n\nimage\n\nIn order to execute CAPE as the cape user you can either launch a shell or execute the following command (notice the command is using Poetry):\n\n$ sudo -u cape poetry run python3 cuckoo.py\n\nCuckooCriticalError: Cannot bind ResultServer on port 2042 because it was in use, bailing\n\nCAPE is already running in the background as cape.service\n\nIf you want to see the logs in realtime printed to stdout, stop the service by running the following command:\n\n$ sudo systemctl stop cape.service\n\nand run cuckoo.py again\n\nCuckooCriticalError: Unable to bind Result server on <IP> [Errno 99]\n\nCheck the cuckoo.conf configuration file again.",
  "Check the cuckoo.conf configuration file again.\n\nYou will have to provide the host IP for the [resultserver], not the guest IP.\n\nStarting processing data generated by virtual machine\n\nSee -h for all latest options, for better customization:\n\nusage: process.py [-h] [-c] [-d] [-r] [-s] [-p PARALLEL] [-fp] [-mc MAXTASKSPERCHILD] [-md] [-pt PROCESSING_TIMEOUT] id\n\npositional arguments:\nid                    ID of the analysis to process (auto for continuous processing of unprocessed tasks).",
  "optional arguments:\n-h, --help            show this help message and exit\n-c, --caperesubmit    Allow CAPE resubmit processing.\n-d, --debug           Display debug messages\n-r, --report          Re-generate report\n-s, --signatures      Re-execute signatures on the report\n-p PARALLEL, --parallel PARALLEL\n                        Number of parallel threads to use (auto mode only).\n-fp, --failed-processing\n                        reprocess failed processing\n-mc MAXTASKSPERCHILD, --maxtasksperchild MAXTASKSPERCHILD\n                        Max children tasks per worker\n-md, --memory-debugging\n                        Enable logging garbage collection related info\n-pt PROCESSING_TIMEOUT, --processing-timeout PROCESSING_TIMEOUT\n                        Max amount of time spent in processing before we fail a task\n\nCommand example:\n\n$ python3 utils/process.py -p7 auto",
  "REST API\n\nTo see the current hosted REST API documentation head to /apiv2/. You will find all endpoints and details on how to do requests.\n\n`API example`: https://capesandbox.com/apiv2/\n\nTo enable the REST API, we use `django-rest-framework`:\n\n$ poetry run pip install djangorestframework\n\nTo generate a user authorization token:\n\n# Ensure you are in CAPE's web directory\ncd /opt/CAPEv2/web\n\n# To create super user aka admin\nsudo -u cape poetry run python3 manage.py createsuperuser\n\n# To create normal user, use web interface /admin/ (in case if you not changed path)\n\n# By hand, only required if auth enabled and user MUST exist\nsudo -u cape poetry run python3 manage.py drf_create_token <your_user>",
  "# Auto generation local or any public instance\ncurl -d \"username=<USER>&password=<PASSWD>\" http://127.0.0.1:8000/apiv2/api-token-auth/\ncurl -d \"username=<USER>&password=<PASSWD>\" https://capesandbox.com/apiv2/api-token-auth/\ncurl -d \"username=<USER>&password=<PASSWD>\" http(s)://<ANY_CAPE>/apiv2/api-token-auth/\n\n# Usage\nimport requests\n\nurl = 'http://127.0.0.1:8000/apiv2/<ENDPOINT>'\nheaders = {'Authorization': 'Token <YOUR_TOKEN>'}\nr = requests.get(url, headers=headers)\n\nCAPE throttling, aka requests per minute/hour/day.\n\nRequires token authentication enabled in api.conf\n\nDefault 5/m\n\nYou can change the default throttle limits in api.conf\n\nTo change the user limit go to django admin /admin/ if you didn't change the path, and set the limit per user in the user profile at the bottom.\n\nWarning\n\nAll documentation below this warning is deprecated.\n\napi.py DEPRECATED\n\nResources",
  "Warning\n\nAll documentation below this warning is deprecated.\n\napi.py DEPRECATED\n\nResources\n\nFollowing is a list of currently available resources and a brief description of each one. For details click on the resource name.",
  "Resource Description POST tasks_create_file Adds a file to the list of pending tasks to be processed and\nanalyzed. POST tasks_create_url Adds an URL to the list of pending tasks to be processed and\nanalyzed. GET tasks_list Returns the list of tasks stored in the internal Cuckoo database.\nYou can optionally specify a limit of entries to return. GET tasks_view Returns the details on the task assigned to the specified ID. GET tasks_delete Removes the given task from the database and deletes the\nresults. GET tasks_report Returns the report generated out of the analysis of the task\nassociated with the specified ID. You can optionally specify which\nreport format to return, if none is specified the JSON report will be\nreturned. GET tasks_shots Retrieves one or all screenshots associated with a given analysis\ntask ID. GET files_view Search the analyzed binaries by MD5 hash, SHA256 hash or internal ID",
  "task ID. GET files_view Search the analyzed binaries by MD5 hash, SHA256 hash or internal ID\n(referenced by the tasks details). GET files_get Returns the content of the binary with the specified SHA256\nhash. GET pcap_get Returns the content of the PCAP associated with the given task. GET machines_list Returns the list of analysis machines available to Cuckoo. GET machines_view Returns details on the analysis machine associated with the\nspecified name. GET cuckoo_status Returns the basic cuckoo status, including version and tasks\noverview",
  "/tasks/create/file\n\nPOST /tasks/create/file\n\nAdds a file to the list of pending tasks. Returns the ID of the newly created task.\n\nExample request .. code-block:: bash\n\ncurl -F file=@/path/to/file http://localhost:8090/tasks/create/file\n\nExample request using Python .. code-block:: python\n\nimport requests import json\n\nREST_URL = \"http://localhost:8090/tasks/create/file\" SAMPLE_FILE = \"/path/to/malware.exe\"\n\n# Add your code to error checking for request.status_code.\n\njson_decoder = json.JSONDecoder() task_id = json_decoder.decode(request.text)[\"task_id\"]\n\n# Add your code for error checking if task_id is None.\n\nExample response:\n\n{\n    \"task_id\" : 1\n}\n\n/tasks/create/url\n\nPOST /tasks/create/url\n\nAdds a file to the list of pending tasks. Returns the ID of the newly created task.\n\nExample request:\n\ncurl -F url=\"http://www.malicious.site\" http://localhost:8090/tasks/create/url\n\nExample request using Python .. code-block:: python\n\nimport requests import json",
  "Example request using Python .. code-block:: python\n\nimport requests import json\n\nREST_URL = \"http://localhost:8090/tasks/create/url\" SAMPLE_URL = \"http://example.org/malwr.exe\"\n\nmultipart_url = {\"url\": (\"\", SAMPLE_URL)} request = requests.post(REST_URL, files=multipart_url)\n\n# Add your code to error checking for request.status_code.\n\njson_decoder = json.JSONDecoder() task_id = json_decoder.decode(request.text)[\"task_id\"]\n\n# Add your code to error checking if task_id is None.\n\nExample response:\n\n{\n    \"task_id\" : 1\n}\n\n/tasks/list\n\nGET /tasks/list/ (int: limit) / (int: offset)\n\nReturns list of tasks.\n\nExample request:\n\ncurl http://localhost:8090/tasks/list\n\nExample response:",
  "{\n    \"tasks\": [\n        {\n            \"category\": \"url\",\n            \"machine\": null,\n            \"errors\": [],\n            \"target\": \"http://www.malicious.site\",\n            \"package\": null,\n            \"sample_id\": null,\n            \"guest\": {},\n            \"custom\": null,\n            \"priority\": 1,\n            \"platform\": null,\n            \"options\": null,\n            \"status\": \"pending\",\n            \"enforce_timeout\": false,\n            \"timeout\": 0,\n            \"memory\": false,\n            \"tags\": []\n            \"id\": 1,\n            \"added_on\": \"2012-12-19 14:18:25\",\n            \"completed_on\": null\n        },\n        {\n            \"category\": \"file\",\n            \"machine\": null,\n            \"errors\": [],\n            \"target\": \"/tmp/malware.exe\",\n            \"package\": null,\n            \"sample_id\": 1,\n            \"guest\": {},\n            \"custom\": null,\n            \"priority\": 1,\n            \"platform\": null,\n            \"options\": null,\n            \"status\": \"pending\",",
  "\"platform\": null,\n            \"options\": null,\n            \"status\": \"pending\",\n            \"enforce_timeout\": false,\n            \"timeout\": 0,\n            \"memory\": false,\n            \"tags\": [\n                        \"32bit\",\n                        \"acrobat_6\",\n                    ],\n            \"id\": 2,\n            \"added_on\": \"2012-12-19 14:18:25\",\n            \"completed_on\": null\n        }\n    ]\n}",
  "/tasks/view\n\nGET /tasks/view/ (int: id)\n\nReturns details on the task associated with the specified ID.\n\nExample request:\n\ncurl http://localhost:8090/tasks/view/1\n\nExample response:\n\n{\n    \"task\": {\n        \"category\": \"url\",\n        \"machine\": null,\n        \"errors\": [],\n        \"target\": \"http://www.malicious.site\",\n        \"package\": null,\n        \"sample_id\": null,\n        \"guest\": {},\n        \"custom\": null,\n        \"priority\": 1,\n        \"platform\": null,\n        \"options\": null,\n        \"status\": \"pending\",\n        \"enforce_timeout\": false,\n        \"timeout\": 0,\n        \"memory\": false,\n        \"tags\": [\n                    \"32bit\",\n                    \"acrobat_6\",\n                ],\n        \"id\": 1,\n        \"added_on\": \"2012-12-19 14:18:25\",\n        \"completed_on\": null\n    }\n}\n\n/tasks/delete\n\nGET /tasks/delete/ (int: id)\n\nRemoves the given task from the database and deletes the results.\n\nExample request:\n\ncurl http://localhost:8090/tasks/delete/1\n\n/tasks/report",
  "Example request:\n\ncurl http://localhost:8090/tasks/delete/1\n\n/tasks/report\n\nGET /tasks/report/ (int: id) / (str: format)\n\nReturns the report associated with the specified task ID.\n\nExample request:\n\ncurl http://localhost:8090/tasks/report/1\n\n/tasks/screenshots\n\nGET /tasks/screenshots/ (int: id) / (str: number)\n\nReturns one or all screenshots associated with the specified task ID.\n\nExample request:\n\nwget http://localhost:8090/tasks/screenshots/1\n\n/files/view\n\nGET /files/view/md5/ (str: md5)\n\nGET /files/view/sha256/ (str: sha256)\n\nGET /files/view/id/ (int: id)\n\nReturns details on the file matching either the specified MD5 hash, SHA256 hash or ID.\n\nExample request:\n\ncurl http://localhost:8090/files/view/id/1\n\nExample response:",
  "Example request:\n\ncurl http://localhost:8090/files/view/id/1\n\nExample response:\n\n{\n    \"sample\": {\n        \"sha1\": \"da39a3ee5e6b4b0d3255bfef95601890afd80709\",\n        \"file_type\": \"empty\",\n        \"file_size\": 0,\n        \"crc32\": \"00000000\",\n        \"ssdeep\": \"3::\",\n        \"sha256\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n        \"sha512\": \"cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e\",\n        \"id\": 1,\n        \"md5\": \"d41d8cd98f00b204e9800998ecf8427e\"\n    }\n}\n\n/files/get\n\nGET /files/get/ (str: sha256)\n\nReturns the binary content of the file matching the specified SHA256 hash.\n\nExample request:\n\ncurl http://localhost:8090/files/get/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 > sample.exe\n\n/pcap/get\n\nGET /pcap/get/ (int: task)\n\nReturns the content of the PCAP associated with the given task.\n\nExample request:",
  "Returns the content of the PCAP associated with the given task.\n\nExample request:\n\ncurl http://localhost:8090/pcap/get/1 > dump.pcap\n\n/machines/list\n\nGET /machines/list\n\nReturns a list with details on the analysis machines available to Cuckoo.\n\nExample request:\n\ncurl http://localhost:8090/machines/list\n\nExample response:\n\n{\n    \"machines\": [\n        {\n            \"status\": null,\n            \"locked\": false,\n            \"name\": \"cuckoo1\",\n            \"resultserver_ip\": \"192.168.56.1\",\n            \"ip\": \"192.168.56.101\",\n            \"tags\": [\n                        \"32bit\",\n                        \"acrobat_6\",\n                    ],\n            \"label\": \"cuckoo1\",\n            \"locked_changed_on\": null,\n            \"platform\": \"windows\",\n            \"snapshot\": null,\n            \"interface\": null,\n            \"status_changed_on\": null,\n            \"id\": 1,\n            \"resultserver_port\": \"2042\"\n        }\n    ]\n}\n\n/machines/view\n\nGET /machines/view/ (str: name)",
  "/machines/view\n\nGET /machines/view/ (str: name)\n\nReturns details on the analysis machine associated with the given name.\n\nExample request:\n\ncurl http://localhost:8090/machines/view/cuckoo1\n\nExample response:\n\n{\n    \"machine\": {\n        \"status\": null,\n        \"locked\": false,\n        \"name\": \"cuckoo1\",\n        \"resultserver_ip\": \"192.168.56.1\",\n        \"ip\": \"192.168.56.101\",\n        \"tags\": [\n                    \"32bit\",\n                    \"acrobat_6\",\n                ],\n        \"label\": \"cuckoo1\",\n        \"locked_changed_on\": null,\n        \"platform\": \"windows\",\n        \"snapshot\": null,\n        \"interface\": null,\n        \"status_changed_on\": null,\n        \"id\": 1,\n        \"resultserver_port\": \"2042\"\n    }\n}\n\n/cuckoo/status\n\nGET /cuckoo/status/\n\nReturns status of the cuckoo server.\n\nExample request:\n\ncurl http://localhost:8090/cuckoo/status\n\nExample response:",
  "Example request:\n\ncurl http://localhost:8090/cuckoo/status\n\nExample response:\n\n{\n    \"tasks\": {\n        \"reported\": 165,\n        \"running\": 2,\n        \"total\": 167,\n        \"completed\": 0,\n        \"pending\": 0\n    },\n    \"version\": \"1.0\",\n    \"protocol_version\": 1,\n    \"hostname\": \"Patient0\",\n    \"machines\": {\n        \"available\": 4,\n        \"total\": 5\n    }\n    \"tools\":[\"vanilla\"]\n}",
  "Performance\n\nThere are several ways to tune the CAPE performance\n\nProcessing\n\n\"Processing\" consists of three steps after the malware is executed in a VM. Those are\n\nprocessing of raw data\n\nsignature matching\n\nreporting\n\nProcessing can take up to 30 minutes if the original raw log is large. This is caused by many API calls in that log. Several steps will iterate through that API list which causes a slowdown. There are several ways to mitigate the impact:\n\nEvented signatures\n\nEvented signatures have a common loop through the API calls. Use them wherever possible and either switch the old-style signatures with their api-call loop or convert them to event based signatures\n\nReporting\n\nReports that contain the API log will also iterate through the list. De-activate reports you do not need. For automated environments switching off the html report will be a good choice.\n\nRam-boost",
  "Ram-boost\n\nRam boost can be switched on in the configuration (in conf/processing.conf -> ram_boost in [behavior]). This will keep the whole API list in Ram. Do that only if you have plenty of Ram (>20 GB for 8 VMs).",
  "CAPE internals\n\nCAPE base core components\n\ncuckoo.py or cape.service - Is in charge of schedule tasks, set proper routing, run them inside of the VM, etc\n\nutils/process.py or cape-processor.service - Is in charge of process the data generated inside of the VM.\n\nutils/rooter.py or cape-rooter.service - Is set proper iptables to route traffic from VM over exit node. As internet, proxy, vpn, etc.\n\nweb/manage.py or cape-web.service - Is web interface. It allows you to see reports if MongoDB or ElasticSearch is enabled, otherwise it only useful for restapi.\n\nCAPE advanced core components\n\nutils/dist.py or cape-dist.service - Allows you to have CAPE cluster with many different workers\n\nutils/fstab.py or cape-fstab.service - Utility for distributed CAPE with NFS mode. It automatically adds entries to /etc/fstab and mounts it. Useful for cloud setups as Google Cloud Platform (GCP) for auto scaling.\n\nHow CAPE processing works?",
  "How CAPE processing works?\n\nAll data processing is divided into stages where lib/cuckoo/core/plugins.py does the magic.\n\nCheck out lib/cuckoo/common/abstracts.py -> class <stage name> for all auxiliary functions that can help you make your code cleaner.\n\nCheck custom/conf/<stage name>.conf for all features/modules that you can enable/disable.",
  "Installation\n\nThis chapter explains how to install CAPE.\n\nNote\n\nThis documentation refers to Host as the underlying operating system on which you are running CAPE (generally being a GNU/Linux distribution) and to Guest as the Windows virtual machine used to run the isolated analysis.\n\nhost/index guest/index guest_physical/index upgrade",
  "Upgrade from a previous release\n\nCAPE Sandbox grows fast. In every release, features are added, fixed and/or removed. There are two ways to upgrade your CAPE: start from scratch or migrate your \"old\" setup. The suggested way to upgrade CAPE is to start from a fresh setup because it's easier and faster than migrating your old setup.\n\nUpgrade starting from scratch\n\nTo start from scratch you have to perform a fresh setup as described in index. The following steps are suggested:\n\nBack up your installation.\n\nRead the documentation shipped with the new release.\n\nMake sure to have installed all required dependencies, otherwise install them.\n\nDo a CAPE fresh installation of the Host components.\n\nReconfigure CAPE as explained in this book (copying old configuration files is not safe because options can change between releases).",
  "If you are using an external database instead of the default or you are using the MongoDb reporting module is suggested to start all databases from scratch, due to possible schema changes between CAPE releases.\n\nTest it!\n\nIf something goes wrong you probably failed to do some steps during the fresh installation or reconfiguration. Check again the procedure explained in this book.\n\nIt's not recommended to rewrite an old CAPE installation with the latest release files, as it might raise some problems because:\n\nYou are overwriting Python source files (.py) but Python bytecode files (.pyc) are still in place.\n\nThere are configuration file changes across the two versions, check our CHANGELOG file for added or removed configuration options.\n\nThe part of CAPE which runs inside guests (agent.py) may change.\n\nIf you are using an external database like the reporting module for MongoDb a change in the data schema may corrupt your database.\n\nMigrate your CAPE",
  "Migrate your CAPE\n\nThe following steps are suggested as a requirement to migrate your data:\n\nBack up your installation.\n\nRead the documentation shipped with the new release.\n\nMake sure to have installed all required dependencies, otherwise install them.\n\nDownload and extract the latest CAPE.\n\nReconfigure CAPE as explained in this book (copying old configuration files is not safe because options can change between releases), and update the agent in your virtual machines.\n\nCopy from your backup \"storage\" and \"db\" folders. (Reports and analyses already present in \"storage\" folder will keep the old format.)\n\nNow setup Alembic (the framework used for migrations) and dateutil with:\n\npoetry run pip install alembic\npoetry run pip install python-dateutil\n\nEnter the alembic migration directory in \"utils/db_migration\" with:\n\ncd utils/db_migration",
  "Enter the alembic migration directory in \"utils/db_migration\" with:\n\ncd utils/db_migration\n\nBefore starting the migration script you must set your database connection in \"cuckoo.conf\" if you are using a custom one. Alembic migration script will use the database connection parameters configured in cuckoo.conf.\n\nAgain, please remember to backup before launching the migration tool! A wrong configuration may corrupt your data, backup should save kittens!\n\nRun the database migrations with:\n\nalembic upgrade head\n\nPython library upgrades:\n\nPIP3:\n\n$ poetry run pip install -U <library>\n\nTroubleshooting:\n\nWhen trying to update your local CAPE installation with poetry with either of the following commands:\n\n$ sudo -u cape poetry install\n$ sudo -u cape poetry update\n\nyou may encounter the following error:",
  "$ sudo -u cape poetry install\n$ sudo -u cape poetry update\n\nyou may encounter the following error:\n\nCalledProcessError\n   Command '['git', '--git-dir', '/tmp/pypoetry-git-web3.pyocemorcf/.git', '--work-tree', '/tmp/pypoetry-git-web3.pyocemorcf', 'checkout', 'master']' returned non-zero exit status 1.\n\nOr maybe when trying to update poetry itself with:\n\n$ sudo -u cape poetry self update\n\nyou may face the following error:\n\nRuntimeError\n   Poetry was not installed with the recommended installer. Cannot update automatically.\n\nThat is because you probably installed poetry with pip.\n\nIn order to solve it you must first upgrade your local poetry installation with:\n\n$ sudo pip3 install poetry --upgrade\n\nand then run the update command again:\n\n$ sudo -u cape poetry update",
  "Preparing the Host\n\nEven though it's reported to run on other operating systems too, CAPE is originally supposed to run on a GNU/Linux native system. For this documentation, we chose the latest Ubuntu LTS as the reference system for the commands examples.\n\ninstallation configuration routing cloud",
  "Configuration\n\nCAPE relies on six main configuration files:\n\ncuckoo_conf: for configuring general behavior and analysis options.\n\nauxiliary_conf: for enabling and configuring auxiliary modules.\n\nmemory_conf: Volatility configuration.\n\nprocessing_conf: for enabling and configuring processing modules.\n\nreporting_conf: for enabling or disabling report formats.\n\nrouting_conf: for defining the routing of internet connection for the VMs.\n\nTo get CAPE working you have to edit auxiliary_conf, cuckoo_conf, and machinery_conf at least. We suggest you check all configs before starting, to be familiar with the possibilities that you have and what you want to be done.\n\nNote\n\nWe recommend to you: create a custom/conf/ directory and put files in there whose names are the same as those in the top-level conf/ directory. These files only need to include settings that will override the defaults. In that way you won't have problems with any upcoming changes to default configs.",
  "To allow for further flexibility, you can also create a custom/conf/<type>.conf.d/ (e.g. custom/conf/reporting.conf.d/) directory and place files in there. Any file in that directory whose name ends in .conf will be read (in lexicographic order). The last value read for a value will be the one that is used.\n\nWarning\n\nAny section inside the configs that is marked #community at the top refers to a plugin that was developed by our community, but that doesn't mean that we maintain it. Those plugins might be outdated or broken due to software/dependency changes. If you find anything like this broken, you are more than welcome to fix it and submit a pull request. The alternative is to switch off the offending plugin. Opening an issue for any of these is pointless as we don't maintain them and cannot support them.\n\ncuckoo.conf\n\nThe first file to edit is conf/cuckoo.conf, it contains the generic configuration options that you might want to verify before launching CAPE.",
  "The file is largely commented and self-explaining, but some of the options you might want to pay more attention to are:\n\nmachinery in [cuckoo]: this defines which Machinery module you want CAPE to use to interact with your analysis machines. The value must be the name of the module without extension.\n\nip and port in [resultserver]: defines the local IP address and port that CAPE is going to use to bind the result server to. Make sure this matches the network configuration of your analysis machines, or they won't be able to return the collected results.\n\nconnection in [database]: defines how to connect to the internal database. You can use any DBMS supported by SQLAlchemy using a valid Database Urls syntax.\n\nWarning",
  "Warning\n\nCheck your interface for resultserver IP! Some virtualization software (for example Virtualbox) doesn't bring up the virtual networking interfaces until a virtual machine is started. CAPE needs to have the interface where you bind the resultserver up before the start, so please check your network setup. If you are not sure about how to get the interface up, a good trick is to manually start and stop an analysis virtual machine, this will bring virtual networking up. If you are using NAT/PAT in your network, you can set up the resultserver IP to 0.0.0.0 to listen on all interfaces, then use the specific options resultserver_ip and resultserver_port in <machinery>.conf to specify the address and port as every machine sees them. Note that if you set resultserver IP to 0.0.0.0 in cuckoo.conf you have to set resultserver_ip for all your virtual machines.\n\nNote",
  "Note\n\nDefault freespace value is 50GB It is worth mentioning that the default freespace value in cuckoo.conf is 50000 MB aka 50 GB.\n\nPlease check the latest version of cuckoo.conf here: cuckoo.conf.\n\nauxiliary.conf\n\nAuxiliary modules are scripts that run concurrently with malware analysis, this file defines their options. Please see the default version here: auxiliary.conf.\n\n<machinery>.conf\n\nMachinery modules are scripts that define how Cuckoo should interact with your virtualization software of choice.\n\nEvery module should have a dedicated configuration file that defines the details of the available machines. For example, if you created a kvm.py machinery module, you should specify kvm in conf/cuckoo.conf and have a conf/kvm.conf file.\n\nCAPE provides some modules by default and for the sake of this guide, we'll assume you're going to use KVM. Please see the latest version here: kvm.conf.",
  "If you are using KVM (kvm.conf), for each VM you want to use for analysis there must be a dedicated section. First you have to create and configure the VM (following the instructions in the dedicated chapter, see preparing_the_guest). The name of the section must be the same as the label of the VM as printed by $ virsh list --all. If no VMs are shown, you can execute the following command sequence: $ virsh, $ connect qemu:///system, $ list --all; or you can check this link to learn how to change the connection in Virtual Manager.\n\nYou can also find examples of other hypervisors like:\n\nVirtualBox: virtualbox.conf.\n\nVMWare: vmware.conf.\n\nThe comments for the options are self-explanatory.\n\nYou can use this same configuration structure for any other machinery module, although existing ones might have some variations or additional configuration options.\n\nmemory.conf",
  "memory.conf\n\nThe Volatility tool offers a large set of plugins for memory dump analysis. Some of them are quite slow. In volatility.conf lets you enable or disable the plugins of your choice. To use Volatility you have to follow two steps:\n\nEnable it in processing.conf\n\nEnable memory_dump in cuckoo.conf\n\nIn the memory.conf's basic section you can configure the Volatility profile and the deletion of memory dumps after processing:\n\n# Basic settings\n[basic]\n# Profile to avoid wasting time identifying it\nguest_profile = WinXPSP2x86\n# Delete memory dump after volatility processing.\ndelete_memdump = no\n\nAfter that every plugin has an own section for configuration:\n\n# Scans for hidden/injected code and dlls\n# http://code.google.com/p/volatility/wiki/CommandReference#malfind\n[malfind]\nenabled = on\nfilter = on",
  "# Lists hooked api in user mode and kernel space\n# Expect it to be very slow when enabled\n# http://code.google.com/p/volatility/wiki/CommandReference#apihooks\n[apihooks]\nenabled = off\nfilter = on\n\nThe filter configuration helps you to remove known clean data from the resulting report. It can be configured separately for every plugin.\n\nThe filter itself is configured in the [mask] section. You can enter a list of pids in pid_generic to filter out processes:\n\n# Masks. Data that should not be logged\n# Just get this information from your plain VM Snapshot (without running malware)\n# This will filter out unwanted information in the logs\n[mask]\n# pid_generic: a list of process ids that already existed on the machine before the malware was started.\npid_generic = 4, 680, 752, 776, 828, 840, 1000, 1052, 1168, 1364, 1428, 1476, 1808, 452, 580, 652, 248, 1992, 1696, 1260, 1656, 1156\n\nPlease see the latest version here: memory.conf.\n\nprocessing.conf",
  "Please see the latest version here: memory.conf.\n\nprocessing.conf\n\nThis file allows you to enable, disable and configure all processing modules. These modules are located under modules/processing/ and define how to digest the raw data collected during the analysis.\n\nYou will find a section for each processing module here: processing.conf.\n\nYou might want to configure the VirusTotal key if you have an account of your own.\n\nreporting.conf\n\nThe conf/reporting.conf file contains information on the automated reports generation. Please see the latest version here: reporting.conf.\n\nBy setting these options to on or off you enable or disable the generation of such reports.\n\nrouting.conf\n\nThe conf/routing.conf file contains information about how the guest VM is connected (or not) to the Internet via the Host, or whether it is isolated. This file is used in conjunction with the rooter.py utility.\n\nPlease see the latest version of routing.conf here: routing.conf.",
  "Please see the latest version of routing.conf here: routing.conf.\n\nYou can read more about the routing.conf file and its options in the routing chapter and more about the rooter.py utility in the rooter chapter.\n\nUsing environment variables in config files\n\nAny of the above config files may reference environment variables in their values by using %(ENV:VARIABLE_NAME)s. For example, instead of putting a VirusTotal Intelligence API key in auxiliary_conf, you could use the following:\n\n[virustotaldl]\nenabled = yes\ndlintelkey = %(ENV:DLINTELKEY)s\n\nassuming the DLINTELKEY environment variable contains the API key.",
  "Deploying CAPE in the Cloud\n\nThe following documentation will detail how to install CAPE using cloud resources.\n\nAzure\n\nTo use Azure as a machinery for CAPE, significant work must be done to deploy and secure the resource groups, network architecture, credential management, etc required.\n\nResource groups\n\nThe description below details how to create the resource groups that are required for isolating resources that should be controlled by the Azure machinery, which is running on a virtual machine and will have raw malware on it.\n\nNetworking\n\nThe description below details how a REST client could send files to CAPE, which would then detonate the submitted files in an isolated network.\n\nA route table resource has to be created in RG2 and applied to direct all traffic from guests through the host (VNET2_RT1). Apply this route table to VNET2_SUB2, and create a new rule that directs all traffic (0.0.0.0/0) to a virtual appliance, aka the IP of VNET2_SUB2_NIC.",
  "These are the main networking resources required to deploy CAPE in Azure.\n\nCredential Management\n\nIn the az.conf, there are several crucial details that we will need for accessing/manipulating Azure resources. These details are client_id, secret, and tenant. To get these details, perform the following:\n\nSee ../guest/saving for instructions on how to create a shared gallery image definition version, the equivalent of a snapshot for virtual machine scale sets.",
  "Per-Analysis Network Routing\n\nWith the more advanced per-analysis routing, it is naturally also possible to have one default route - a setup that used to be popular before, when the more luxurious routing was not yet available.\n\nIn our examples, we'll be focusing on KVM as it is our default machinery choice.\n\nWarning\n\nIn case if you see proxy IP:PORT in networking for example as tor 9040 port. It happens due that you have installed docker on your host and it breaks some networking filters.\n\nTo fix proxy IP:PORT problem, you need to run following script. Save it to file, give execution permission with sudo a+x iptables_fix.sh and run it with proper arguments:\n\n!/bin/bash\n# Fix when docker breaks your iptables\nif [ $# -eq 0 ] || [ $# -lt 2 ]; then\n    echo \"$0 <network range> <vir_iface> <real_iface>\"\n    echo \"    example: $0 192.168.1.0 virbr0 eno0\"\n    exit 1\nfi",
  "echo \"[+] Setting iptables\"\niptables -t nat -A POSTROUTING -o \"$2\" -j MASQUERADE\niptables -A FORWARD -i \"$2\" -o \"$2\" -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -A FORWARD -i \"$2\" -o \"$2\" -j ACCEPT\niptables -I FORWARD -m physdev --physdev-is-bridged -j ACCEPT\niptables -I FORWARD -o \"$2\" -d  \"$1\"/24 -j ACCEPT\niptables -t nat -A POSTROUTING -s \"$1\"/24 -j MASQUERADE\niptables -A FORWARD -o \"$2\" -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -A FORWARD -i \"$2\" -o \"$3\" -j ACCEPT\niptables -A FORWARD -i \"$2\" -o lo -j ACCEPT",
  "echo \"[+] Setting network options\"\n# https://forums.fedoraforum.org/showthread.php?312824-Bridge-broken-after-docker-install&s=ffc1c60cccc19e46c01b9a8e0fcd0c35&p=1804899#post1804899\n{\n    echo \"net.bridge.bridge-nf-call-ip6tables=0\";\n    echo \"net.bridge.bridge-nf-call-iptables=0\";\n    echo \"net.bridge.bridge-nf-call-arptables=0\";\n    echo \"net.ipv4.conf.all.forwarding=1\";\n    echo \"net.ipv4.ip_forward=1\";\n} >> /etc/sysctl.conf\nsysctl -p\necho \"iptables -A FORWARD -i $2 -o $2 -j ACCEPT\" >> /etc/network/if-pre-up.d/kvm_bridge_iptables\n\nvirsh nwfilter-list\n\nTo make it permanent you can use iptables-save.\n\nPer-Analysis Network Routing Options\n\nFollowing is the list of available routing options.",
  "Per-Analysis Network Routing Options\n\nFollowing is the list of available routing options.\n\nRouting Option Description routing_none No routing whatsoever, the only option that does not require the Rooter to be run (and therefore also the default routing option). routing_drop Completely drops all non-CAPE traffic, including traffic within the\nVMs' subnet. routing_internet Full internet access as provided by the given network interface routing_inetsim Routes all traffic to an InetSim instance -which provides fake\nservices - running on the host machine. routing_tor Routes all traffic through Tor. routing_tun Route traffic though any \"tun\" interface routing_vpn Routes all traffic through one of perhaps multiple pre-defined VPN\nendpoints. routing_socks Routes all traffic through one of perhaps multiple pre-defined VPN\nendpoints.\n\nUsing Per-Analysis Network Routing",
  "Using Per-Analysis Network Routing\n\nNow that you know the available network routing options, it is time to use them in practice. Assuming CAPE has been configured properly taking advantage of its features is as simple as starting the CAPE Rooter and choosing a network routing option for your analysis.\n\nDocumentation on starting the Rooter may be found in the cape_rooter_usage document.\n\nBoth global routing and per-analysis routing require ip forwarding to be enabled:\n\n$ echo 1 | sudo tee -a /proc/sys/net/ipv4/ip_forward\n$ sudo sysctl -w net.ipv4.ip_forward=1\n\nWarning\n\nPlease be aware by default these changes do not persist and will be reset after a system restart.\n\nConfiguring netplan\n\nIn modern releases of Ubuntu, all network configuration is handled by netplan, including routing tables.\n\nIf you are using Ubuntu Server, disable cloud-init, which is used by default.",
  "If you are using Ubuntu Server, disable cloud-init, which is used by default.\n\nDo this by writing a file at /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg, with the content network: {config: disabled}, then delete /etc/netplan/50-cloud-init.yaml.\n\nIf you are using a desktop version of Ubuntu instead, you will need to disable NetworkManager and enable networkd.\n\nsudo systemctl stop NetworkManager\nsudo systemctl disable NetworkManager\nsudo systemctl mask NetworkManager\n\nsudo systemctl unmask systemd-networkd\nsudo systemctl enable systemd-networkd\nsudo systemctl start systemd-networkd\n\nNext, create your own netplan configuration file manually at /etc/netplan/99-manual.yaml",
  "Next, create your own netplan configuration file manually at /etc/netplan/99-manual.yaml\n\nThe example netplan configuration below has a 5G hotspot interface named enx00a0c6000000 for routing_internet (aka the dirty line) and a management interface named enp8s0 for hosting the CAPE web UI, SSH and other administrative services. In this configuration the dirty line is used as the default gateway for all internet traffic on the host. This helps prevent network leaks, firewall IDS/IPS issues, and keeps administrative traffic separate, where it could be placed in its own subnet for additional security.\n\nYou will need to replace the interface names and IP addresses to reflect your own system.\n\nEach interface configuration needs a routes section that describes the routes that can be accessed via that interface. In order for the configuration to work with CAPE's per-analysis routing, each routes section must have an arbitrary but unique table integer value.",
  "network:\n    version: 2\n    renderer: networkd\n    ethernets:\n        lo:\n            addresses: [ \"127.0.0.1/8\", \"::1/128\", \"7.7.7.7/32\" ]\n        enx00a0c6000000:\n            dhcp4: no\n            addresses: [ \"192.168.1.2/24\" ]\n            nameservers:\n                addresses: [ \"192.168.1.1\" ]\n            routes:\n                - to: default\n                  via: 192.168.1.1\n                - to: 192.168.1.0/24\n                  via: 192.168.1.1\n                  table: 101\n            routing-policy:\n             - from: 192.168.1.0/24\n               table: 101\n        enp8s0:\n            dhcp4: no\n            addresses: [ \"10.23.6.66/24\" ]\n            routes:\n                - to: 10.23.6.0/24\n                  via: 10.23.6.1\n                  table: 102\n            routing-policy:\n                - from: 10.23.6.0/24\n                  table: 102",
  "Run sudo netplan apply to apply the new netplan configuration. You can verify the new routing rules and tables have been created with:\n\nip r. To show 'main' table.\n\nip r show table X. To show 'X' table, where X is either the number or the name you specified in the netplan file.\n\nip r show table all. To show all routing rules form all tables.\n\nNote\n\nThere are some considerations you should take into account when configuring and setting netplan and others components necessary so as to provide the Hosts with Internet connection:\n\nIP forwarding MUST be enabled.\n\nThe routing table NUMBER specified in the netplan config file should be the SAME as the one specified in /etc/iproute2/rt_tables.\n\nThe routing table NAME specified in /etc/iproute2/rt_tables (next to its number) should be the SAME as the one specified specified in routing.conf (with the rt_table field).\n\nProtecting host ports",
  "Protecting host ports\n\nBy default, most Linux network services listen on all network interface interfaces/addresses, leaving the services running on the host machine exposed to potential attacks from the analysis VMs.\n\nTo mitigate this issue, use the ufw firewall included with Ubuntu. It will not break CAPE\u2019s per-analysis network routing.\n\nAllow access to administrative services using the interface that is being used for management of the sandbox. Network interface details can be found by using the ip addr command.\n\nIn this example the management interface name is enp8s0, with an IP address of 10.23.6.66. Replace these values with the proper values for your server.\n\n# HTTP\nsudo ufw allow in on enp8s0 to 10.23.6.66 port 80 proto tcp\n\n# HTTPS\nsudo ufw allow in on enp8s0 to 10.23.6.66 port 443 proto tcp\n\n# SSH\nsudo ufw allow in on enp8s0 to 10.23.6.66 port 22 proto tcp",
  "# SSH\nsudo ufw allow in on enp8s0 to 10.23.6.66 port 22 proto tcp\n\n# SMB (smbd is enabled by default on desktop versions of Ubuntu)\nsudo ufw allow in on enp8s0 to 10.23.6.66 port 22 proto tcp\n\n# RDP (if xrdp is used on the server)\nsudo ufw allow in on enp8s0 to 10.23.6.66 port 445 proto tcp\n\nAllow analysis VMs to access the CAPE result server, which used TCP port 2042 by default.\n\nIn this example the host interface name is virbr1 with an IP address of 192.168.42.1. Replace these values with the proper values for your server.\n\nsudo ufw allow in on virbr1 to 192.168.42.1 port 2042 proto tcp\n\nEnable the firewall after all of the rules have ben configured.\n\nsudo ufw enable\n\nNone Routing\n\nThe default routing mechanism in the sense that CAPE allows the analysis to route as defined by a third party. As in, it doesn't do anything. One may use the none routing\n\nDrop Routing",
  "Drop Routing\n\nThe drop routing option is somewhat like a default routing_none setup (as in, in a machine where no global iptables rules have been created providing full internet access to VMs or so), except that it is much more aggressive in actively locking down the internet access provided to the VM.\n\nWith drop routing the only traffic possible is internal CAPE traffic and hence any DNS requests or outgoing TCP/IP connections are blocked.\n\nInternet Routing\n\nBy using the internet routing one may provide full internet access to VMs through one of the connected network interfaces. We also refer to this option as the dirty line due to its nature of allowing all potentially malicious samples to connect to the internet through the same uplink.\n\nNote\n\nIt is required to register the dirty line network interface with iproute2 as described in the routing_netplan section.\n\nInetSim Routing",
  "InetSim Routing\n\nFor those that have not heard of InetSim, it's a project that provides fake services for malware to talk to. To use InetSim routing one will have to set up InetSim on the host machine (or in a separate VM) and configure CAPE so that it knows where to find the InetSim server.\n\nThe configuration for InetSim is self-explanatory and can be found as part of the $CWD/conf/routing.conf configuration file:\n\n[inetsim]\nenabled = yes\nserver = 192.168.122.1\n\nTo quickly get started with InetSim it is possible to download the latest version of the REMnux distribution which features - among many other tools - the latest version of InetSim. Naturally, this VM will require a static IP address which should then be configured in the routing.conf configuration file.\n\nWe suggest running it on a virtual machine to avoid any possible leaks\n\nTor Routing\n\nNote",
  "We suggest running it on a virtual machine to avoid any possible leaks\n\nTor Routing\n\nNote\n\nAlthough we highly discourage the use of Tor for malware analysis - the maintainers of Tor exit nodes already have a hard enough time keeping up their servers - it is a well-supported feature.\n\nFirst of all, Tor will have to be installed. Please find instructions on installing the latest stable version of Tor here.\n\nWe'll then have to modify the Tor configuration file (not talking about CAPE's configuration for Tor yet!) To do so, we will have to provide Tor with the listening address and port for TCP/IP connections and UDP requests. For a default KVM setup, where the host machine has IP address 192.168.122.1, the following lines will have to be configured in the /etc/tor/torrc file:\n\nTransPort 192.168.122.1:9040\nDNSPort 192.168.122.1:5353",
  "TransPort 192.168.122.1:9040\nDNSPort 192.168.122.1:5353\n\nDon't forget to restart Tor (/etc/init.d/tor restart). That leaves us with the Tor configuration for Cuckoo, which may be found in the $CWD/conf/routing.conf file. The configuration is pretty self-explanatory so we'll leave filling it out as an exercise to the reader (in fact, toggling the enabled field goes a long way):\n\n[tor]\nenabled = yes\ndnsport = 5353\nproxyport = 9040\n\nNote that the port numbers in the /etc/tor/torrc and $CWD/conf/routing.conf files must match for the two to interact correctly.\n\nTun Routing\n\nThis allows you to route via any tun interface. You can pass the tun interface name on demand per analysis. The interface name can be tunX or tun_foo. This assumes you create the tunnel inferface outside of CAPE.\n\nThen you set the route=tun_foo on the /apiv2/tasks/create/file/ API call.\n\nVPN Routing",
  "Then you set the route=tun_foo on the /apiv2/tasks/create/file/ API call.\n\nVPN Routing\n\nIt is possible to route analyses through multiple VPNs. By defining a couple of VPNs, perhaps ending up in different countries, it may be possible to see if potentially malicious samples behave differently depending on the country of origin of their IP address.\n\nThe configuration for a VPN is much like the configuration of a VM. For each VPN you will need one section in the $CWD/conf/routing.conf configuration file detailing the relevant information for the VPN. In the configuration, the VPN will also have to be registered in the list of available VPNs (the same as you'd do for registering more VMs).\n\nConfiguration for a single VPN looks roughly as follows:\n\n[vpn]\n# Are VPNs enabled?\nenabled = yes\n\n# Comma-separated list of the available VPNs.\nvpns = vpn0",
  "[vpn]\n# Are VPNs enabled?\nenabled = yes\n\n# Comma-separated list of the available VPNs.\nvpns = vpn0\n\n[vpn0]\n# Name of this VPN. The name is represented by the filepath to the\n# configuration file, e.g., CAPE would represent /etc/openvpn/cuckoo.conf\n# Note that you can't assign the names \"none\" and \"internet\" as those would\n# conflict with the routing section in cuckoo.conf.\nname = vpn0\n\n# The description of this VPN which will be displayed in the web interface.\n# Can be used to for example describe the country where this VPN ends up.\ndescription = Spain, Europe\n\n# The tun device hardcoded for this VPN. Each VPN *must* be configured to use\n# a hardcoded/persistent tun device by explicitly adding the line \"dev tunX\"\n# to its configuration (e.g., /etc/openvpn/vpn1.conf) where X in tunX is a\n# unique number between 0 and your lucky number of choice.\ninterface = tun0",
  "# Routing table name/id for this VPN. If table name is used it *must* be\n# added to /etc/iproute2/rt_tables as \"<id> <name>\" line (e.g., \"201 tun0\").\n# ID and name must be unique across the system (refer /etc/iproute2/rt_tables\n# for existing names and IDs).\nrt_table = tun0\n\nNote\n\nIt is required to register each VPN network interface with netplan as described in the routing_netplan section.\n\nQuick and dirty example of iproute2 configuration for VPN:\n\nExample:\n    /etc/iproute2/rt_tables\n        5 host1\n        6 host2\n        7 host3\n\n    conf/routing.conf\n        [vpn5]\n        name = X.ovpn\n        description = X\n        interface = tunX\n        rt_table = host1\n\nBear in mind that you will need to adjust some values inside of VPN route script. Read it!\n\nHelper script vpt2cape.py, read code to understand it\n\nVPN persistence & auto-restart source:",
  "Helper script vpt2cape.py, read code to understand it\n\nVPN persistence & auto-restart source:\n\n1. Run the command:\n    # sudo nano /etc/default/openvpn`\n    and uncomment, or remove, the \u201c#\u201d in front of AUTOSTART=\"all\"\n    then press \u2018Ctrl X\u2019 to save the changes and exit the text editor.\n\n2. Move the .ovpn file with the desired server location to the \u2018/etc/openvpn\u2019 folder:\n    # sudo cp /location/whereYouDownloadedConfigFilesTo/Germany.ovpn /etc/openvpn/\n\n3. In the \u2018/etc/openvpn\u2019 folder, create a text file called login.creds:\n    # sudo nano /etc/openvpn/login.creds\n    and enter your IVPN Account ID (starts with \u2018ivpn\u2019) on the first line and any non-blank text on the 2nd line, then press \u2018Ctrl X\u2019 to save the changes and exit the text editor.\n\n4. Change the permissions on the pass file to protect the credentials:\n    # sudo chmod 400 /etc/openvpn/login.creds\n\n5. Rename the .ovpn file to \u2018client.conf\u2019:\n    # sudo cp /etc/openvpn/Germany.ovpn /etc/openvpn/client.conf",
  "6. Reload the daemons:\n# sudo systemctl daemon-reload\n\n7. Start the OpenVPN service:\n    # sudo systemctl start openvpn\n\n8. Test if it is working by checking the external IP:\n    # curl ifconfig.co\n\n9. If curl is not installed:\n    # sudo apt install curl\n\nWireguard VPN\n\nSetup Wireguard\n\nOriginal blog post on how to setup WireGuard with CAPE\n\nInstall wireguard:\n\nsudo apt install wireguard\n\nDownload Wireguard configurations from your VPN provider and copy them into /etc/wireguard/wgX.conf. E.g.:\n\n/etc/wireguard/wg1.conf\n/etc/wireguard/wg2.conf\n/etc/wireguard/wg3.conf\n\nEach configuration is for a different exit destination.\n\nAn example config for wg1.conf:\n\n# VPN-exit-CC\n[Interface]\nPrivateKey = <REMOVED>\nAddress = xxx.xxx.xxx.xxx/32\nTable = 420",
  "# VPN-exit-CC\n[Interface]\nPrivateKey = <REMOVED>\nAddress = xxx.xxx.xxx.xxx/32\nTable = 420\n\n# Following 2 lines added in attempt to allow local traffic\nPreUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o %i -j MASQUERADE\nPreDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o %i -j MASQUERADE\n\n[Peer]\nPublicKey = <REMOVED>\nAllowedIPs = 0.0.0.0/0\nEndpoint = xxx.xxx.xxx.xxx:51820\n\nThe only changes I made to the original file from my VPN provider was adding Table = 420 and the PreUp and PreDown lines to configure iptables.\n\nThen start the VPN: wg-quick up wg1. If all goes well you can run wg and see that the tunnel is active. If you want to test it\u2019s working I suggest:\n\ncurl https://ifconfig.me/\ncurl --interface wg1 https://ifconfig.me/\n\nExample snippet from /opt/CAPEv2/conf/routing.conf configuration:",
  "Example snippet from /opt/CAPEv2/conf/routing.conf configuration:\n\n[vpn0]\nname = vpn0\ndescription = vpn_CC_wg1\ninterface = wg1\nrt_table = wg1\n\nNote\n\nIt is required to register each VPN network interface with netplan as described in the routing_netplan section. Check quick and dirty note in original VPN section.\n\nSOCKS Routing\n\nYou also can use socks proxy servers to route your traffic. To manage your socks server you can use Socks5man software. Building them by yourself, using your favorite software, buying, etc The configuration is pretty simple and looks like VPN, but you don't need to configure anything else\n\nRequires to install dependency: poetry run pip install git+https://github.com/CAPESandbox/socks5man\n\nExample:\n\n[socks5]\n# By default we disable socks5 support as it requires running utils/rooter.py as\n# root next to cuckoo.py (which should run as regular user).\nenabled = no\n\n# Comma-separated list of the available proxies.\nproxies = socks_CC",
  "# Comma-separated list of the available proxies.\nproxies = socks_CC\n\n[socks_CC]\nname = CC_socks\ndescription = CC_socks\nproxyport = 5000\ndnsport = 10000\n\nTroubleshooting\n\nConfiguring the Internet connection in the Hosts (VMs) can become a tedious task given the elements involved in the correct functioning. Here you can find several ways of debugging the connections from and to the Hosts besides cuckoo.py -d.\n\nManually testing Internet connection\n\nYou can manually test the Internet connection from inside the VMs without the need of performing any analysis. To do so, you have to use the . This utility allows you to enable or disable specific routes and debug them. It is a \"Standalone script to debug VM problems that allows to enable routing on VM\".\n\nFirst, stop the cape-rooter service with:\n\n$ sudo systemctl stop cape-rooter.service\n\nAssuming you already have any VM running, to test the internet connection using router_manager.py you have to execute the following commands:",
  "$ sudo python3 router_manager.py -r internet -e --vm-name win1 --verbose\n$ sudo python3 router_manager.py -r internet -d --vm-name win1 --verbose\n\nThe -e flag is used to enable a route and -d is used to disable it. You can read more about all the options the utility has by running:\n\n$ sudo python3 router_manager.py -h\n\nNote\n\nThe --vm-name parameters expects any ID from the ones in <machinery>.conf, not the label you named each VM with. To see the available options you can execute $ sudo python3 router_manager.py --show-vm-names.\n\nWhenever you use the router_manager.py utility to either enable or disable any given route, there are changes made to iptables are you should be able to see them take place.\n\nFor instance, this is how it looks BEFORE enabling any route:\n\n$ ip rule\n0:  from all lookup local\n32766:  from all lookup main\n32767:  from all lookup default\n\nAnd this is how it looks AFTER executing the following commands:",
  "And this is how it looks AFTER executing the following commands:\n\n$ sudo python3 router_manager.py -r internet -e --vm-name win1 --verbose\ninternet eno1 eno1 {'label': 'win10', 'platform': 'windows', 'ip': 'X.X.X.133', 'arch': 'x64'} None None\n$ sudo python3 router_manager.py -r internet -e --vm-name win2 --verbose\ninternet eno1 eno1 {'label': 'win10-clone', 'platform': 'windows', 'ip': 'X.X.X.134', 'arch': 'x64'} None None\n\n$ ip rule\n0:  from all lookup local\n32764:  from X.X.X.134 lookup eno1\n32765:  from X.X.X.133 lookup eno1\n32766:  from all lookup main\n32767:  from all lookup default\n\nThen again, if everything is configured as expected, when executing the utility with the -d option the IP rules should disappear, reverting them to their original state.\n\nIf your routing configuration is correct, you should now be able to successfully ping 8.8.8.8. If you disable the route you shouldn't be able to ping anything on the Internet.\n\nNote",
  "Note\n\nSometimes ip rules may remain undeleted for several reasons. You can manually delete them with $ sudo ip rule delete from $IP, where $IP is the IP the rule refers to.\n\nDebugging iptables rules\n\nEvery single time the rooter brings up or down any route (assuming it works as expected) or you do so by using the router_manager.py utility, your iptables set of rules is modified in one way or another.\n\nTo inspect the changes being made and verify them, you can use the watch utility preinstalled in the vast majority of *nix systems. For example, to view rules created by CAPE-rooter or the utility you can run the following command:\n\n$ sudo watch -n 1 iptables -L -n -v\n\nYou can also leverage watch to inspect the connections being made from the Guest to the Host or viceversa:\n\n$ sudo watch -n 1 'netstat -peanut | grep $IP'\n\nwhere $IP is the IP of your Guest.",
  "Installing CAPE\n\nProceed with download and installation. Read ../../introduction/what to learn where you can obtain a copy of the sandbox.\n\nAutomated installation, read the full page before you start\n\nWe have automated all work for you but bear in mind that 3rd party dependencies change frequently and can break the installation, so please check the installation log and try to provide the fix / correct issue to the developers.\n\nWarning\n\nWe advise against modifying or updating any package installed by the script explained below. By using package managers like apt there are high chances your KVM/libvirt/CAPE installation will break and you will most likely end up riding the lanes of dependency hell.\n\nTo install KVM\n\nWhile you can install and use any hypervisor you like, we recommend using KVM. The script to install everything related to KVM (including KVM itself) can be found here: kvm-qemu.sh.\n\nNote",
  "Note\n\nWe recommend using the script to install everything related with KVM-Qemu since the script performs a stealthier configuration and achieves better performance than the installation from APT.\n\nBEFORE executing the script, you should replace the <WOOT> occurrences withing the script itself with real hardware patterns. You can use acpidump in Linux and acpiextract in Windows to obtain such patterns, as stated in the script itself.\n\nWarning\n\nIf you are installing or using CAPE in a laboratory environment you can replace <WOOT> with any random 4 chars you like. However, if you are planning to use CAPE in real production environments and you want to hinder the sandbox/VM detection, you should use REAL hardware 4 chars. To find out which chars correspond to each piece of HW, you should use ACPIDUMP/ACPIEXTRACT and Google.\n\nIn order to install KVM itself, execute the following command:\n\n$ sudo chmod a+x kvm-qemu.sh\n$ sudo ./kvm-qemu.sh all <username> | tee kvm-qemu.log",
  "$ sudo chmod a+x kvm-qemu.sh\n$ sudo ./kvm-qemu.sh all <username> | tee kvm-qemu.log\n\nreplacing <username> with your actual username.\n\nRemember to reboot after the installation.\n\nIf you want to install Virtual Machine Manager (virt-manager), execute the following command:\n\n$ sudo ./kvm-qemu.sh virtmanager <username> | tee kvm-qemu-virt-manager.log\n\nreplacing <username> with your actual username.\n\nRemember to reboot after the installation.\n\nImportant\n\nIt is important to assert everything works as expected before moving forward. The vast majority of errors at this point can be solved by reinstalling the specific component with kvm-qemu.sh. For example, the error below was raised when trying to open virt-manager but libvirt installation was corrupted for some reason. Reinstalling libvirt with the script solved the issue.\n\nError\n\n.. image:: ../../_images/screenshots/libvirt_error_virtmanager.png\n\nTo install CAPE\n\nThe script to install CAPE can be found here: cape2.sh.\n\nNote",
  "To install CAPE\n\nThe script to install CAPE can be found here: cape2.sh.\n\nNote\n\nCAPE is being maintained and updated in a rolling fashion. That is, there are no versions or releases. It is your responsibility to regularly pull the repo and stay up to date.\n\nPlease keep in mind that all our scripts use the -h flag to print the help and usage message. However, it is recommended to read the scripts themselves to understand what they do.\n\nPlease become familiar with available options using:\n\n$ sudo chmod a+x cape2.sh\n$ ./cape2.sh -h\n\nTo install CAPE with all the optimizations, use one of the following commands:\n\n$ sudo ./cape2.sh base cape | tee cape.log\n$ sudo ./cape2.sh all cape | tee cape.log\n\nRemember to reboot after the installation.\n\nThis should install all libraries and services for you, read the code if you need more details. Specifically, the installed services are:\n\ncape.service\n\ncape-processor.service\n\ncape-web.service\n\ncape-rooter.service\n\nTo restart any service use:",
  "cape-processor.service\n\ncape-web.service\n\ncape-rooter.service\n\nTo restart any service use:\n\n$ systemctl restart <service_name>\n\nTo see service log use:\n\n$ journalctl -u <service_name>\n\nTo install dependencies\n\nTo install dependencies with poetry, execute the following command (from the main working directory of CAPE, usually /opt/CAPEv2/):\n\n$ poetry install\n\nOnce the installation is done, you can confirm a virtual environment has been created with:\n\n$ poetry env list\n\nThe output should be similar to:\n\n$ poetry env list\ncapev2-t2x27zRb-py3.10 (Activated)\n\nFrom now on, you will have to execute CAPE within the virtual env of Poetry. To do so you need just poetry run <command>. For example:\n\n$ sudo -u cape poetry run python3 cuckoo.py\n\nIf you need further assistance with Poetry, there are hundreds of cheat sheets on the Internet\n\nOptional dependencies\n\nsudo -u cape poetry run pip install -r extra/optional_dependencies.txt\n\nATTENTION! cape user",
  "sudo -u cape poetry run pip install -r extra/optional_dependencies.txt\n\nATTENTION! cape user\n\nOnly the installation scripts and some utilities like rooter.py must be executed with sudo, the rest of configuration scripts and programs MUST be executed under the cape user, which is created in the system after executing cape2.sh.\n\nBy default, the cape user has no login. In order to substitute it and use the cmd on its behalf, you can execute the following command:\n\n$ sudo su - cape -c /bin/bash",
  "Preparing the Guest (Physical Machine)\n\nAt this point, you should have configured the CAPE host component and you should have designed and defined the number and the names of the physical machines you are going to use for malware execution.\n\nYou don't need KVM or any other hypervisor to run physical machinery. You only need FOG.\n\nPlease see this writeup for more updated details 15.10.2020\n\nhttps://mariohenkel.medium.com/using-cape-sandbox-and-fog-to-analyze-malware-on-physical-machines-4dda328d4e2c\n\nNow it's time to create such machines and configure them properly.\n\ncreation requirements network ../guest/agent saving",
  "Creation of the Physical Machine\n\nOnce you have properly installed <../host/installation> your imaging software, you can proceed with creating all the physical machines you need.\n\nUsing and configuring your imaging software is out of the scope of this guide, so please refer to the official documentation.\n\nNote\n\nYou can find some hints and considerations on how to design and create your virtualized environment in the ../../introduction/sandboxing chapter.\n\nNote\n\nFor analysis purposes, you are recommended to use Windows 10 21H2 with User Access Control disabled.\n\nWhen creating the physical machine, CAPE doesn't require any specific configuration. You can choose the options that best fit your needs.",
  "Requirements\n\nTo make CAPE run properly in your physical Windows system, you will have to install some required software and libraries.\n\nInstall Python\n\nPython is a strict requirement for the CAPE guest component (analyzer) to run properly.\n\nYou can download the proper Windows installer from the official website. Also in this case Python > 3.6 is preferred.\n\nSome Python libraries are optional and provide some additional features to the CAPE guest component. They include:\n\nPython Image Library: it's used for taking screenshots of the Windows desktop during the analysis.\n\nThey are not strictly required by CAPE to work properly, but you are encouraged to install them if you want to have access to all available features. Make sure to download and install the proper packages according to your Python version.\n\nAdditional Software\n\nAt this point, you should have installed everything needed by CAPE to run properly.",
  "At this point, you should have installed everything needed by CAPE to run properly.\n\nDepending on what kind of files you want to analyze and what kind of sandboxed Windows environment you want to run the malware samples in, you might want to install additional software such as browsers, PDF readers, office suites, etc. Remember to disable the \"auto update\" or \"check for updates\" feature of any additional software.\n\nThis is completely up to you and what your needs are. You can get some hints by reading the ../../introduction/sandboxing chapter.\n\nAdditional Host Requirements\n\nOn Debian/Ubuntu:\n\n$ sudo apt-get install samba-common-bin\n\nFor the physical machine manager to work, you must have a way for physical machines to be returned to a clean state. In development/testing Fog (http://www.fogproject.org/) was used as a platform to handle re-imaging the physical machines. However, any re-imaging platform can be used (Clonezilla, Deepfreeze, etc) to accomplish this.",
  "Some extras by doomedraven: .. choco.bat: https://github.com/kevoreilly/CAPEv2/raw/master/installer/choco.bat .. disablewin7noise.bat: https://github.com/kevoreilly/CAPEv2/blob/master/installer/disable_win7noise.bat",
  "Network Configuration\n\nNow it's time to set up the network for your physical machine.\n\nWindows Settings\n\nBefore configuring the underlying networking of the sandbox, you might want to tweak some settings inside Windows itself.\n\nOne of the most important things to do is disable Windows Firewall and the Automatic Updates. The reason behind this is that they can affect the behavior of the malware under normal circumstances and that they can pollute the network analysis performed by CAPE, by dropping connections or including irrelevant requests.\n\nYou can do so from Windows' Control Panel as shown in the picture:\n\nimage\n\nUsing a physical machine manager requires a few more configuration options than the virtual machine managers to run properly. In addition to the steps laid out in the regular Preparing the Guest section, some settings need to be changed for physical machines to work properly.\n\nEnable auto-login (Allows for the agent to start upon reboot)",
  "Enable auto-login (Allows for the agent to start upon reboot)\n\nEnable Remote RPC (Allows for CAPE to reboot the sandbox using RPC)\n\nTurn off paging (Optional)\n\nDisable Screen Saver (Optional)\n\nIn Windows 7 the following commands can be entered into an Administrative command prompt to enable auto-logon and Remote RPC. :\n\nreg add \"hklm\\software\\Microsoft\\Windows NT\\CurrentVersion\\WinLogon\" /v DefaultUserName /d <USERNAME> /t REG_SZ /f\nreg add \"hklm\\software\\Microsoft\\Windows NT\\CurrentVersion\\WinLogon\" /v DefaultPassword /d <PASSWORD> /t REG_SZ /f\nreg add \"hklm\\software\\Microsoft\\Windows NT\\CurrentVersion\\WinLogon\" /v AutoAdminLogon /d 1 /t REG_SZ /f\nreg add \"hklm\\system\\CurrentControlSet\\Control\\TerminalServer\" /v AllowRemoteRPC /d 0x01 /t REG_DWORD /f\nreg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System\" /v LocalAccountTokenFilterPolicy /d 0x01 /t REG_DWORD /f\n\nNetworking",
  "Networking\n\nNow you need to decide how to make your physical machine able to access the Internet or your local network.\n\nTo make it work properly you'll have to configure your machine's network so that the Host and the Guest can communicate. Testing the network access by pinging a guest is a good practice, to make sure the virtual network was set up correctly. Use only static IP addresses for your guest, as today CAPE doesn't support DHCP, and using it will break your setup.\n\nThis stage is very much up to your requirements and the characteristics of your virtualization software.\n\nFor physical machines, make sure when setting the IP address of the guest to also set the Gateway and DNS server to be the IP address of the CAPE server on the physical network. For example, if your CAPE server has the IP address of 192.168.1.1, then you would set the Gateway and DNS server in Windows Settings to be 192.168.1.1 as well.\n\nimage",
  "Saving the Guest\n\nNow you should be ready to save the physical machine to a clean state. For the physical machine manager to work, you must have a way for physical machines to be returned to a clean state.\n\nBefore doing this make sure you rebooted it softly and that it's currently running, with CAPE's agent running and with Windows fully booted.\n\nNow you can proceed with saving the machine. The way to do it depends on the imaging software you decided to use.\n\nIn development/testing Fog (http://www.fogproject.org/) was used as a platform to handle re-imaging the physical machines. However, any re-imaging platform can be used (Clonezilla, Deepfreeze, etc.) to accomplish this.\n\nIf you follow all the below steps properly, your virtual machine should be ready to be used by CAPE.\n\nFog\n\nAfter installing Fog, you will need to create an image and add an image and a host to the Fog server.",
  "To add an image to the fog server, open the Image Management window (http://<your_fog_server>/fog/management/index.php?node=images) and click \"Create New Image.\" Provide the proper inputs for your OS configuration and click \"Add\"\n\nimage\n\nNext, you will need to add the host you plan to re-image to Fog. To add a host, open a web browser and navigate to the Host Management page of Fog (http://<your_fog_server>/fog/management/index.php?node=host). Click \"Create New Host.\" Provide the proper inputs for your host configuration. Be sure to select the image you created above from the \"Host Image\" option when finished click the \"Add\" button.\n\nimage",
  "image\n\nAt this point, you should be ready to take an image from the guest machine. To take an image you will need to navigate to the Task Management page and list all hosts (http://<your_fog_server>/fog/management/index.php?node=tasks&sub=listhosts). From here you should be able to click the Upload icon (Green up arrow), which should instantly add a task to the queue to take an image. Now you should reboot your CAPE guest image and it should PXE boot into Fog and capture the base image from the CAPE guest.",
  "After you have successfully taken an image of the guest machine, you can use that image as one to deploy to the CAPE physical sandbox as needed. It is recommended to use a scheduled task to accomplish this. In order to create a scheduled task to re-image sandboxes, navigate to the Host Management page on Fog (http://<your_fog_server>/fog/management/index.php?node=host&sub=list). Then click \"Download\" the machine you wish to schedule the re-image task for. From this menu, select \"Schedule Cron-style Deployment\" and put in the values you wish for the schedule to apply to (*/5 * * * *) in the case shown in the screenshot below, but you may need to tweak these times for your environment.\n\nimage",
  "Installing the Agent\n\nThe CAPE agent is designed to be cross-platform, therefore you should be able to use it on Windows as well as on Linux and OS X. To make CAPE work properly, you'll have to install and start this agent on every guest.\n\nIn the agent/ directory you will find an agent.py file, just copy it to the Guest operating system (in whatever way you want, perhaps in a temporary shared folder, downloading it from a Host webserver, or mounting a CDROM containing the agent.py file) and run it. This will launch the HTTP server which will listen for connections.\n\nImportant\n\nIt is a MUST to launch agent.py/w with elevated privileges. One of the (arguably) easiest way of doing so is creating a Scheduled Task, as explained further below in this page.",
  "On Windows, if you simply launch the script, a Python window will be spawned, with a title similar to C:\\Windows\\py.exe. If you want to hide this window you can rename the file from agent.py to agent.pyw which will prevent the window from spawning upon launching the script.\n\nWarning\n\nIt is encouraged to use the agent in its window-less version (.pyw extension) given that opening a cmd window will definitely interfere with human.py, causing several problems like blocking the agent.py. communication with the host or producing no behavioral analysis output, just to mention some.\n\nDon't forget to test the agent before saving the snapshot. You can do it both navigating to VM_IP:8000 with a browser from your Host or be executing: curl VM_IP:8000. You should see an output similar to the following:\n\nimage\n\nimage\n\nPrior To Windows 10",
  "image\n\nimage\n\nPrior To Windows 10\n\nIf you want the script to be launched at Windows' boot, place the file in the admin startup folder. To access this folder, open the app launcher with Win+R and search for \"shell:common startup\" which will open the folder you want (usually C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\StartUp). Do not place the agent in the user startup folder (usually C:\\Users\\<Username>\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup) as it will launch the agent without admin privileges and therefore insufficient permissions resulting in the agent not being able to work as intended.\n\nWindows 10+\n\nNote\n\nUsing the scheduler as documented below is not strictly necessary. It is sufficient to take a snapshot with the agent running.\n\nTo start the script at boot, you will need to set the agent to be run as a scheduler task. Dropping it in C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\StartUp will result in it being ran with improper privilege.",
  "Open Windows menu (Win key) and search for Task Scheduler.\n\nSelect Create Basic Task from the action list.\n\nimage\n\nGive the task a name (for example pizza.pyw, the name is irrelevant as long as you don't make any mention to CAPE or anything blatant for anti-VM detection algorithms) and click Next.\n\nSet the trigger as When I logon and click Next.\n\nIn the Action window, select Start a program and click Next.\n\nIn the Start a program window, select the path of the agent.py, and click Finish.\n\nAfter the task is created, click the Task Scheduler Library and find the one you just created. Right click on it and select Properties.\n\nimage\n\nIn the general tab tell it to Run with highest privileges.\n\nimage\n\nSelect OK.\n\nAfter that all is done, it will come up on the next restart/login.",
  "Preparing the Guest\n\nAt this point, you should have configured the CAPE host component and you should have designed and defined the number and the names of the virtual machines you are going to use for malware execution.\n\nNow it's time to create such machines and configure them properly.\n\ncreation requirements agent additional_configuration network troubleshooting saving cloning linux",
  "Additional Configuration\n\nIn this chapter we will enumerate several recommendations so as to make your Guest virtual machine as stealthy and operational as it gets. Additionally, we intend to address some of the most common problems that may arise.\n\nWindows Guest\n\nWindows Debloating\n\nThere exist some tools that automatically try to debloat your Windows instance. That is, uninstalling lots of pre-installed software and disabling intrusive features of Windows. The purpose of these tools is optimization, performance, security or all of these. In the context of CAPE, they're useful to reduce noise and the probability of malware not detonating. Examples of these tools are Debloat-Windows-10 or BlackBird. You can find a larger list here.\n\nNote\n\nIt is recommended to use any of these tools to disable as much noise as possible. Remember to create a snapshot before executing them.\n\nDisable Microsoft Store",
  "Disable Microsoft Store\n\nSometimes the Microsoft Store opens up as soon as an analysis starts. In order to disable it, you can remove the environment variable %USERPROFILE%\\AppData\\Local\\Microsoft\\WindowsApps from the user PATH, as specified in this issue (#1237).\n\nReduce Overall Noise\n\nSometimes disabling all Windows services (like UAC, defender, update, aero, firewall, etc...) is necessary in order to make the analysis as fluent as possible. Make sure you check this script out and use it to get rid of all unnecessary noise. This is just an example. Your VM may require a different configuration in order to reduce or delete any Windows noise.\n\nWindows automatically enables the Virus Real-time Protection\n\nOne possible annoying behavior of Windows occurs when it automatically enables the real-time protection whenever an analysis is started therefore deleting the sample (if it identifies the sample as malware).",
  "To definitely turn it off you can follow one or more options listed in this site.",
  "Cloning the Virtual Machine\n\nIf you want to use more than one virtual machine based on a single \"golden image\", there's no need to repeat all the steps done so far: you can clone it. This way you'll have a copy of the original virtualized Windows with all requirements already installed.\n\nThere is a Python command-line utility available that can automate this process for you.\n\nThe new virtual machine will also contain all of the settings of the original one, which is not good. Now you need to proceed by repeating the steps explained in network, agent, and saving for this new machine.",
  "One alternative to manually make the clones unique is to enable the disguise auxiliary module, windows_static_route and windows_static_route_gateway in conf/auxiliary.conf. The auxiliary option is applicable to dnsmasq user which can't set the default gateway there because of the usage of an isolated routing in kvm. One could run it once and snapshot to apply the modification or running the auxiliary module at every analysis.",
  "Installing the Linux guest\n\nLinux guests doesn't have official CAPAE support! First, prepare the networking for your machinery platform on the host side.\n\nNext, get the list of virtual machines for which to configure the interface from conf/qemu.conf. For example, ubuntu_x32, ubuntu_x64, ubuntu_arm, ubuntu_mips, ubuntu_mipsel, et cetera. For each VM, preconfigure a network tap interface on the host, required to avoid having to start as root, e.g.:\n\n$ sudo ip tuntap add dev tap_ubuntu_x32 mode tap user cape\n$ sudo ip link set tap_ubuntu_x32 master br0\n$ sudo ip link set dev tap_ubuntu_x32 up\n$ sudo ip link set dev br0 up\n\n$ sudo ip tuntap add dev tap_ubuntu_x64 mode tap user cape\n$ sudo ip link set tap_ubuntu_x64 master br0\n$ sudo ip link set dev tap_ubuntu_x64 up\n$ sudo ip link set dev br0 up\n\nNote that if you run CAPE as a different user, replace ``cape`` after -u with your user. You also have a script in utils/linux_mktaps.sh\n\nPreparing x32/x64 Linux guests\n\nWarning",
  "Preparing x32/x64 Linux guests\n\nWarning\n\nFor Linux guests on an Azure hypervisor, installing Python3 32-bit breaks the way that the Azure agent starts: https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/agent-linux#installation. So the use of the monitor is limited to what can be run with the 64-bit version of Python3. You will have to comment out the architecture check in the CAPE agent.py for the CAPE agent to start. To reiterate, this warning is only relevant if you are using an Azure hypervisor.\n\nx32 guests\n\nInstall support file dependencies:\n\n$ sudo apt update\n$ sudo apt install python3-pip systemtap-runtime\n$ sudo pip3 install pyinotify\n$ sudo pip3 install Pillow       # optional\n$ sudo pip3 install pyscreenshot # optional\n$ sudo pip3 install pyautogui    # optional\n\nx64 guests\n\nInstall support file dependencies (we need Python3 32-bit):",
  "x64 guests\n\nInstall support file dependencies (we need Python3 32-bit):\n\n$ sudo dpkg --add-architecture i386\n$ sudo apt update\n$ sudo apt install python3:i386 -y\n$ sudo apt install python3-distutils -y\n$ sudo apt install systemtap-runtime -y\n$ curl -sSL https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n$ sudo python3 get-pip.py\n$ sudo python3 -m pip install pyinotify\n$ sudo python3 -m pip install Pillow       # optional\n$ sudo python3 -m pip install pyscreenshot # optional\n$ sudo python3 -m pip install pyautogui    # optional\n\nEnsure the agent automatically starts. The easiest way is to add it to crontab:\n\n$ sudo crontab -e\n@reboot python3 /path/to/agent.py\n\nDisable the firewall inside of the VM, if it exists:\n\n$ sudo ufw disable\n\nDisable NTP inside of the VM:\n\n$ sudo timedatectl set-ntp off\n\nDisable auto-update for noise reduction:",
  "$ sudo timedatectl set-ntp off\n\nDisable auto-update for noise reduction:\n\n$ sudo tee /etc/apt/apt.conf.d/20auto-upgrades << EOF\nAPT::Periodic::Update-Package-Lists \"0\";\nAPT::Periodic::Download-Upgradeable-Packages \"0\";\nAPT::Periodic::AutocleanInterval \"0\";\nAPT::Periodic::Unattended-Upgrade \"0\";\nEOF\n\n$ sudo systemctl stop snapd.service && sudo systemctl mask snapd.service\n\nIf needed, kill the unattended-upgrade process using htop or ps + kill.\n\nOptional - remove preinstalled software and configurations:\n\n$ sudo apt-get purge update-notifier update-manager update-manager-core ubuntu-release-upgrader-core -y\n$ sudo apt-get purge whoopsie ntpdate cups-daemon avahi-autoipd avahi-daemon avahi-utils -y\n$ sudo apt-get purge account-plugin-salut libnss-mdns telepathy-salut -y",
  "It is recommended to configure the Linux guest with a static IP addresses. Make sure the machine entry in the configuration has the correct IP address and has the platform variable set to linux. Create a snapshot once the VM has been configured. It is now ready for analysis!\n\nCommunity Feature - Tracee ---\n\nFor more information about Tracee in CAPEv2 and how to install it, visit its integration page: :ref:`tracee`.\n\nTo use [Tracee eBPF event tracing](https://github.com/kevoreilly/CAPEv2/pull/2235) in Linux, you will have to install Docker and the Tracee container in the Ubuntu guest:\n\n`shell docker pull docker.io/aquasec/tracee:0.20.0 docker image tag aquasec/tracee:0.20.0 aquasec/tracee:latest`\n\nAfterwards, enable Tracee using the appropriate options in auxiliary.conf and processing.conf and install the [CAPEv2 Community Repo](https://github.com/CAPESandbox/community). Here is a guide: https://capev2.readthedocs.io/en/latest/usage/utilities.html#community-download-utility.",
  "Tracee should be able to automatically highlight events such as fileless execution and syscall hooking.",
  "Creation of the Virtual Machine\n\nOnce you have properly installed <../host/installation> your virtualization software, you can create the virtual machines that you need.\n\nThe usage and configuration of your virtualization software is out of scope for this guide, so please refer to the virtualization software's official documentation.\n\nNote\n\nYou can find some hints and considerations on how to design and create your virtualized environment in the ../../introduction/sandboxing chapter.\n\nNote\n\nFor analysis purposes, it is recommended to use Windows 10 21H2 with User Access Control disabled.\n\nNote\n\nKVM Users - Be sure to choose a hard drive image format that supports snapshots, such as QCOW2. See saving for more information.\n\nWhen creating the virtual machine, CAPE doesn't require any specific configuration. Choose the options that best fit your needs.",
  "Requirements\n\nTo make CAPE run properly in your virtualized Windows system, you will have to install some required software and libraries.\n\nInstall Python\n\nPython is a strict requirement for the CAPE guest component (analyzer) to run properly.\n\nWarning\n\nPlease note that only 32-bit (x86) versions of Python3 are supported at this time for Windows, due to the way the analyzer interacts with low-level Windows libraries. Using a 64-bit version of Python will crash the analyzer in Windows. For other platforms the version of Python can be 64-bit (x64).\n\nYou can download the proper Windows / Linux installer from the official website. Python versions > 3.10 and < 3.13 are preferred.\n\nImportant\n\nWhen installing Python, it is recommended to select the Add Python <version> to PATH option. And remove from that PATH %USERPROFILE%AppDataLocalMicrosoftWindowsApps\n\nimage",
  "image\n\nWhen the installation is done, it is recommended to test whether Python is correctly set into your PATH environment variable. In order to do so, you can execute the following commands from a command prompt:\n\n> python --version\n\nYou should be prompted with Python's installed version. If not, make sure you add the binaries to your PATH. There are tutorials galore on the Internet.\n\nSome Python libraries are optional and provide some additional features to the CAPE guest component. They include:\n\nPython Image Library: used for taking screenshots of the Windows desktop during the analysis.\n\nThe recommended installation is the execution of the following commands:\n\n> python -m pip install --upgrade pip\n> python -m pip install Pillow\n\nThese Python libraries are not strictly required by CAPE, but you are encouraged to install them if you want to have access to all available features. Make sure to download and install the proper packages according to your Python version.",
  "Additional Software\n\nAt this point, you should have installed everything needed by CAPE to run properly.\n\nDepending on what kind of files you want to analyze and what kind of sandbox environment you want to run the malware samples in, you may want to install additional software such as browsers, PDF readers, office suites, etc.\n\nNote\n\nRemember to disable the \"Auto Update\" or \"Check For Updates\" feature of any additional software that you install.\n\nFor Microsoft Office we recommend Office 2010 SP2. This is both for its susceptibility to exploits typically used in maldocs, and its proven compatibility with CAPE. The only recommended alternative is Office 2016 (32-bit).\n\nWe do not recommend any Office version more recent than 2016 due to lack of proven compatibility with both maldocs and CAPE.\n\nFor hints about what your needs may be, give the ../../introduction/sandboxing chapter a read.",
  "Troubleshooting\n\nWhere to start diagnosing\n\nGiven the large number of technologies involved in CAPE installation, configuration and usage, chances are high one or more of them start failing, crashing or simply dying. When this happens, there are a few places you should always look first, since it could help you diagnosing the real problem and avoid wasting time looking at rabbit holes. These places are (no surprise here) the logs generated by each fundamental service involved in CAPE's execution. While all of them can be checked in their corresponding directories, journalctl can be leveraged to check all of them at once.\n\nNote\n\nPlease note the following errors are just random examples used to show how and where to start dealing with CAPE problems. You may never face these errors at all!",
  "Regardless of the error you are facing there are two places where you should start looking: (1) CAPE's logs (naming inherited from cuckoo) and (2) virtqemu logs (assuming you have installed KVM/QEMU using the kvm_qemu.sh script <installation_kvm>.)\n\nFor example, lets consider the following situation:\n\nCAPE submission (either via web or <submit.py>) apparently works, but the VM is never spawned (and analysis never launched).\n\nWithout prior indication, the first place to check are CAPE logs, located in /opt/CAPEv2/log/ (installation directory). The logs corresponding to the analyses are rotated daily, and the current log is cuckoo.log. Checking the contents of /opt/CAPEv2/log/cuckoo.log one could easily spot the culprit:\n\nError\n\nError example in <cuckoo.log> file.\n\nimage",
  "Error\n\nError example in <cuckoo.log> file.\n\nimage\n\nFurthermore, the error states something about libvirt. This is a clear indication that the corresponding logs must also be inspected. In this case, the logs of libvirt are stored under the virtqemud service. Whenever something seems wrong regarding the virtual machines, this is the place to look after. It can be inspected with $ sudo journalctl -u virtqemud -r:\n\nError\n\nError examples by inspecting vertqemud logs with journalctl.\n\nimage\n\nimage\n\nAdditionally, you should always try to see if you are able to manually replicate the error in order to discard technologies and find out which one is failing. Considering the scenario above, when trying to manually spawn the virtual machines:\n\nError\n\nError example in Virtual Manager - KVM.\n\nimage\n\nNo Internet connection in the guest",
  "Error\n\nError example in Virtual Manager - KVM.\n\nimage\n\nNo Internet connection in the guest\n\nThere are reasons galore why your guest VM has no Internet connection when an analysis is fired up. Before digging into this problem, please make sure you followed the steps at Network Configuration to set up both the virtual machine and its connections. Furthermore, you should read the routing chapter in order to know and understand the different routing modes as well as the rooter chapter to understand what the Rooter is.\n\nSome considerations:\n\ndirtyline should be the interface that provides your host internet connection like eno1, not a virtual interface like virbr1. This must be configured in the routing.conf configuration file.\n\nCheck agent.py is running with elevated privileges within the guest VM.\n\nMake sure you specify the correct STATIC IP in kvm.conf.\n\nMake sure you specified the correct interface in auxiliary.conf.",
  "Make sure you specified the correct interface in auxiliary.conf.\n\nAlso, bear in mind there are already created (and some of them solved) issues about this particular problem. For example:\n\nhttps://github.com/kevoreilly/CAPEv2/issues/1234\n\nhttps://github.com/kevoreilly/CAPEv2/issues/1245\n\nhttps://github.com/kevoreilly/CAPEv2/issues/371\n\nhttps://github.com/kevoreilly/CAPEv2/issues/367\n\nhttps://github.com/kevoreilly/CAPEv2/issues/136\n\nPCAP Generation\n\nIf you are facing problems related to either tcpdump or the PCAP generation, take a look at this issue (#1234).\n\nNote\n\nMake sure the pcap group exists in your system and that the user you use to launch CAPE (presumably the cape user) belongs to it as well as the tcpdump binary.\n\nMake sure the correct path is specified in auxiliary.conf for tcpdump. Check the path of your local installation of tcpdump with:\n\n$ whereis tcpdump",
  "$ whereis tcpdump\n\nCheck permissions of tcpdump binary. cape user must be able to run it. Also check whether you specified the correct interface in auxiliary.conf.\n\nIf you are still facing problems and the PCAP is not generating, verify the tcpdump binary belongs to the pcap group and it has the neede capabilities:\n\n$ sudo chgrp pcap /usr/bin/tcpdump\n$ sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/tcpdump\n\nOther issues about this problem:\n\nhttps://github.com/kevoreilly/CAPEv2/issues/1193",
  "Network Configuration\n\nNow it's time to set up the network for your virtual machine.\n\nWindows Settings\n\nNote\n\nAs was discussed in the previous chapter <additional_configuration>, any additional configuration like disabling the Windows Firewall and the Automatic Updates should be done before configuring the network as stated below. Given that VMs may be left without internet connection, it is convenient to download and make changes before this happens. The reason for turning off updates and firewall is that these features can affect the behavior of the malware under normal circumstances and they can pollute the network analysis performed by CAPE, by dropping connections or including irrelevant requests.\n\nWindows 10\n\nTo do so in Windows 10, open Control Panel and search for Windows Defender Firewall. Disable it completely:\n\nimage\n\nimage",
  "image\n\nimage\n\nThe next step is disabling automatic updates. To do so, open Control Panel and search for Administrative Tools. Open it, then open Services. Look for the Windows Update entry and double-click on it. Set Startup type to disabled and click stop.\n\nimage\n\nWindows XP\n\nYou can do so from Windows' Control Panel as shown in the picture:\n\nimage\n\nVirtual Networking\n\nNow you need to decide whether you want your virtual machine to be able to access the Internet or your local network.\n\nTo make the virtual machine's networking work properly you'll have to configure your machine's network so that the Host and the Guest can communicate.\n\nTesting the network access by pinging a guest from the host is good practice, to make sure that the virtual network was set up correctly.\n\nOnly use static IP addresses for your guests, since CAPE doesn't support DHCP (at least, as of this writing).\n\nWarning",
  "Warning\n\nThe range 192.168.122.0/24 is the default range for KVM's first interface (usually virbr01) and it can be used as an ANTI VM check. If you want to read more about ANTI VM checks and how to set up your VM, check this KVM ANTIVM post.\n\nThe recommended setup is using a Host-Only networking layout with proper forwarding and filtering configuration done with iptables on the Host.\n\nWe have automated this for you with:\n\n$ utils/rooter.py\n\nYou can read more about rooter.py in its dedicated chapter: rooter.\n\nIn the chapter Setting a static IP you will find the instructions for configuring a Windows guest OS to use a static IP. In the chapter Creating an isolated network you will find instructions on how to create an isolated network (usually referred to as hostonly) network and use it in your virtual machine. You can find further instructions on creating VMs with Virtual Machine Manage in this post.\n\nCreating an isolated network",
  "Creating an isolated network\n\nThe recommended setup is using an isolated network for your VM. In order to do so, you can follow the instructions below if you are using KVM and virt-manager (Virtual Machine Manager).\n\nFirst, in the Virtual Machine Manager GUI click con Edit -> Connection Details.\n\nimage\n\nIn the opened window click on the + sign, at the bottom left corner of the image. We are now defining the details of the new network. Give it a name (hostonly, for example) and make sure you select Isolated mode. Then, click on the IPv$ configuration drop-down menu and define the range of your network. In the image below only the third octet is changed.\n\nimage\n\nOnce the new isolated network is created, if you already created a VM, you can select it from Virtual Machine Manager by clicking Show virtual hardware details of that specific VM. Then click on the network adapter and choose the recently created network. Then click Apply.\n\nimage",
  "image\n\nThe next thing is checking the new interface was indeed created and the VM is actually using it. From your Host, execute the following command from a command prompt:\n\n> ip a\n\nimage\n\nThere should be an interface with the IP address you specified while creating it. in the image above the specific interface is virbr1.\n\nFrom the guest VM (Windows OS in this example) execute the following command from a command prompt:\n\n> ipconfig\n\nimage\n\nThe assigned IP should be in the range of the hostonly network.\n\nThe guest VM and host must have connectivity between them. In order to check it, you can use tools like ping or telnet.\n\nimage\n\nPlease bear in mind that this time the IP is assigned via DHCP, something CAPE does not support. Please set a static IP for your VM. Next chapter has instructions on that.\n\nSetting a static IP",
  "Setting a static IP\n\nTo set up a static IP it is first recommended to inspect the assigned IP, which will be (ideally) in the range of your interface (presumably y virbr0). To see your actual IP settings execute the following command from a command prompt:\n\n> ipconfig /all\n\nimage\n\nNote\n\nThe IP addresses and ranges used throughout this chapter are just examples. Please make sure you use your own working configurations and addresses.\n\nOpen Control Panel and search for Network. Find and open the Network and Sharing Center. Click Change adapter settings.\n\nimage\n\nNow open the Ethernet adapter and click Properties.\n\nimage\n\nThen click Internet Protocol Version 4 (TCP/IPv4) and Properties. Set the IP address, Subnet mask, Default gateway and DNS Server according to the results of the ipconfig command.\n\nimage\n\nNote\n\nYou can set as static IP address the address previously given by DHCP or any other address you like within the range of your interface.",
  "Wait a few seconds and you should have Internet access (in case you are using NAT. Bear in mind an isolated network will not provide Internet connection).\n\nIt is important to check connectivity between the Host and the Guest, like in the previous chapter.\n\nThis stage is very much up to your requirements and the characteristics of your virtualization software.\n\nWarning\n\nVirtual networking errors! Virtual networking is a vital component for CAPE. You must be sure that connectivity works between the host and the guests. Most of the issues reported by users are related to an incorrect networking setup. If you aren't sure about your networking, check your virtualization software documentation and test connectivity with ping and telnet.\n\nDisable Noisy Network Services\n\nWindows 7 introduced new network services that create a lot of noise and can hinder PCAP processing. Disable them by following the instructions below.\n\nTeredo\n\nOpen a command prompt as Administrator, and run:",
  "Teredo\n\nOpen a command prompt as Administrator, and run:\n\n> netsh interface teredo set state disabled\n\nLink Local Multicast Name Resolution (LLMNR)\n\nOpen the Group Policy editor by typing gpedit.msc into the Start Menu search box, and press Enter. Then navigate to Computer Configuration> Administrative Templates> Network> DNS Client, and open Turn off Multicast Name Resolution.\n\nSet the policy to enabled.\n\ngpedit.msc missing\n\nWarning\n\nIf gpedit.msc is not present in your system (if you are using Windows 10 Home Edition, for example), you can enable it by executing the following commands from an Administrator command prompt:\n\n> FOR %F IN (\"%SystemRoot%\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~*.mum\") DO (DISM /Online /NoRestart /Add-Package:\"%F\")\n> FOR %F IN (\"%SystemRoot%\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~*.mum\") DO (DISM /Online /NoRestart /Add-Package:\"%F\")",
  "If the commands were successful, you should now be able to execute Run (Win+R) -> gpedit.msc.\n\nNetwork Connectivity Status Indicator, Error Reporting, etc\n\nWindows has many diagnostic tools such as Network Connectivity Status Indicator and Error Reporting, that reach out to Microsoft servers over the Internet. Fortunately, these can all be disabled with one Group Policy change.\n\nOpen the Group Policy editor by typing gpedit.msc into the Start Menu search box, and press Enter. Then navigate to Computer Configuration> Administrative Templates> System> Internet Communication Management, and open Restrict Internet Communication.\n\nSet the policy to enabled.",
  "Saving the Virtual Machine\n\nNow you should be ready to save the virtual machine to a snapshot state.\n\nBefore doing this, make sure that you have rebooted the guest softly and that it's currently running, with CAPE's agent running and with Windows fully booted.\n\nNow you can proceed with saving the machine, which depends on the virtualization software that you decided to use.\n\nThe virtualization software-specific instructions found below can assist with getting the virtual machine ready to be used by CAPE.\n\nKVM\n\nHere are some helpful links for creating a virtual machine with virt-manager:\n\nCreate a virtual machine with virt-manager aka GUI client\n\nAdvanced KVM preparation for malware analysis",
  "Advanced KVM preparation for malware analysis\n\nIf you have decided to adopt KVM, you must use a disk format for your virtual machines that supports snapshots. By default, libvirt tools create RAW virtual disks, and since we need snapshots you'll have to use either QCOW2 or LVM. For the scope of this guide, we adopt QCOW2, since it is easier to set up than LVM.\n\nThe easiest way to create such a virtual disk is by using the tools provided by the libvirt suite. You can either use virsh if you prefer command-line interfaces or virt-manager for a nice GUI. You should be able to directly create the virtual disk in the QCOW2 format, but in case you have a RAW disk you can convert it like this:\n\n$ cd /your/disk/image/path\n$ qemu-img convert -O qcow2 your_disk.raw your_disk.qcow2\n\nNow edit your VM definition as follows:\n\n$ virsh edit \"<Name of VM>\"\n\nFind the disk section, which looks like this:",
  "$ virsh edit \"<Name of VM>\"\n\nFind the disk section, which looks like this:\n\n<disk type='file' device='disk'>\n    <driver name='qemu' type='raw'/>\n    <source file='/your/disk/image/path/your_disk.raw'/>\n    <target dev='hda' bus='ide'/>\n    <address type='drive' controller='0' bus='0' unit='0'/>\n</disk>\n\nAnd change \"type\" to qcow2 and \"source file\" to your qcow2 disk image path, like this:\n\n<disk type='file' device='disk'>\n    <driver name='qemu' type='qcow2'/>\n    <source file='/your/disk/image/path/your_disk.qcow2'/>\n    <target dev='hda' bus='ide'/>\n    <address type='drive' controller='0' bus='0' unit='0'/>\n</disk>\n\nKVM by default will pass through a feature flag, viewable in ECX as the 31st bit after executing the CPUID instruction with EAX set to 1. Some malware will use this unprivileged instruction to detect its execution in a VM. One way to avoid this is to modify your VM definition as follows: find the following line:\n\n<domain type='kvm'>\n\nChange it to:",
  "<domain type='kvm'>\n\nChange it to:\n\n<domain type='kvm' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0'>\n\nThen within the domain element, add the following:\n\n<qemu:commandline>\n  <qemu:arg value='-cpu'/>\n  <qemu:arg value='host,-hypervisor'/>\n</qemu:commandline>\n\nInstead of using \"host\", you can also choose from multiple other CPU models from the list displayed with the qemu-system-i386 -cpu help command (SandyBridge, Haswell, etc).\n\nNow test your virtual machine. If everything works, prepare it for snapshotting while running CAPE's agent. This means the virtual machine needs to be running when you take the snapshot. You can take a snapshot with the following command via virsh:\n\n$ virsh snapshot-create \"<Name of VM>\"\n$ virsh snapshot-create-as --domain \"<Name of VM>\" --name \"<Name of snapshot>\"\n\nAfter snapshotting the guest, you can shut it down.\n\nWarning\n\nHaving multiple snapshots can cause errors such as:\n\nERROR: No snapshot found for virtual machine <VM-Name>",
  "ERROR: No snapshot found for virtual machine <VM-Name>\n\nVM snapshots can be managed using the following commands.\n\n$ virsh snapshot-list \"<VM-Name>\"\n\n$ virsh snapshot-delete \"<VM-Name>\" \"<Snapshot-Name>\"\"\n\nSnapshot with Virtual Manager (virt-manager)\n\nIf you are using virtual manager (virt-manager) to manage you VMs (as mentioned in the installation_kvm chapter), you can also use it to create the snapshots.\n\nWarning\n\nVirtual manager allows you to create either internal or external snapshots (which you can read more about here). The arguably easier mode of operation are internal snapshots, given that external ones use individual files that may mess up your whole libvirt - qemu - kvm installation in case of name/path modification or loss.\n\nWhen creating a new snapshot, in newer versions of KVM you can select whether you want an internal or external or one:\n\nimage\n\nWhen any given snapshot is external, it's label will be suffixed with \"*(External)*\".\n\nimage\n\nVirtualBox",
  "image\n\nVirtualBox\n\nIf you are going for VirtualBox you can take the snapshot from the graphical user interface or the command line:\n\n$ VBoxManage snapshot \"<Name of VM>\" take \"<Name of snapshot>\" --pause\n\nAfter the snapshot creation is completed, you can power off the machine and restore it:\n\n$ VBoxManage controlvm \"<Name of VM>\" poweroff\n$ VBoxManage snapshot \"<Name of VM>\" restorecurrent\n\nVMware Workstation\n\nIf you decided to adopt VMware Workstation, you can take the snapshot from the graphical user interface or the command line:\n\n$ vmrun snapshot \"/your/disk/image/path/wmware_image_name.vmx\" your_snapshot_name\n\nWhere your_snapshot_name is the name you choose for the snapshot. After that power off the machine from the GUI or the command line:\n\n$ vmrun stop \"/your/disk/image/path/wmware_image_name.vmx\" hard\n\nXenServer",
  "$ vmrun stop \"/your/disk/image/path/wmware_image_name.vmx\" hard\n\nXenServer\n\nIf you decided to adopt XenServer, the XenServer machinery supports starting virtual machines from either disk or a memory snapshot. Creating and reverting memory snapshots require that the Xen guest tools be installed in the virtual machine. The recommended method of booting XenServer virtual machines is through memory snapshots because they can greatly reduce the boot time of virtual machines during analysis. If, however, the option of installing the guest tools is not available, the virtual machine can be configured to have its disks reset on boot. Resetting the disk ensures that malware samples cannot permanently modify the virtual machine.\n\nMemory Snapshots\n\nThe Xen guest tools can be installed from the XenCenter application that ships with XenServer. Once installed, restart the virtual machine and ensure that the CAPE agent is running.",
  "Snapshots can be taken through the XenCenter application and the command line interface on the control domain (Dom0). When creating the snapshot from XenCenter, ensure that the \"Snapshot disk and memory\" is checked. Once created, right-click on the snapshot and note the snapshot UUID.\n\nTo snapshot from the command line interface, run the following command:\n\n$ xe vm-checkpoint vm=\"vm_uuid_or_name\" new-name-label=\"Snapshot Name/Description\"\n\nThe snapshot UUID is printed to the screen once the command completes.\n\nRegardless of how the snapshot was created, save the UUID in the virtual machine's configuration section. Once the snapshot has been created, you can shut down the virtual machine.\n\nBooting from Disk\n\nIf you can't install the Xen guest tools or if you don't need to use memory snapshots, you will need to ensure that the virtual machine's disks are reset on boot and that the CAPE agent is set to run at boot time.",
  "Running the agent at boot time can be configured in Windows by adding a startup item for the agent.\n\nThe following commands must be run while the virtual machine is powered off.\n\nTo set the virtual machine's disks to reset on boot, you'll first need to list all the attached disks for the virtual machine. To list all attached disks, run the following command:\n\n$ xe vm-disk-list vm=\"vm_name_or_uuid\"\n\nIgnoring all CD-ROM and read-only disks, run the following command for each remaining disk to change its behavior to reset on boot:\n\n$ xe vdi-param-set uuid=\"vdi_uuid\" on-boot=reset\n\nAfter the disk is set to reset on boot, no permanent changes can be made to the virtual machine's disk. Modifications that occur while a virtual machine is running will not persist past shutdown.\n\nAzure\n\nOnce you have a virtual machine that is ready to be your golden image for a virtual machine scale set, take a snapshot of the virtual machine's disk.",
  "Official documentation on how to do this: Create a snapshot of a virtual hard disk\n\nWe are now going to turn this snapshot into an \"image\", which is the terminology Azure uses as the base for all virtual machines in a scale set.\n\nThe creation of an image from a snapshot takes a while, so be patient.\n\nIn the az.conf file, you will need to specify the Compute Gallery Name as well as the Image Definition Name.",
  "Integrations\n\nThis chapter explains how to integrate external/3rd party services to CAPE. CAPE is written in a modular architecture built to be as customizable as it can, to fit the needs of all users.\n\nbox-js curtain librenms suricata",
  "Curtain\n\nDetailed writeup by Mandiant's powershell blog post\n\nConfiguration required in Virtual Machine. Example for Windows 7:\n\nWindows 7 SP1, .NET at least 4.5, powershell 5 preferably over v4\nKB3109118 - Script block logging back port update for WMF4\nx64 - https://cuckoo.sh/vmcloak/Windows6.1-KB3109118-v4-x64.msu\nx32 - https://cuckoo.sh/vmcloak/Windows6.1-KB3109118-v4-x86.msu\nKB2819745 - WMF 4 (Windows Management Framework version 4) update for Windows 7\n\nx64 - https://cuckoo.sh/vmcloak/Windows6.1-KB2819745-x64-MultiPkg.msu\nx32 - https://cuckoo.sh/vmcloak/Windows6.1-KB2819745-x86-MultiPkg.msu\nKB3191566 - https://www.microsoft.com/en-us/download/details.aspx?id=54616",
  "You should create following registry entries\nreg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\ModuleLogging\\ModuleNames\" /v * /t REG_SZ /d * /f /reg:64\nreg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\ScriptBlockLogging\" /v EnableScriptBlockLogging /t REG_DWORD /d 00000001 /f /reg:64\nreg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\Transcription\" /v EnableTranscripting /t REG_DWORD /d 00000001 /f /reg:64\nreg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\Transcription\" /v OutputDirectory /t REG_SZ /d C:\\PSTranscipts /f /reg:64\nreg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\Transcription\" /v EnableInvocationHeader /t REG_DWORD /d 00000001 /f /reg:64",
  "Suricata\n\nSuricata can be used to grab binaries or the like off the wire and then feed them to CAPEv2 for detonation. This involves several parts.\n\nA box running Suricata listening on a network span.\n\nsuricata_extract_submit from CAPE::Utils for handling found binaries.\n\nA CAPEv2 box for detonation.\n\nmojo_cape_submit from CAPE::Utils for accepting submissions via suricata_extract_submit.\n\nSuricata requires rules are capable of this and a output configured for file extraction.\n\nCAPE::Utils can be installed via the command cpanm CAPE::Utils and on some Linux distros the headers, which on Debian is included in the package zlib1g-dev.\n\nOnce that is installed, a config file for suricata_extract_submit needs configured. The default location is usr/local/etc/suricata_extract_submit.ini.",
  "# the API key to use if needed\n#apikey=\n# URL to find mojo_cape_submit at\nurl=http://192.168.14.15:8080/\n# the group/client/whathaveya slug\nslug=foo\n# where Suricata has the file store at\nfilestore=/var/log/suricata/files\n# a file of IPs or subnets to ignore SRC or DEST IPs of\n#ignore=\n# a file of regex to use for checking host names go ignore\n#ignoreHosts=\n# if it should use HTTPS_PROXY and HTTP_PROXY from ENV or not\nenv_proxy=0\n# stats file holding only the stats for the last run\nstats_file=/var/cache/suricata_extract_submit_stats.json\n# stats dir\nstats_dir=/var/cache/suricata_extract_submit_stats/\n\nAnd then a cron job setup akin to below to handle the submission.\n\n/5 * * * * /usr/local/bin/suricata_extract_submit 2> /dev/null > /dev/null\n\nThe output is safe to dump to /dev/null as script sends it's data to syslog as suricata_extract_submit to the daemon log.\n\nYou can check if this has hung like below.",
  "You can check if this has hung like below.\n\n/usr/local/libexec/nagios/check_file_age -i -f /var/run/suricata_extract_submit.pid\n\nAnd if monitoring via LibreNMS the following line can be added to the SNMPD config to enable monitoring of it. There are then several rules available in the rules collection that can be used for alerting upon submission issues.\n\nextend suricata_extract /usr/local/bin/suricata_extract_submit_extend\n\nWith the submission CAPE::Utils just needs installed on the CAPEv2 system beingused for detonation. In the default configuration of CAPEv2 does not require /usr/local/etc/cape_utils.ini being used, but may be worthwhile reviewing the documentation. You will need to make sure the directories specifeid via the variable incoming and incoming_json exists and is writable/readable by CAPEv2.",
  "And if using the supplied systemd service file the following config file needs configured at /usr/local/etc/mojo_cape_submit.env. For more information on deploying Mojolicious based apps, the listen string, or for writing your own service file or something similar, checkout docs for Mojolicious Deployment.\n\nCAPE_USER=\"cape\"\nLISTEN_ON=\"http://192.168.14.15:8080\"\n\nSecurity mojo_cape_submit defaults to IP and can be controlled by the auth value in the config and has the default value of subnet as being 192.168.0.0/16,127.0.0.1/8,::1/128,172.16.0.0/12,10.0.0.0/8, which allows submission via anything on common private/local subnets.\n\nIf you using LibreNMS, you can monitor monitor it via mojo_cape_submit_extend by adding the following to your SNMPD config.\n\nextend mojo_cape_submit /usr/local/bin/mojo_cape_submit_extend",
  "Box-js\n\nbox_installation\n\nbox_preparation\n\nbox_starting\n\nbox_restapi\n\nInstallation\n\nQuick and dirty notes on how to integrate box-js to CAPE:\n\n$ curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash -\n$ sudo apt install docker.io nodejs git\n$ sudo usermod -aG docker cape\n# newgrp docker\n$ docker run hello-world\n$ sudo npm install -g --save npm@latest core-util-is hapi rimraf express express-fileupload\n$ git clone https://github.com/kirk-sayre-work/box-js /opt/box-js\n$ cd /opt/box-js\n$ sudo npm audit fix --force\n\nPreparation\n\nWe will leave fixing and hardening of box-js for you, here are just a few examples:",
  "Preparation\n\nWe will leave fixing and hardening of box-js for you, here are just a few examples:\n\nUSERNAME=\"CAPE\"\nIP=\"0.0.0.0\"\nsudo sed -i \"s|\\\\\\\\SYSOP1~1\\\\\\\\|\\\\\\\\$USERNAME\\\\\\\\|g\" emulator/WScriptShell.js\nsudo sed -i \"s|\\\\\\\\Sysop12\\\\\\\\|\\\\\\\\$USERNAME\\\\\\\\|g\" emulator/WScriptShell.js\nsudo sed -i \"s|windows-xp|windows 7|g\" emulator/WScriptShell.js # or 10 who knows\nsudo sed -i \"s|\\\\\\\\MyUsername\\\\\\\\|\\\\\\\\$USERNAME\\\\\\\\|g\" emulator/ShellApplication.js\nsudo sed -i \"s|USER-PC|$USERNAME-PC|g\" emulator/WMI.js\nsudo sed -i \"s|Sysop12|$USERNAME|g\" emulator/WMI.js\nsudo sed -i \"s|127.0.0.1|$IP|g\" integrations/api/api.js\n\nreplace emulator/processes.json with your own, you can use this to generate one:\n\n$ gwmi -Query \"SELECT * FROM Win32_Process\" > a.txt\n$ tools/makeProcList.js\n\ncreate a tar.gz with tar -czvf master.tar.gz box-js-master/:\n\n$ cd integrations/api/\n\nreplace Dockerfile with this content, required to run fixed/patched box-js inside of the Docker:",
  "replace Dockerfile with this content, required to run fixed/patched box-js inside of the Docker:\n\nFROM node:10-alpine\n#ENV http_proxy http://PROXY_IP:PORT\n#ENV https_proxy http://PROXY_IP:PORT\nRUN apk update && apk upgrade\nRUN apk add --no-cache bash file gcc m4\nRUN apk add -U --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing aufs-util\n# Install the latest v1 of box-js\nCOPY master.tar.gz /samples/\nRUN npm install /samples/master.tar.gz --global --production\nRUN rm /samples/master.tar.gz\nWORKDIR /samples\nCMD box-js /samples --output-dir=/samples --loglevel=debug\n\nStarting box-js rest-api\n\nThe default port is 9000 you can change it inside of api.py\n\n$ node api.js\n\nBox-js rest-api endpoints\n\nSandbox configuration\n\nIn conf/processing.conf enable box-js and set correct url",
  "Tracee eBPF for Linux\n\nCAPEv2 now has support for [Aqua Security Tracee](https://www.aquasec.com/products/tracee/), an eBPF-based threat detection engine with built-in signatures, for Linux dynamic analysis to complement the existing strace implementation.\n\nTo use it, you need to install the [CAPEv2 Community Repo](https://github.com/CAPESandbox/community). Here is a guide: https://capev2.readthedocs.io/en/latest/usage/utilities.html#community-download-utility.\n\nOnce you have installed the CAPEv2 Community Repo, you should have analyzer/linux/modules/auxiliary/tracee.py.\n\nTracee has functionality to:\n\ncapture artifacts such as loaded kernel modules, suspicious memory regions and eBPF programs in their run-time state, allowing their easy extraction even from packed and encrypted malwares\n\noperate at the eBPF level to capture events\n\nThe information captured from Tracee will then be displayed in a results UI:",
  "The information captured from Tracee will then be displayed in a results UI:\n\n![Screenshot of the Tracee Behaviour UI](https://github.com/user-attachments/assets/039ea42f-36bd-4530-b5d9-48face5f642b)\n\nConfiguring Tracee using Policies ===\n\nThe CAPEv2 Tracee module provides analyzer/linux/modules/auxiliary/tracee/policy.yml to Tracee. This policy.yml file defines how Tracee should behave and what events it should capture. You can modify locally it to fit your needs.\n\nDocumentation for the policy file: https://aquasecurity.github.io/tracee/v0.20/docs/policies/\n\nVerifying Functionality ===\n\nAfter performing the Tracee setup for Linux guests detailed in [Installing the Linux guest](https://capev2.readthedocs.io/en/latest/installation/guest/linux.html), you may want to verify the functionality of your installation and make sure everything is working well.",
  "You can obtain a live malware sample for Linux to load into CAPEv2 from https://bazaar.abuse.ch/sample/bd0141e88a0d56b508bc52db4dab68a49b6027a486e4d9514ec0db006fe71eed/. Please be careful with this file as it's actual malware. We do not take responsibility for anything that goes wrong.\n\nOnce the task is finished processing, the \"Detailed Behaviour (Tracee)\" tab ought to be available.",
  "LibreNMS\n\nLibreNMS is capable of monitoring stats for CAPEv2. This is handled by a SNMP extend.\n\nwget https://raw.githubusercontent.com/librenms/librenms-agent/master/snmp/cape -O /etc/snmp/cape\nchmod +x /etc/snmp/cape\napt-get install libfile-readbackwards-perl libjson-perl libconfig-tiny-perl libdbi-perl libfile-slurp-perl libstatistics-lite-perl libdbi-perl libdbd-pg-perl\n\nWith that all in place, you will then need to create a config file for it at /usr/local/etc/cape_extend.ini. Unless you are doing anything custom DB wise, the settings below, but with the proper PW will work.\n\n# DBI connection DSN\ndsn=dbi:Pg:dbname=cape;host=127.0.0.1\n\n# DB user\nuser=cape\n\n# DB PW\npass=12345\n\nThis module will also send warnings, errors, and critical errors found in the logs to LibreNMS. To filter these, /usr/local/etc/cape_extend.ignores can be used. The format for that is as below.\n\n<ignore level> <pattern>",
  "<ignore level> <pattern>\n\nThis the ignore level will be lower cased. The separator between the level and the regexp pattern is /[\\ \\t]+/. So if you want to ignore the two warnings generated when VM traffic is dropped, you would use the two lines such as below.\n\nWARNING PCAP file does not exist at path\nWARNING Unable to Run Suricata: Pcap file\n\nOn the CAPEv2 side, you will need to make a few tweaks to reporting.conf. litereport will need enabled and keys_to_copy should include 'signatures' and 'detections'.\n\nFinally will need to enable the extend for your\n\nextend cape /etc/snmp/extends/cape\n\nOnce snmpd is restarted and the the device rediscovered via LibreNMS, you will then be able to\n\nFor more detailed monitoring, if using KVM, you will likely want to also considering using HV::Monitor, which will allow detailed monitoring various stats VMs.",
  "Final Remarks\n\nLinks\n\nAsking for help\n\nPlease read the following rules before posting:\n\nBefore posting, Google about your issue. DO NOT post questions that have already been answered over and over everywhere.\n\nPosting messages saying just something like \"Doesn't work, help me\" is completely useless. If something is not working report the error, paste the logs, the config file, the information on the virtual machine, the results of the troubleshooting, etc. Give context. We are not wizards and we don't have a crystal ball.\n\nUse a proper title. Stuff like \"Doesn't work\", \"Help me\", and \"Error\" are not proper titles.\n\nTry to use pastebin.com, pastie.org or similar services to paste logs and configs: makes the message more readable.\n\nGithub issues. Please read the Markdown documentation before posting for tips on how to escape and post configs as code blocks.\n\nSupport Us",
  "Support Us\n\nCAPE Sandbox is a completely open source software, released freely to the public and developed mostly during free time by volunteers. If you enjoy it and want to see it kept developed and updated, please consider supporting us.\n\nWe are always looking for financial support, hardware support, and contributions of any sort. If you're interested in cooperating, feel free to contact us.\n\nPeople\n\nCAPE Sandbox is an open source project resulting from the efforts and contributions of a lot of people who enjoyed volunteering some of their time for the greater good :).\n\nActive Developers\n\nName Role Kevin O'Reilly Lead Developer Andriy Brukhovetskyy Lead Developer"
]