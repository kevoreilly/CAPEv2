# Enable or disable the available reporting modules [on/off].
# If you add a custom reporting module to your Cuckoo setup, you have to add
# a dedicated entry in this file, or it won't be executed.
# You can also add additional options under the section of your module and
# they will be available in your Python class.

# Community
[cents]
enabled = no
on_demand = no
# starting signature id for created Suricata rules
start_sid = 1000000

[mitre]
enabled = no

# https://github.com/geekscrapy/binGraph
# requires -> apt-get install python-tk
[bingraph]
enabled = yes
on_demand = yes
binary = yes
# geenrate bingraphs for cape/procdumps
cape = yes
procdump = yes

# Community
[pcap2cert]
enabled = yes

# Community
[litereport]
enabled = no
keys_to_copy = CAPE procdump info signatures dropped static target network shot malscore ttps
behavior_keys_to_copy = processtree summary

# Community
[reportbackup]
enabled = no
# External service to use
googledrive = no
# Specify the ID of the shared Google Drive Folder where reports will be backed up to
# Replace folder ID with own Google Drive shared folder (share access to created service account)
# Without service account, upload process cannot complete due to browser not being able to launch
drive_folder_id = id_here
drive_credentials_location = data/google_creds.json

[jsondump]
enabled = yes
indent = 4
encoding = latin-1

# Community
[reporthtml]
# Standalone report, not requires CAPE webgui
enabled = no
# Include screenshots in report
screenshots = no
apicalls = no

# Community
[reporthtmlsummary]
# much smaller, faster report generation, omits API logs and is non-interactive
enabled = no
# Include screenshots in report
screenshots = no

# Community
[reportpdf]
# Note that this requires reporthtmlsummary to be enabled above as well
enabled = no

# Community
[maec41]
enabled = no
mode = overview
processtree = true
output_handles = false
static = true
strings = true
virustotal = true
deduplicate = true

# Community
[maec5]
enabled = no

[mongodb]
enabled = no
host = 127.0.0.1
port = 27017
db = cuckoo
# Set those values if you are using mongodb authentication
# username =
# password =
# authsource = cuckoo

# Set this value if you are using mongodb with TLS enabled
# tlscafile =

# Automatically delete large dict values that exceed mongos 16MB limitation
# Note: This only deletes dict keys from data stored in MongoDB. You would
# still get the full dataset if you parsed the results dict in another
# reporting module or from the jsondump module.
fix_large_docs = yes

# Community
# Latest known working version is 7.16.2
# Use ElasticSearch as the "database" which powers Django.
# NOTE: If this is enabled, MongoDB should not be enabled, unless
# search only option is set to yes. Then elastic search is only used for /search web page.
[elasticsearchdb]
enabled = no
searchonly = no
host = 127.0.0.1
port = 9200
# The report data is indexed in the form of {{index-yyyy.mm.dd}}
# so the below index configuration option is actually an index 'prefix'.
index = cuckoo
# username =
# password =
# use_ssl =
# verify_certs =

# Community
[retention]
enabled = no
# run at most once every this many hours (unless reporting.conf is modified)
run_every = 6
# The amount of days old a task needs to be before deleting data
# Set a value to no to never delete it
memory = 14
procmemory = 62
pcap = 62
sortedpcap = 14
bsonlogs = 62
dropped = 62
screencaps = 62
reports = 62
mongo = 731
elastic = no

[syslog]
enabled = no
# IP of your syslog server/listener
host = x.x.x.x
# Port of your syslog server/listener
port = 514
# Protocol to send data over
protocol = tcp
# Store a logfile? [in reports directory]
logfile = yes
# if yes, what logname? [Default: syslog.txt]
logname = syslog.log

# Community
[moloch]
enabled = no
base = https://172.18.100.105:8005/
node = cuckoo3
capture = /data/moloch/bin/moloch-capture
captureconf = /data/moloch/etc/config.ini
user = admin
pass = admin
realm = Moloch

# Community
[resubmitexe]
enabled = no
resublimit = 5

# Community
[compression]
enabled = no
zipmemdump = yes
zipmemstrings = yes
zipprocdump = yes
zipprocstrings = yes

# Community
[misp]
enabled = no
apikey =
url =
#Make event published after creation?
published = no
# minimal malscore, by default all
min_malscore = 0
# by default 5 threads
threads =
# this will retrieve information for iocs
# and activate misp report download from webgui
extend_context = no
# upload iocs from cuckoo to MISP
upload_iocs = no
distribution = 0
threat_level_id = 2
analysis = 2
# Sections to report
# Analysis ID will be appended, change
title = Iocs from cuckoo analysis:
network = no
ids_files = no
dropped = no
registry = no
mutexes = no

# Community
[callback]
enabled = no
# will send as post data {"task_id":X}
# can be coma separated urls
url = http://IP/callback

# Community
# Compress results including CAPE output
# to help avoid reaching the hard 16MB MongoDB limit.
[compressresults]
enabled = no

[tmpfsclean]
enabled = no
key = tr_extractor

# Community
# This calls the specified command, pointing it at the report.json as
# well as setting $ENV{CAPE_TASK_ID} to the task ID of the run in question.
[zexecreport]
enabled=no
command=/foo/bar.pl

# Community
# run statistics, this may take more time.
[runstatistics]
enabled = no

# Community
[malheur]
enabled = no
